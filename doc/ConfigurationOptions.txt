# This is an auto-generated file, DO NOT EDIT!
# Run ant to generate it.

# entry function
analysis.entryFunction = "main"

# run interprocedural analysis
analysis.interprocedural = true

# which reached set implementation to use?
# NORMAL: just a simple set
# LOCATIONMAPPED: a different set per location (faster, elements with
# different locations cannot be merged)
# PARTITIONED: partitioning depending on CPAs (e.g Location, Callstack etc.)
analysis.reachedSet = PARTITIONED
  enum:     [NORMAL, LOCATIONMAPPED, PARTITIONED]

# restart the algorithm using a different CPA after unknown result
analysis.restartAfterUnknown = false

# stop after the first error has been found
analysis.stopAfterError = true

# which strategy to adopt for visiting states?
analysis.traversal.order = DFS
  enum:     [DFS, BFS, TOPSORT, RAND]

# handle states with a deeper callstack first?
# This needs the CallstackCPA to have any effect.
analysis.traversal.useCallstack = false

# Use an implementation of topsort strategy that allows to select a secondary
# strategy that is used if there are two elements with the same topsort id.
# The secondary strategy is selected with 'analysis.traversal.order'. The
# secondary strategy may not be TOPSORT.
analysis.traversal.useTopsort = false

# use assumption collecting algorithm
analysis.useAssumptionCollector = false

# use a BMC like algorithm that checks for satisfiability after the analysis
# has finished, works only with PredicateCPA
analysis.useBMC = false

# use CBMC to double-check counter-examples
analysis.useCBMC = false

# add declarations for global variables before entry function
analysis.useGlobalVars = true

# use CEGAR algorithm for lazy counter-example guided analysis
# You need to specify a refiner with the cegar.refiner option.
# Currently all refiner require the use of the ARTCPA.
analysis.useRefinement = false

# write collected assumptions as automaton to file
assumptions.automatonFile = "AssumptionAutomaton.txt"

# write collected assumptions to file
assumptions.export = true
assumptions.file = "assumptions.txt"

# If BMC did not find a bug, check whether the bounding did actually remove
# parts of the state space (this is similar to CBMC's unwinding assertions).
bmc.boundingAssertions = true

# Check reachability of target states after analysis (classical BMC). The
# alternative is to check the reachability as soon as the target states are
# discovered, which is done if cpa.predicate.targetStateSatCheck=true.
bmc.checkTargetStates = true

# try using induction to verify programs with loops
bmc.induction = true

# file name where to put the path program that is generated as input for
# CBMC. A temporary file is used if this is unspecified.
cbmc.dumpCBMCfile = 

# maximum time limit for CBMC (0 is infinite)
cbmc.timelimit = 0

# Which refinement algorithm to use? (give class name, required for CEGAR) If
# the package name starts with 'org.sosy_lab.cpachecker.', this prefix can be
# omitted.
cegar.refiner = ""

# completely restart analysis on refinement by removing everything from the
# reached set
cegar.restartOnRefinement = false

# export CFA as .dot file
cfa.export = true

# export individual CFAs for function as .dot files
cfa.exportPerFunction = true

# export CFA as .dot file
cfa.file = "cfa.dot"

# remove paths from CFA that cannot lead to a error location
cfa.removeIrrelevantForErrorLocations = false

# which model checker to use for verifying counterexamples as a second check
# Currently CBMC or CPAchecker with explicit analysis can be used.
counterexample.checker = "CBMC"
  allowed values: [CBMC, EXPLICIT]

# continue analysis after an counterexample was found that was denied by the
# second check
counterexample.continueAfterInfeasibleError = true

# CPA to use (see HowToConfiguration.txt for more documentation on this)
cpa = CompositeCPA.class.getCanonicalName()

# disable caching of abstract state spaces for blocks
cpa.abm.NO_CACHING = false

# Type of partitioning (FunctionAndLoopPartitioning or
# DelayedFunctionAndLoopPartitioning)
# or any class that implements a PartitioningHeuristic
cpa.abm.blockHeuristic = "FunctionAndLoopPartitioning"

# export error path to file, if one is found
cpa.art.errorPath.core = "ErrorPathCore.txt"
cpa.art.errorPath.export = true
cpa.art.errorPath.file = "ErrorPath.txt"
cpa.art.errorPath.json = "ErrorPath.json"
cpa.art.errorPath.source = "ErrorPath.c"

# export final ART as .dot file
cpa.art.export = true
cpa.art.file = "ART.dot"

# which merge operator to use for ARTCPA? only use sep here if all other CPAs
# also use sep
cpa.art.merge = "JOIN"
  allowed values: [SEP, JOIN]

# which heuristics should be used to track progress?
cpa.assumptions.progressobserver.heuristics = {}

# threshold for heuristics of progressobserver
cpa.assumptions.progressobserver.heuristics.assumeEdgesInPathHeuristics.threshold = -1
cpa.assumptions.progressobserver.heuristics.edgeCountHeuristics.threshold = -1
cpa.assumptions.progressobserver.heuristics.memoryOutHeuristics.threshold = -1
cpa.assumptions.progressobserver.heuristics.pathLengthHeuristics.threshold = -1
cpa.assumptions.progressobserver.heuristics.reachedSizeHeuristics.threshold = -1
cpa.assumptions.progressobserver.heuristics.repetitionsInPathHeuristics.threshold = -1
cpa.assumptions.progressobserver.heuristics.timeOutHeuristics.threshold = -1
cpa.assumptions.progressobserver.heuristics.usedMemoryOutHeuristics.threshold = 0

# signal the analysis to break in case of reached error state
cpa.automaton.breakOnTargetState = true

# export automaton to file
cpa.automaton.dotExport = false

# file for saving the automaton in DOT format
cpa.automaton.dotExportFile = "automaton.dot"

# file with automaton specification for ObserverAutomatonCPA and
# ControlAutomatonCPA
cpa.automaton.inputFile = 

# which composite merge operator to use (plain or agree)
# Both delegate to the component cpas, but agree only allows merging if all
# cpas agree on this. This is probably what you want.
cpa.composite.merge = "AGREE"
  allowed values: [PLAIN, AGREE]

# which merge operator to use for DefUseCPA
cpa.defuse.merge = "sep"
  allowed values: [sep, join]

# which merge operator to use for ExplicitCPA
cpa.explicit.merge = "SEP"
  allowed values: [SEP, JOIN]

# which stop operator to use for ExplicitCPA
cpa.explicit.stop = "SEP"
  allowed values: [SEP, JOIN, NEVER]

# threshold for amount of different values that are tracked for one variable
# in ExplicitCPA (0 means infinitely)
cpa.explicit.threshold = 0

# blacklist regex for variables that won't be tracked by ExplicitCPA
cpa.explicit.variableBlacklist = ""

# whitelist regex for variables that will be tracked by FeatureVarsCPA
cpa.featurevars.variableWhitelist = ""

# which type of merge operator to use for IntervalAnalysisCPA
cpa.interval.merge = "SEP"
  allowed values: [SEP, JOIN]

# at most that many intervals will be tracked per variable
cpa.interval.threshold = 0

# which merge operator to use for InvariantCPA
cpa.invariants.merge = "JOIN"
  allowed values: [JOIN, SEP]

# threshold for unrolling loops of the program (0 is infinite)
# works only if assumption storage CPA is enabled, because otherwise it would
# be unsound
cpa.loopstack.maxLoopIterations = 0

# time limit for a single post computation in millseconds (0 to disable)
cpa.monitor.limit = 0

# time limit for all computations on a path in milliseconds (0 to disable)
cpa.monitor.pathcomputationlimit = 0

# which merge operator to use for OctagonCPA?
cpa.octagon.merge = "SEP"
  allowed values: [SEP, JOIN]

# which merge operator to use for PointerCPA?
cpa.pointer.merge = "sep"
  allowed values: [sep, join]

# print warnings during analysis when unsafe pointer operations are found
cpa.pointer.printWarnings = true

# whether to use auxiliary predidates for reduction
cpa.predicate.abm.auxiliaryPredicateComputer = true

# use caching of region to formula conversions
# use caching of abstractions
cpa.predicate.abs.useCache = true

# whether to use Boolean (false) or Cartesian (true) abstraction
cpa.predicate.abstraction.cartesian = false

# dump the abstraction formulas if they took to long
cpa.predicate.abstraction.dumpHardQueries = false

# get an initial set of predicates from a file in MSAT format
cpa.predicate.abstraction.initialPredicates = 

# which solver to use?
cpa.predicate.abstraction.solver = "MATHSAT"
  allowed values: [MATHSAT, YICES]

# when transforming code to formula, add predicates that help producing more
# precise error paths (not necessary for SBE)
cpa.predicate.addBranchingInformation = true

# force abstractions on function call/return
cpa.predicate.blk.functions = true

# force abstractions for each loop iteration
cpa.predicate.blk.loops = true

# require that both the threshold and (functions or loops) have to be
# fulfilled to compute an abstraction
cpa.predicate.blk.requireThresholdAndLBE = false

# maximum blocksize before abstraction is forced
# (non-negative number, special values: 0 = don't check threshold, 1 = SBE)
cpa.predicate.blk.threshold = 0

# use caching of path formulas
cpa.predicate.blk.useCache = true

# always check satisfiability at end of block, even if precision is empty
cpa.predicate.checkBlockFeasibility = false

# export one satisfying assignment for the error path
cpa.predicate.errorPath.export = true
cpa.predicate.errorPath.file = "ErrorPathAssignment.txt"

# where to dump interpolation and abstraction problems (format string)
cpa.predicate.formulaDumpFilePattern = "%s%04d-%s%03d.msat"

# initialize all variables to 0 when they are declared
cpa.predicate.initAllVars = false

# which interpolating solver to use for interpolant generation?
cpa.predicate.interpolatingProver = "MATHSAT"
  allowed values: [MATHSAT, CSISAT]

# try second interpolating solver if the first takes too long
cpa.predicate.interpolation.changesolverontimeout = false

# use uninterpreted functions for *, & and array access
cpa.predicate.mathsat.lvalsAsUIFs = false

# use a combination of theories (this is incomplete)
cpa.predicate.mathsat.useDtc = false

# encode program variables as INTEGERs in MathSAT, instead of using REALs.
# Since interpolation is not really supported by the laz solver, when
# computing interpolants we still use the LA solver, but encoding variables
# as ints might still be a good idea: we can tighten strict inequalities, and
# split negated equalities
cpa.predicate.mathsat.useIntegers = false

# if initAllVars is true, we get rid of all non-determinism. This might not
# be desirable. If the following property is set to a non-empty value, all
# variables starting with this prefix will not be initialized automatically
cpa.predicate.noAutoInitPrefix = "__BLAST_NONDET"

# list of functions that should be considered as giving a non-deterministic
# return value
#  Only predicate analysis honors this option. If you specify this option,
# the default values are not added automatically to the list, so you need to
# specify them explicitly if you need them. Mentioning a function in this
# list has only an effect, if it is an 'external function', i.e., no source
# is given in the code for this function.
cpa.predicate.nondetFunctions = {"int_nondet", "malloc", "nondet_int", "random"}

# export final predicate map, if the error location is not reached
cpa.predicate.predmap.export = true
cpa.predicate.predmap.file = "predmap.txt"

# refinement will add all discovered predicates to all the locations in the
# abstract trace
cpa.predicate.refinement.addPredicatesGlobally = false

# refinement will try to build 'well-scoped' predicates, by cutting spurious
# traces as explained in Section 5.2 of the paper 'Abstractions From Proofs'
# (this does not work with function inlining).
# THIS FEATURE IS CURRENTLY NOT AVAILABLE. 
cpa.predicate.refinement.addWellScopedPredicates = false

# only use the atoms from the interpolants as predicates, and not the whole
# interpolant
cpa.predicate.refinement.atomicPredicates = true

# try again with a second solver if refinement timed out
cpa.predicate.refinement.changesolverontimeout = false

# dump all interpolation problems
cpa.predicate.refinement.dumpInterpolationProblems = false

# apply deletion-filter to the abstract counterexample, to get a minimal set
# of blocks, before applying interpolation-based refinement
cpa.predicate.refinement.getUsefulBlocks = false

# skip refinement if input formula is larger than this amount of bytes
# (ignored if 0)
cpa.predicate.refinement.maxRefinementSize = 0

# where to dump the counterexample formula in case the error location is
# reached
cpa.predicate.refinement.msatCexFile = "counterexample.msat"

# use incremental search in counterexample analysis, to find the minimal
# infeasible prefix
cpa.predicate.refinement.shortestCexTrace = false

# if shortestCexTrace is used, start from the end with the incremental search
cpa.predicate.refinement.shortestCexTraceUseSuffix = false

# if shortestCexTrace is used, alternatingly search from start and end of the
# trace
cpa.predicate.refinement.shortestCexTraceZigZag = false

# split arithmetic equalities when extracting predicates from interpolants
cpa.predicate.refinement.splitItpAtoms = false

# time limit for refinement (0 is infinitely long)
cpa.predicate.refinement.timelimit = 0

# maximum blocksize before a satisfiability check is done
# (non-negative number, 0 means never, if positive should be smaller than
# blocksize)
cpa.predicate.satCheck = 0

# whether to include the symbolic path formula in the coverage checks or do
# only the fast abstract checks
cpa.predicate.symbolicCoverageCheck = false

# check satisfiability when a target state has been found (should be true)
cpa.predicate.targetStateSatCheck = true

# try to add some useful static-learning-like axioms for bitwise operations
# (which are encoded as UFs): essentially, we simply collect all the numbers
# used in bitwise operations, and add axioms like (0 & n = 0)
cpa.predicate.useBitwiseAxioms = false

# add special information to formulas about non-deterministic functions
cpa.predicate.useNondetFlags = false

# which merge operator to use for UninitializedVariablesCPA?
cpa.uninitvars.merge = "sep"
  allowed values: [sep, join]

# print warnings during analysis when uninitialized variables are used
cpa.uninitvars.printWarnings = "true"

# which stop operator to use for UninitializedVariablesCPA?
cpa.uninitvars.stop = "sep"
  allowed values: [sep, join]

# Possible log levels in descending order 
# (lower levels include higher ones):
# OFF:      no logs published
# SEVERE:   error messages
# WARNING:  warnings
# INFO:     messages
# FINE:     logs on main application level
# FINER:    logs on central CPA algorithm level
# FINEST:   logs published by specific CPAs
# ALL:      debugging information
# Care must be taken with levels of FINER or lower, as output files may
# become quite large and memory usage might become an issue.

# single levels to be excluded from being logged
log.consoleExclude = {}

# log level of console output
log.consoleLevel = "INFO"
  allowed values: [OFF, SEVERE, WARNING, INFO, FINE, FINER, FINEST, ALL]

# name of the log file
log.file = "CPALog.txt"

# single levels to be excluded from being logged
log.fileExclude = {}

# log level of file output
log.level = "OFF"
  allowed values: [OFF, SEVERE, WARNING, INFO, FINE, FINER, FINEST, ALL]

# maximum size of log output strings before they will be truncated
log.truncateSize = 10000

# all used options are printed
log.usedOptions.export = false

# variables whose name contains this will be seen by InterpreterCPA as having
# non-deterministic values
# variables whose name contains this will be seen by ExplicitCPA as having
# non-deterministic values
noAutoInitPrefix = "__BLAST_NONDET"

# disable all default output files
# (any explicitly given file will still be written)
output.disable = false

# directory to put all output files in
output.path = "test/outp
