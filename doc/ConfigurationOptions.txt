# This is an auto-generated file, DO NOT EDIT!
# Run ant to generate it.

# entry function
analysis.entryFunction = "main"

# use CBMC as an external tool from CPAchecker
analysis.externalCBMC = false

# run interprocedural analysis
analysis.interprocedural = true

# which reached set implementation to use?
# NORMAL: just a simple set
# LOCATIONMAPPED: a different set per location (faster, elements with
# different locations cannot be merged)
# PARTITIONED: partitioning depending on CPAs (e.g Location, Callstack etc.)
analysis.reachedSet = PARTITIONED
  enum:     [NORMAL, LOCATIONMAPPED, PARTITIONED]

# restart the algorithm using a different CPA after unknown result
analysis.restartAfterUnknown = false

# stop after the first error has been found
analysis.stopAfterError = true

# which strategy to adopt for visiting states?
analysis.traversal.order = DFS
  enum:     [DFS, BFS, TOPSORT, RAND]

# handle states with a deeper callstack first?
# This needs the CallstackCPA to have any effect.
analysis.traversal.useCallstack = false

# handle more abstract states (with less information) first? (only for
# ExplicitCPA)
analysis.traversal.useExplicitInformation = false

# Use an implementation of topsort strategy that allows to select a secondary
# strategy that is used if there are two elements with the same topsort id.
# The secondary strategy is selected with 'analysis.traversal.order'. The
# secondary strategy may not be TOPSORT.
analysis.traversal.useTopsort = false

# use assumption collecting algorithm
analysis.useAssumptionCollector = false

# use a BMC like algorithm that checks for satisfiability after the analysis
# has finished, works only with PredicateCPA
analysis.useBMC = false

# use CBMC to double-check counter-examples
analysis.useCBMC = false

# add declarations for global variables before entry function
analysis.useGlobalVars = true

# use CEGAR algorithm for lazy counter-example guided analysis
# You need to specify a refiner with the cegar.refiner option.
# Currently all refiner require the use of the ARTCPA.
analysis.useRefinement = false

# use experimental rely-guarantee CEGAR loop
analysis.useRelyGuaranteeRefinement = false

# write collected assumptions as automaton to file
assumptions.automatonFile = "AssumptionAutomaton.txt"

# write collected assumptions to file
assumptions.export = true
assumptions.file = "assumptions.txt"

# If BMC did not find a bug, check whether the bounding did actually remove
# parts of the state space (this is similar to CBMC's unwinding assertions).
bmc.boundingAssertions = true

# Check reachability of target states after analysis (classical BMC). The
# alternative is to check the reachability as soon as the target states are
# discovered, which is done if cpa.predicate.targetStateSatCheck=true.
bmc.checkTargetStates = true

# try using induction to verify programs with loops
bmc.induction = false

# configuration file for invariant generation
bmc.invariantGenerationConfigFile = 

# generate invariants for induction in parallel to the analysis
bmc.parallelInvariantGeneration = false

# file name where to put the path program that is generated as input for
# CBMC. A temporary file is used if this is unspecified.
cbmc.dumpCBMCfile = 

# specify the name of the error label
cbmc.options.errorLabel = "ERROR"

# set width of int (16, 32 or 64)
cbmc.options.intWidth = 32

# disable unwinding assertions violation error
cbmc.options.nuaf = false

# specify the limit for unwindings (0 is infinite)
cbmc.options.unwindings = 0

# maximum time limit for CBMC (0 is infinite)
cbmc.timelimit = 0

# Which refinement algorithm to use? (give class name, required for CEGAR) If
# the package name starts with 'org.sosy_lab.cpachecker.', this prefix can be
# omitted.
cegar.refiner = ""

# completely restart analysis on refinement by removing everything from the
# reached set
cegar.restartOnRefinement = false

# export CFA as .dot file
cfa.export = true

# export individual CFAs for function as .dot files
cfa.exportPerFunction = true

# export CFA as .dot file
cfa.file = "cfa.dot"
cfa.relyguarantee.export = true

# export individual CFAs for function as .dot files
cfa.relyguarantee.exportPerFunction = true

# File path template for exporting  thread CFA to .dot files
cfa.relyguarantee.file = "test/output/cfa_"

# Names of main functions for threads. They ought to be uniquee.
cfa.relyguarantee.threadFunctions = {"thread0", "thread1", "thread3", "thread4", "thread5", "thread6", "thread7", "thread8", "thread9"}

# remove paths from CFA that cannot lead to a error location
cfa.removeIrrelevantForErrorLocations = false

# which model checker to use for verifying counterexamples as a second check
# Currently CBMC or CPAchecker with a different config can be used.
counterexample.checker = "CBMC"
  allowed values: [CBMC, CPACHECKER]

# configuration file for counterexample checks with CPAchecker
counterexample.checker.config = "test/config/explicitAnalysisInf.properties"

# continue analysis after an counterexample was found that was denied by the
# second check
counterexample.continueAfterInfeasibleError = true

# If continueAfterInfeasibleError is true, remove the infeasible
# counterexample before continuing.Setting this to false may prevent a lot of
# similar infeasible counterexamples to get discovered, but is unsound
counterexample.removeInfeasibleErrors = false

# CPA to use (see HowToConfiguration.txt for more documentation on this)
cpa = CompositeCPA.class.getCanonicalName()

# disable caching of abstract state spaces for blocks
cpa.abm.NO_CACHING = false

# Type of partitioning (FunctionAndLoopPartitioning or
# DelayedFunctionAndLoopPartitioning)
# or any class that implements a PartitioningHeuristic
cpa.abm.blockHeuristic = "FunctionAndLoopPartitioning"

# export error path to file, if one is found
cpa.art.errorPath.core = "ErrorPathCore.txt"
cpa.art.errorPath.export = true
cpa.art.errorPath.file = "ErrorPath.txt"
cpa.art.errorPath.json = "ErrorPath.json"
cpa.art.errorPath.source = "ErrorPath.c"

# export final ART as .dot file
cpa.art.export = true
cpa.art.file = "ART.dot"

# which heuristics should be used to track progress?
cpa.assumptions.progressobserver.heuristics = {}

# threshold for heuristics of progressobserver
cpa.assumptions.progressobserver.heuristics.assumeEdgesInPathHeuristics.threshold = -1
cpa.assumptions.progressobserver.heuristics.edgeCountHeuristics.threshold = -1
cpa.assumptions.progressobserver.heuristics.memoryOutHeuristics.threshold = -1
cpa.assumptions.progressobserver.heuristics.pathLengthHeuristics.threshold = -1
cpa.assumptions.progressobserver.heuristics.reachedSizeHeuristics.threshold = -1
cpa.assumptions.progressobserver.heuristics.repetitionsInPathHeuristics.threshold = -1
cpa.assumptions.progressobserver.heuristics.timeOutHeuristics.threshold = -1
cpa.assumptions.progressobserver.heuristics.usedMemoryOutHeuristics.threshold = 0

# signal the analysis to break in case of reached error state
cpa.automaton.breakOnTargetState = true

# export automaton to file
cpa.automaton.dotExport = false

# file for saving the automaton in DOT format
cpa.automaton.dotExportFile = "automaton.dot"

# file with automaton specification for ObserverAutomatonCPA and
# ControlAutomatonCPA
cpa.automaton.inputFile = 

# which composite merge operator to use (plain or agree)
# Both delegate to the component cpas, but agree only allows merging if all
# cpas agree on this. This is probably what you want.
cpa.composite.merge = "AGREE"
  allowed values: [PLAIN, AGREE]

# which merge operator to use for DefUseCPA
cpa.defuse.merge = "sep"
  allowed values: [sep, join]

# which merge operator to use for ExplicitCPA
cpa.explicit.merge = "SEP"
  allowed values: [SEP, JOIN]

# which stop operator to use for ExplicitCPA
cpa.explicit.stop = "SEP"
  allowed values: [SEP, JOIN, NEVER]

# threshold for amount of different values that are tracked for one variable
# in ExplicitCPA (0 means infinitely)
cpa.explicit.threshold = 0

# blacklist regex for variables that won't be tracked by ExplicitCPA
cpa.explicit.variableBlacklist = ""

# whitelist regex for variables that will be tracked by FeatureVarsCPA
cpa.featurevars.variableWhitelist = ""

# which type of merge operator to use for IntervalAnalysisCPA
cpa.interval.merge = "SEP"
  allowed values: [SEP, JOIN]

# decides whether one (false) or two (true) successors should be created when
# an inequality-check is encountered
cpa.interval.splitIntervals = false

# at most that many intervals will be tracked per variable
cpa.interval.threshold = 0

# which merge operator to use for InvariantCPA
cpa.invariants.merge = "JOIN"
  allowed values: [JOIN, SEP]

# threshold for unrolling loops of the program (0 is infinite)
# works only if assumption storage CPA is enabled, because otherwise it would
# be unsound
cpa.loopstack.maxLoopIterations = 0

# time limit for a single post computation in millseconds (0 to disable)
cpa.monitor.limit = 0

# time limit for all computations on a path in milliseconds (0 to disable)
cpa.monitor.pathcomputationlimit = 0

# which merge operator to use for OctagonCPA?
cpa.octagon.merge = "SEP"
  allowed values: [SEP, JOIN]

# which merge operator to use for PointerCPA?
cpa.pointer.merge = "sep"
  allowed values: [sep, join]

# print warnings during analysis when unsafe pointer operations are found
cpa.pointer.printWarnings = true

# whether to use auxiliary predidates for reduction
cpa.predicate.abm.auxiliaryPredicateComputer = true

# use caching of region to formula conversions
# use caching of abstractions
cpa.predicate.abs.useCache = true

# whether to use Boolean (false) or Cartesian (true) abstraction
cpa.predicate.abstraction.cartesian = false

# dump the abstraction formulas if they took to long
cpa.predicate.abstraction.dumpHardQueries = false

# get an initial set of predicates from a file in MSAT format
cpa.predicate.abstraction.initialPredicates = 

# which solver to use?
cpa.predicate.abstraction.solver = "MATHSAT"
  allowed values: [MATHSAT, YICES]

# force abstractions on function call/return
cpa.predicate.blk.functions = true

# force abstractions for each loop iteration
cpa.predicate.blk.loops = true

# require that both the threshold and (functions or loops) have to be
# fulfilled to compute an abstraction
cpa.predicate.blk.requireThresholdAndLBE = false

# maximum blocksize before abstraction is forced
# (non-negative number, special values: 0 = don't check threshold, 1 = SBE)
cpa.predicate.blk.threshold = 0

# use caching of path formulas
cpa.predicate.blk.useCache = true

# always check satisfiability at end of block, even if precision is empty
cpa.predicate.checkBlockFeasibility = false

# export one satisfying assignment for the error path
cpa.predicate.errorPath.export = true
cpa.predicate.errorPath.file = "ErrorPathAssignment.txt"

# where to dump interpolation and abstraction problems (format string)
cpa.predicate.formulaDumpFilePattern = "%s%04d-%s%03d.msat"

# initialize all variables to 0 when they are declared
cpa.predicate.initAllVars = false

# which interpolating solver to use for interpolant generation?
cpa.predicate.interpolatingProver = "MATHSAT"
  allowed values: [MATHSAT, CSISAT]

# try second interpolating solver if the first takes too long
cpa.predicate.interpolation.changesolverontimeout = false

# use uninterpreted functions for *, & and array access
cpa.predicate.mathsat.lvalsAsUIFs = false

# use a combination of theories (this is incomplete)
cpa.predicate.mathsat.useDtc = false

# encode program variables as INTEGERs in MathSAT, instead of using REALs.
# Since interpolation is not really supported by the laz solver, when
# computing interpolants we still use the LA solver, but encoding variables
# as ints might still be a good idea: we can tighten strict inequalities, and
# split negated equalities
cpa.predicate.mathsat.useIntegers = false

# if initAllVars is true, we get rid of all non-determinism. This might not
# be desirable. If the following property is set to a non-empty value, all
# variables starting with this prefix will not be initialized automatically
cpa.predicate.noAutoInitPrefix = "__BLAST_NONDET"

# list of functions that should be considered as giving a non-deterministic
# return value
#  Only predicate analysis honors this option. If you specify this option,
# the default values are not added automatically to the list, so you need to
# specify them explicitly if you need them. Mentioning a function in this
# list has only an effect, if it is an 'external function', i.e., no source
# is given in the code for this function.
cpa.predicate.nondetFunctions = {"int_nondet", "malloc", "nondet_int", "random"}

# export final predicate map, if the error location is not reached
cpa.predicate.predmap.export = true
cpa.predicate.predmap.file = "predmap.txt"

# refinement will add all discovered predicates to all the locations in the
# abstract trace
cpa.predicate.refinement.addPredicatesGlobally = false

# refinement will try to build 'well-scoped' predicates, by cutting spurious
# traces as explained in Section 5.2 of the paper 'Abstractions From Proofs'
# (this does not work with function inlining).
# THIS FEATURE IS CURRENTLY NOT AVAILABLE. 
cpa.predicate.refinement.addWellScopedPredicates = false

# only use the atoms from the interpolants as predicates, and not the whole
# interpolant
cpa.predicate.refinement.atomicPredicates = true

# try again with a second solver if refinement timed out
cpa.predicate.refinement.changesolverontimeout = false

# dump all interpolation problems
cpa.predicate.refinement.dumpInterpolationProblems = false

# apply deletion-filter to the abstract counterexample, to get a minimal set
# of blocks, before applying interpolation-based refinement
cpa.predicate.refinement.getUsefulBlocks = false

# skip refinement if input formula is larger than this amount of bytes
# (ignored if 0)
cpa.predicate.refinement.maxRefinementSize = 0

# where to dump the counterexample formula in case the error location is
# reached
cpa.predicate.refinement.msatCexFile = "counterexample.msat"

# use incremental search in counterexample analysis, to find the minimal
# infeasible prefix
cpa.predicate.refinement.shortestCexTrace = false

# if shortestCexTrace is used, start from the end with the incremental search
cpa.predicate.refinement.shortestCexTraceUseSuffix = false

# if shortestCexTrace is used, alternatingly search from start and end of the
# trace
cpa.predicate.refinement.shortestCexTraceZigZag = false

# split arithmetic equalities when extracting predicates from interpolants
cpa.predicate.refinement.splitItpAtoms = false

# time limit for refinement (0 is infinitely long)
cpa.predicate.refinement.timelimit = 0

# maximum blocksize before a satisfiability check is done
# (non-negative number, 0 means never, if positive should be smaller than
# blocksize)
cpa.predicate.satCheck = 0

# whether to include the symbolic path formula in the coverage checks or do
# only the fast abstract checks
cpa.predicate.symbolicCoverageCheck = false

# check satisfiability when a target state has been found (should be true)
cpa.predicate.targetStateSatCheck = true

# try to add some useful static-learning-like axioms for bitwise operations
# (which are encoded as UFs): essentially, we simply collect all the numbers
# used in bitwise operations, and add axioms like (0 & n = 0)
cpa.predicate.useBitwiseAxioms = false

# add special information to formulas about non-deterministic functions
cpa.predicate.useNondetFlags = false

# Abstract environmental transitions using their own predicates:0 - don't
# abstract, 1 - abstract filter, 2 - abstract filter and operation.
cpa.relyguarantee.abstractEnvTransitions = 1

# get an initial set of predicates from a file in MSAT format
cpa.relyguarantee.abstraction.initialPredicates0 = 
cpa.relyguarantee.abstraction.initialPredicates1 = 

# which solver to use?
cpa.relyguarantee.abstraction.solver = "MATHSAT"
  allowed values: [MATHSAT, YICES]

# only use the atoms from the interpolants as predicates, and not the whole
# interpolant
cpa.relyguarantee.atomicPredicates = true

# maximum number of atoms in a path formula before abstraction is forced
# (non-negative number, special values: 0 = don't check threshold, 1 = SBE)
cpa.relyguarantee.blk.atomThreshold = 0

# force abstractions on function call/return
cpa.relyguarantee.blk.functions = true

# force abstractions for each loop iteration
cpa.relyguarantee.blk.loops = true

# require that both the threshold and (functions or loops) have to be
# fulfilled to compute an abstraction
cpa.relyguarantee.blk.requireThresholdAndLBE = false

# maximum blocksize before abstraction is forced
# (non-negative number, special values: 0 = don't check threshold, 1 = SBE)
cpa.relyguarantee.blk.threshold = 0

# use caching of path formulas
cpa.relyguarantee.blk.useCache = true

# always check satisfiability at end of block, even if precision is empty
cpa.relyguarantee.checkBlockFeasibility = true

# Combine all valid environmental edges for thread in two one edge?
cpa.relyguarantee.combineEnvEdges = false

# Print debugging info?
cpa.relyguarantee.debug = true
cpa.relyguarantee.debug = true
cpa.relyguarantee.debug = false
cpa.relyguarantee.debug = true

# export one satisfying assignment for the error path
cpa.relyguarantee.errorPath.export = true
cpa.relyguarantee.errorPath.file = "ErrorPathAssignment.txt"

# List of variables global to multiple threads
cpa.relyguarantee.globalVariables = {}

# which interpolating solver to use for interpolant generation?
cpa.relyguarantee.interpolatingProver = "MATHSAT"
  allowed values: [MATHSAT, CSISAT]

# try second interpolating solver if the first takes too long
cpa.relyguarantee.interpolation.changesolverontimeout = false

# export final predicate map, if the error location is not reached
cpa.relyguarantee.predmap.export = true
cpa.relyguarantee.predmap.file = "predmap.txt"

# refinement will add all discovered predicates to all the locations in the
# abstract trace
cpa.relyguarantee.refinement.addPredicatesGlobally = true
cpa.relyguarantee.refinement.addPredicatesGlobally = false

# If true, the analysis continues in the previous thread. If false, the first
# thread is analysed first.
cpa.relyguarantee.refinement.continueThread = false

# Dump a DAG representation of interpolation formulas to the choosen file.
cpa.relyguarantee.refinement.dumpDAGfile = "test/output/itpDAG"

# which interpolating solver to use for interpolant generation?
cpa.relyguarantee.refinement.interpolatingProver = "MATHSAT"
  allowed values: [MATHSAT, CSISAT]

# Detect and skip interpolation branches that don't give new predicates.
cpa.relyguarantee.refinement.itpEnvSkip = false

# where to dump the counterexample formula in case the error location is
# reached
cpa.relyguarantee.refinement.msatCexFile = "counterexample.msat"

# How to refine the counterexample DAG: 0 - unfoald to a tree, 1 - insert
# env. edges
cpa.relyguarantee.refinement.refinementMethod = 0

# restart analysis after refinement
cpa.relyguarantee.refinement.restartAnalysis = false

# split arithmetic equalities when extracting predicates from interpolants
cpa.relyguarantee.refinement.splitItpAtoms = false

# maximum blocksize before a satisfiability check is done
# (non-negative number, 0 means never, if positive should be smaller than
# blocksize)
cpa.relyguarantee.satCheck = 0

# Use a theorem prover to remove covered environemtal transitions if false
# perform only a syntatic check for equivalence
# whether to include the symbolic path formula in the coverage checks or do
# only the fast abstract checks
cpa.relyguarantee.symbolicCoverageCheck = true
cpa.relyguarantee.symbolicCoverageCheck = false

# check satisfiability when a target state has been found (should be true)
cpa.relyguarantee.targetStateSatCheck = true

# which merge operator to use for UninitializedVariablesCPA?
cpa.uninitvars.merge = "sep"
  allowed values: [sep, join]

# print warnings during analysis when uninitialized variables are used
cpa.uninitvars.printWarnings = "true"

# which stop operator to use for UninitializedVariablesCPA?
cpa.uninitvars.stop = "sep"
  allowed values: [sep, join]

# Possible log levels in descending order 
# (lower levels include higher ones):
# OFF:      no logs published
# SEVERE:   error messages
# WARNING:  warnings
# INFO:     messages
# FINE:     logs on main application level
# FINER:    logs on central CPA algorithm level
# FINEST:   logs published by specific CPAs
# ALL:      debugging information
# Care must be taken with levels of FINER or lower, as output files may
# become quite large and memory usage might become an issue.

# single levels to be excluded from being logged
log.consoleExclude = {}

# log level of console output
log.consoleLevel = "INFO"
  allowed values: [OFF, SEVERE, WARNING, INFO, FINE, FINER, FINEST, ALL]

# name of the log file
log.file = "CPALog.txt"

# single levels to be excluded from being logged
log.fileExclude = {}

# log level of file output
log.level = "OFF"
  allowed values: [OFF, SEVERE, WARNING, INFO, FINE, FINER, FINEST, ALL]

# maximum size of log output strings before they will be truncated
log.truncateSize = 10000

# all used options are printed
log.usedOptions.export = false

# variables whose name contains this will be seen by InterpreterCPA as having
# non-deterministic values
# variables whose name contains this will be seen by ExplicitCPA as having
# non-deterministic values
noAutoInitPrefix = "__BLAST_NONDET"

# disable all default output files
# (any explicitly given file will still be written)
output.disable = false

# directory to put all output files in
output.path = "test/output/"

# C dialect for parser
parser.dialect = GNUC
  enum:     [C99, GNUC]

# Ignore all casts that appear in the source code.
parser.ignoreCasts = false

# print reached set to text file
reachedSet.export = true
reachedSet.file = "reached.txt"

# base directory for all input & output files
# (except for the configuration file itself)
rootDirectory = "."

# file with a specification that should be checked
# (see test/config/automata/ for examples)
specification = 

# write some statistics to disk
statistics.export = true
statistics.file = "Statistics.txt"

# track memory usage of JVM during runtime
statistics.memory = true

