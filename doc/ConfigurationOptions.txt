# This is an auto-generated file, DO NOT EDIT!
# Run ant to generate it.

# This file is part of CPAchecker,
# a tool for configurable software verification:
# https://cpachecker.sosy-lab.org
#
# SPDX-FileCopyrightText: 2007-2020 Dirk Beyer <https://www.sosy-lab.org>
#
# SPDX-License-Identifier: Apache-2.0

# Possible log levels in descending order 
# (lower levels include higher ones):
# OFF:      no logs published
# SEVERE:   error messages
# WARNING:  warnings
# INFO:     messages
# FINE:     logs on main application level
# FINER:    logs on central CPA algorithm level
# FINEST:   logs published by specific CPAs
# ALL:      debugging information
# Care must be taken with levels of FINER or lower, as output files may
# become quite large and memory usage might become an issue.

# single levels to be excluded from being logged
log.consoleExclude = []

# log level of console output
log.consoleLevel = Level.INFO

# name of the log file
log.file = "CPALog.txt"

# single levels to be excluded from being logged
log.fileExclude = []

# log level of file output
log.level = Level.OFF

# Maximum size of log output strings before they will be truncated. Note that
# truncation is not precise and truncation to small values has no effect. Use
# 0 for disabling truncation completely.
log.truncateSize = 10000

# use colors for log messages on console
log.useColors = true

# disable all default output files
# (any explicitly given file will still be written)
output.disable = false

# directory to put all output files in
output.path = "output/"

# base directory for all paths in default values
rootDirectory = "."

# SPDX-FileCopyrightText: 2020 Dirk Beyer <https://www.sosy-lab.org>
#
# SPDX-License-Identifier: Apache-2.0

# Further options for Boolector in addition to the default options. Format: 
# "Optionname=value" with ’,’ to seperate options. Optionname and value can
# be found in BtorOption or Boolector C Api.Example:
# "BTOR_OPT_MODEL_GEN=2,BTOR_OPT_INCREMENTAL=1".
solver.boolector.furtherOptions = ""

# The SAT solver used by Boolector.
solver.boolector.satSolver = CADICAL
  enum:     [LINGELING, PICOSAT, MINISAT, CMS, CADICAL]

# Counts all operations and interactions towards the SMT solver.
solver.collectStatistics = false

# Default rounding mode for floating point operations.
solver.floatingPointRoundingMode = NEAREST_TIES_TO_EVEN
  enum:     [NEAREST_TIES_TO_EVEN, NEAREST_TIES_AWAY, TOWARD_POSITIVE, TOWARD_NEGATIVE,
             TOWARD_ZERO]

# Export solver queries in SmtLib format into a file.
solver.logAllQueries = false
solver.logfile = no default value

# Further options that will be passed to Mathsat in addition to the default
# options. Format is 'key1=value1,key2=value2'
solver.mathsat5.furtherOptions = ""

# Load less stable optimizing version of mathsat5 solver.
solver.mathsat5.loadOptimathsat5 = false

# Use non-linear arithmetic of the solver if supported and throw exception
# otherwise, approximate non-linear arithmetic with UFs if unsupported, or
# always approximate non-linear arithmetic. This affects only the theories of
# integer and rational arithmetic.
solver.nonLinearArithmetic = USE
  enum:     [USE, APPROXIMATE_FALLBACK, APPROXIMATE_ALWAYS]

# Enable additional assertion checks within Princess. The main usage is
# debugging. This option can cause a performance overhead.
solver.princess.enableAssertions = false

# log all queries as Princess-specific Scala code
solver.princess.logAllQueriesAsScala = false

# file for Princess-specific dump of queries as Scala code
solver.princess.logAllQueriesAsScalaFile = "princess-query-%03d-"

# The number of atoms a term has to have before it gets abbreviated if there
# are more identical terms.
solver.princess.minAtomsForAbbreviation = 100

# Random seed for SMT solver.
solver.randomSeed = 42

# If logging from the same application, avoid conflicting logfile names.
solver.renameLogfileToAvoidConflicts = true

# Double check generated results like interpolants and models whether they
# are correct
solver.smtinterpol.checkResults = false

# Further options that will be set to true for SMTInterpol in addition to the
# default options. Format is 'option1,option2,option3'
solver.smtinterpol.furtherOptions = []

# Which SMT solver to use.
solver.solver = SMTINTERPOL
  enum:     [MATHSAT5, SMTINTERPOL, Z3, PRINCESS, BOOLECTOR, CVC4, CVC5, YICES2]

# Sequentialize all solver actions to allow concurrent access!
solver.synchronize = false

# Use provers from a seperate context to solve queries. This allows more
# parallelity when solving larger queries.
solver.synchronized.useSeperateProvers = false

# Log solver actions, this may be slow!
solver.useLogger = false

# Activate replayable logging in Z3. The log can be given as an input to the
# solver and replayed.
solver.z3.log = no default value

# Ordering for objectives in the optimization context
solver.z3.objectivePrioritizationMode = "box"
  allowed values: [lex, pareto, box]

# Engine to use for the optimization
solver.z3.optimizationEngine = "basic"
  allowed values: [basic, farkas, symba]

# Require proofs from SMT solver
solver.z3.requireProofs = false

# Whether to use PhantomReferences for discarding Z3 AST
solver.z3.usePhantomReferences = false


# Refiner that SlicingDelegatingRefiner should delegate to
SlicingDelegatingRefiner.refiner = no default value

# maximum number of condition adjustments (-1 for infinite)
adjustableconditions.adjustmentLimit = no default value

# number of threads, positive values match exactly, with -1 we use the number
# of available cores or the machine automatically.
algorithm.parallelBam.numberOfThreads = no default value

# export number of running RSE instances as CSV
algorithm.parallelBam.runningRSESeriesFile = no default value

# use a BMC like algorithm that checks for satisfiability after the analysis
# has finished, works only with PredicateCPA
analysis.algorithm.BMC = no default value

# use CEGAR algorithm for lazy counter-example guided analysis
# You need to specify a refiner with the cegar.refiner option.
# Currently all refiner require the use of the ARGCPA.
analysis.algorithm.CEGAR = no default value

# use dual approximated reachability model checking algorithm, works only
# with PredicateCPA and large-block encoding
analysis.algorithm.DAR = no default value

# use McMillan's interpolation-based model checking algorithm, works only
# with PredicateCPA and large-block encoding
analysis.algorithm.IMC = no default value

# Use MPI for running analyses in new subprocesses. The resulting reachedset
# is the one of the first analysis returning in time. All other mpi-processes
# will get aborted.
analysis.algorithm.MPI = no default value

# use MPV algorithm for checking multiple properties
analysis.algorithm.MPV = no default value

# use a analysis which proves if the program satisfies a specified property
# with the help of an enabler CPA to separate differnt program paths
analysis.algorithm.analysisWithEnabler = no default value

# use adjustable conditions algorithm
analysis.algorithm.conditionAdjustment = no default value

# Distribute predicate analysis to multiple workers
analysis.algorithm.configurableComponents = no default value

# for found property violation, perform fault localization with coverage
analysis.algorithm.faultLocalization.by_coverage = no default value

# Use fault localization with distance metrics
analysis.algorithm.faultLocalization.by_distance = no default value

# for found property violation, perform fault localization with trace
# formulas
analysis.algorithm.faultLocalization.by_traceformula = no default value

# Use McMillan's Impact algorithm for lazy interpolation
analysis.algorithm.impact = no default value

# Import faults stored in a JSON format.
analysis.algorithm.importFaults = no default value

# use nontermination witness validator to check a violation witness for
# termination
analysis.algorithm.nonterminationWitnessCheck = no default value

# use PDR algorithm
analysis.algorithm.pdr = no default value

# use a proof check algorithm to validate a previously generated proof
analysis.algorithm.proofCheck = no default value

# use a proof check algorithm to validate a previously generated proofand
# extract requirements on a (reconfigurable) HW from the proof
analysis.algorithm.proofCheckAndGetHWRequirements = no default value

# use a proof check algorithm to validate a previously generated proofand
# read the configuration for checking from the proof
analysis.algorithm.proofCheckReadConfig = no default value

# use a proof check algorithm that using pcc.strategy=arg.ARG_CMCStrategy to
# validate a previously generated proof
analysis.algorithm.proofCheckWithARGCMCStrategy = no default value

# do analysis and then check if reached set fulfills property specified by
# ConfigurableProgramAnalysisWithPropertyChecker
analysis.algorithm.propertyCheck = no default value

# Use termination algorithm to prove (non-)termination. This needs the
# TerminationCPA as root CPA and an automaton CPA with
# termination_as_reach.spc in the tree of CPAs.
analysis.algorithm.termination = no default value

# collect undefined functions
analysis.algorithm.undefinedFunctionCollector = no default value

# run the parallel BAM algortihm.
analysis.algorithm.useParallelBAM = no default value

# If not already done by the analysis, store a found counterexample in the
# ARG for later re-use. Does nothing if no ARGCPA is used
analysis.alwaysStoreCounterexamples = no default value

# Construct a residual program from condition and verify residual program
analysis.asConditionalVerifier = no default value

# use a second model checking run (e.g., with CBMC or a different CPAchecker
# configuration) to double-check counter-examples
analysis.checkCounterexamples = no default value

# use counterexample check and the BDDCPA Restriction option
analysis.checkCounterexamplesWithBDDCPARestriction = no default value

# do analysis and then check analysis result
analysis.checkProof = no default value

# use assumption collecting algorithm
analysis.collectAssumptions = no default value

# Construct the program slice for the given configuration.
analysis.constructProgramSlice = no default value

# Solely construct the residual program for a given condition/assumption.
analysis.constructResidualProgram = no default value

# continue analysis after a unsupported code was found on one path
analysis.continueAfterUnsupportedCode = no default value

# Maximum number of counterexamples to be created.
analysis.counterexampleLimit = no default value

# stop CPAchecker after startup (internal option, not intended for users)
analysis.disable = no default value

# entry function
analysis.entryFunction = no default value

# do analysis and then extract pre- and post conditions for custom
# instruction from analysis result
analysis.extractRequirements.customInstruction = no default value

# create all potential function pointer call edges
analysis.functionPointerCalls = no default value

# Create edge for skipping a function pointer call if its value is unknown.
analysis.functionPointerEdgesForUnknownPointer = no default value

# potential targets for call edges created for function pointer parameter
# calls
analysis.functionPointerParameterTargets = no default value

# potential targets for call edges created for function pointer calls
analysis.functionPointerTargets = no default value

# What CFA nodes should be the starting point of the analysis?
analysis.initialStatesFor = no default value

# run interprocedural analysis
analysis.interprocedural = no default value

# the machine model, which determines the sizes of types like int:
# - LINUX32: ILP32 for Linux on 32-bit x86
# - LINUX64: LP64 for Linux on 64-bit x86
# - ARM: ILP32 for Linux on 32-bit ARM
# - ARM64: LP64 for Linux on 64-bit ARM
analysis.machineModel = no default value
  enum:     [LINUX32, LINUX64, ARM, ARM64]

# Use as targets for call edges only those shich are assigned to the
# particular expression (structure field).
analysis.matchAssignedFunctionPointers = no default value

# If a no target function was assigned to a function pointer, use the origin
# heuristic instead of replacing with empty calls
analysis.matchAssignedFunctionPointers.ignoreUnknownAssignments = no default value

# memorize previously used (incomplete) reached sets after a restart of the
# analysis
analysis.memorizeReachedAfterRestart = no default value

# Name of the used analysis, defaults to the name of the used configuration
analysis.name = no default value

# Partition the initial states based on the type of location they were
# created for (see 'initialStatesFor')
analysis.partitionInitialStates = no default value

# A String, denoting the programs to be analyzed
analysis.programNames = no default value

# which reached set implementation to use?
# NORMAL: just a simple set
# LOCATIONMAPPED: a different set per location (faster, states with different
# locations cannot be merged)
# PARTITIONED: partitioning depending on CPAs (e.g Location, Callstack etc.)
# PSEUDOPARTITIONED: based on PARTITIONED, uses additional info about the
# states' lattice (maybe faster for some special analyses which use merge_sep
# and stop_sep
analysis.reachedSet = no default value
  enum:     [NORMAL, LOCATIONMAPPED, PARTITIONED, PSEUDOPARTITIONED, USAGE]

# track more statistics about the reachedset
analysis.reachedSet.withStatistics = no default value

# Use if you are going to change function with function pionter parameter
analysis.replaceFunctionWithParameterPointer = no default value

# Functions with function pointer parameter which will be instrumented
analysis.replacedFunctionsWithParameters = no default value

# restart the analysis using a different configuration after unknown result
analysis.restartAfterUnknown = no default value

# Use heuristics to select the analysis
analysis.selectAnalysisHeuristically = no default value

# Split program in subprograms which can be analyzed separately afterwards
analysis.split.program = no default value

# stop after the first error has been found
analysis.stopAfterError = no default value

# create summary call statement edges
analysis.summaryEdges = no default value

# Enable converting test goals to conditions.
analysis.testGoalConverter = no default value

# Replace thread creation operations with a special function callsso, any
# analysis can go through the function
analysis.threadOperationsTransform = no default value

# Patterns for detecting block starts (ldv_ like functions)
analysis.traversal.blockFunctionPatterns = no default value

# resource limit for the block
analysis.traversal.blockResourceLimit = no default value

# save resources for the block if it is empty
analysis.traversal.blockSaveResources = no default value

# traverse in the order defined by the values of an automaton variable
analysis.traversal.byAutomatonVariable = no default value

# resource limit for the entry block
analysis.traversal.entryResourceLimit = no default value

# which strategy to adopt for visiting states?
analysis.traversal.order = no default value
  enum:     [DFS, BFS, RAND, RANDOM_PATH, ROUND_ROBIN]

# Exponent of random function.This value influences the probability
# distribution over the waitlist elementswhen choosing the next element.Has
# to be a double in the range [0, INF)
analysis.traversal.random.exponent = no default value

# Seed for random values.
analysis.traversal.random.seed = no default value

# handle abstract states with more automaton matches first? (only if
# AutomatonCPA enabled)
analysis.traversal.useAutomatonInformation = no default value

# use blocks and set resource limits for its traversal, blocks are handled in
# DFS order
analysis.traversal.useBlocks = no default value

# handle states with a deeper callstack first
# This needs the CallstackCPA instance to have any effect.
analysis.traversal.useCallstack = no default value

# handle more abstract states (with less information) first? (only for
# ExplicitCPA)
analysis.traversal.useExplicitInformation = no default value

# handle states with more loop iterations first.
analysis.traversal.useLoopIterationCount = no default value

# handle states with a deeper loopstack first.
analysis.traversal.useLoopstack = no default value

# handle abstract states with fewer heap objects first? (needs SMGCPA)
analysis.traversal.useNumberOfHeapObjects = no default value

# handle abstract states with fewer running threads first? (needs
# ThreadingCPA)
analysis.traversal.useNumberOfThreads = no default value

# Use an implementation of postorder strategy that allows to select a
# secondary strategy that is used if there are two states with the same
# postorder id. The secondary strategy is selected with
# 'analysis.traversal.order'.
analysis.traversal.usePostorder = no default value

# handle states with fewer loop iterations first.
analysis.traversal.useReverseLoopIterationCount = no default value

# handle states with a more shallow loopstack first.
analysis.traversal.useReverseLoopstack = no default value

# Use an implementation of reverse postorder strategy that allows to select a
# secondary strategy that is used if there are two states with the same
# reverse postorder id. The secondary strategy is selected with
# 'analysis.traversal.order'.
analysis.traversal.useReversePostorder = no default value

# perform a weighted random selection based on the branching depth
analysis.traversal.weightedBranches = no default value

# perform a weighted random selection based on the depth in the ARG
analysis.traversal.weightedDepth = no default value

# After an incomplete analysis constructs a residual program which contains
# all program paths which are not fully explored
analysis.unexploredPathsAsProgram = no default value

# Do not report unknown if analysis terminated, report true (UNSOUND!).
analysis.unknownAsTrue = no default value

# stop the analysis with the result unknown if the program does not satisfies
# certain restrictions.
analysis.unknownIfUnrestrictedProgram = no default value

# Use array abstraction by program transformation.
analysis.useArrayAbstraction = no default value

# select an analysis from a set of analyses after unknown result
analysis.useCompositionAnalysis = no default value

# add declarations for global variables before entry function
analysis.useGlobalVars = no default value

# add loop-structure information to CFA.
analysis.useLoopStructure = no default value

# Use analyses parallely. The resulting reachedset is the one of the first
# analysis finishing in time. All other analyses are terminated.
analysis.useParallelAnalyses = no default value

# generate random test cases
analysis.useRandomTestCaseGeneratorAlgorithm = no default value

# generate test cases for covered test targets
analysis.useTestCaseGeneratorAlgorithm = no default value

# converts a witness to an ACSL annotated program
analysis.useWitnessToACSLAlgorithm = no default value

# Whether to allow imprecise array abstraction that may lead to false alarms.
arrayAbstraction.allowImprecision = no default value

# Whether to export the CFA with abstracted arrays as C source file.
arrayAbstraction.cfa.c.export = no default value

# C source file path for CFA with abstracted arrays.
arrayAbstraction.cfa.c.file = no default value

# Whether to export the CFA with abstracted arrays as DOT file.
arrayAbstraction.cfa.dot.export = no default value

# DOT file path for CFA with abstracted arrays.
arrayAbstraction.cfa.dot.file = no default value

# Use a second delegate analysis run to check counterexamples on the original
# program that contains (non-abstracted) arrays for imprecise array
# abstractions.
arrayAbstraction.checkCounterexamples = no default value

# Configuration file path of the delegate analysis running on the transformed
# program.
arrayAbstraction.delegateAnalysis = no default value

# Add a threshold to the automaton, after so many branches on a path the
# automaton will be ignored (0 to disable)
assumptions.automatonBranchingThreshold = no default value

# write collected assumptions as automaton to file
assumptions.automatonFile = no default value

# If it is enabled, automaton does not add assumption which is considered to
# continue path with corresponding this edge.
assumptions.automatonIgnoreAssumptions = no default value

# If it is enabled, automaton adds transitions to later ARG states first
assumptions.automatonOrderedTransitions = no default value

# compress the produced assumption automaton using GZIP compression.
assumptions.compressAutomaton = no default value

# export assumptions as automaton to dot file
assumptions.dotExport = no default value

# write collected assumptions as automaton to dot file
assumptions.dotFile = no default value

# write collected assumptions to file
assumptions.export = no default value

# export assumptions collected per location
assumptions.export.location = no default value

# write collected assumptions to file
assumptions.file = no default value

# If it is enabled, check if a state that should lead to false state indeed
# has successors.
assumptions.removeNonExploredWithoutSuccessors = no default value

# comma-separated list of files with specifications that should be used 
# in a backwards analysis; used if the analysis starts at the target states!
# (see config/specification/ for examples)
backwardSpecification = no default value

# Count accesses for the BDD library. Counting works for concurrent accesses.
bdd.countLibraryAccess = no default value

# Size of the BDD cache in relation to the node table size (set to 0 to use
# fixed BDD cache size).
bdd.javabdd.cacheRatio = no default value

# Initial size of the BDD cache, use 0 for cacheRatio*initTableSize.
bdd.javabdd.cacheSize = no default value

# Initial size of the BDD node table in percentage of available Java heap
# memory (only used if initTableSize is 0).
bdd.javabdd.initTableRatio = no default value

# Initial size of the BDD node table, use 0 for size based on initTableRatio.
bdd.javabdd.initTableSize = no default value

# Measure the time spent in the BDD library. The behaviour in case of
# concurrent accesses is undefined!
bdd.measureLibraryAccess = no default value

# Which BDD package should be used?
# - java:   JavaBDD (default, no dependencies, many features)
# - sylvan: Sylvan (only 64bit Linux, uses multiple threads)
# - cudd:   CUDD (native library required, reordering not supported)
# - micro:  MicroFactory (maximum number of BDD variables is 1024, slow, but
# less memory-comsumption)
# - buddy:  Buddy (native library required)
# - cal:    CAL (native library required)
# - jdd:    JDD
# - pjbdd:  A java native parallel bdd framework
bdd.package = no default value
  allowed values: [JAVA, SYLVAN, CUDD, MICRO, BUDDY, CAL, JDD, PJBDD]

# Size of the BDD cache in relation to the node table size (set to 0 to use
# fixed BDD cache size).
bdd.pjbdd.cacheRatio = no default value

# size of the BDD cache.
bdd.pjbdd.cacheSize = no default value

# Disable thread safe bdd operations.
bdd.pjbdd.disableThreadSafety = no default value

# increase factor for resizing tables
bdd.pjbdd.increaseFactor = no default value

# Initial size of the BDD node table in percentage of available Java heap
# memory (only used if initTableSize is 0).
bdd.pjbdd.initTableRatio = no default value

# Initial size of the BDD node table, use 0 for size based on initTableRatio.
bdd.pjbdd.initTableSize = no default value

# unique table's concurrency factor
bdd.pjbdd.tableParallelism = no default value

# Number of worker threads, Runtime.getRuntime().availableProcessors()
# default
bdd.pjbdd.threads = no default value

# Use bdd chaining.
bdd.pjbdd.useChainedBDD = no default value

# Use internal a int based bdd representation.
bdd.pjbdd.useInts = no default value

# initial variable count
bdd.pjbdd.varCount = no default value

# Granularity of the Sylvan BDD operations cache (recommended values 4-8).
bdd.sylvan.cacheGranularity = no default value

# Log2 size of the BDD cache.
bdd.sylvan.cacheSize = no default value

# Log2 size of the BDD node table.
bdd.sylvan.tableSize = no default value

# Number of worker threads, 0 for automatic.
bdd.sylvan.threads = no default value

# sequentialize all accesses to the BDD library.
bdd.synchronizeLibraryAccess = no default value

# output file for visualizing the block graph
blockCFAFile = no default value

# Allow reduction of function entries; calculate abstractions always at
# function entries?
blockreducer.allowReduceFunctionEntries = no default value

# Allow reduction of function exits; calculate abstractions always at
# function exits?
blockreducer.allowReduceFunctionExits = no default value

# Allow reduction of loop heads; calculate abstractions always at loop heads?
blockreducer.allowReduceLoopHeads = no default value

# write the reduced cfa to the specified file.
blockreducer.reducedCfaFile = no default value

# Do at most n summarizations on a node.
blockreducer.reductionThreshold = no default value

# If BMC did not find a bug, check whether the bounding did actually remove
# parts of the state space (this is similar to CBMC's unwinding assertions).
bmc.boundingAssertions = no default value

# If BMC did not find a bug, check which parts of the boundary actually
# reachableand prevent them from being unrolled any further.
bmc.boundingAssertionsSlicing = no default value

# Check reachability of target states after analysis (classical BMC). The
# alternative is to check the reachability as soon as the target states are
# discovered, which is done if cpa.predicate.targetStateSatCheck=true.
bmc.checkTargetStates = no default value

# try using induction to verify programs with loops
bmc.induction = no default value

# Strategy for generating auxiliary invariants
bmc.invariantGenerationStrategy = no default value
  enum:     [INDUCTION, REACHED_SET, DO_NOTHING]

# k-induction configuration to be used as an invariant generator for
# k-induction (ki-ki(-ai)).
bmc.invariantGeneratorConfig = no default value

# Controls how long the invariant generator is allowed to run before the
# k-induction procedure starts.
bmc.invariantGeneratorHeadStartStrategy = no default value
  enum:     [NONE, AWAIT_TERMINATION, WAIT_UNTIL_EXPENSIVE_ADJUSTMENT]

# Export auxiliary invariants used for induction.
bmc.invariantsExport = no default value

# get candidate invariants from a predicate precision file
bmc.kinduction.predicatePrecisionFile = no default value

# which strategy to use to convert predicate precision to k-induction
# invariant
bmc.kinduction.reuse.pred.strategy = no default value
  enum:     [ALL, GLOBAL, FUNCTION, LOCAL, GLOBAL_AND_FUNCTION, GLOBAL_AND_LOCAL,
             FUNCTION_AND_LOCAL]

# Propagates the interrupts of the invariant generator.
bmc.propagateInvGenInterrupts = no default value

# Try to simplify the structure of formulas for the sat check of BMC. The
# improvement depends on the underlying SMT solver.
bmc.simplifyBooleanFormula = no default value

# Use generalized counterexamples to induction as candidate invariants.
bmc.usePropertyDirection = no default value

# File name where to put the path program that is generated as input for
# CBMC. A temporary file is used if this is unspecified. If specified, the
# file name should end with '.i' because otherwise CBMC runs the
# pre-processor on the file.
cbmc.dumpCBMCfile = no default value

# maximum time limit for CBMC (use milliseconds or specify a unit; 0 for
# infinite)
cbmc.timelimit = no default value

# continue analysis after a failed refinement (e.g. due to interpolation)
# other paths may still contain errors that could be found
cegar.continueAfterFailedRefinement = no default value

# if this score is exceeded by the first analysis, the auxilliary analysis
# will be refined
cegar.domainScoreThreshold = no default value

# Whether to do refinement immediately after finding an error state, or
# globally after the ARG has been unrolled completely.
# whether or not global refinement is performed
cegar.globalRefinement = no default value

# Max number of refinement iterations, -1 for no limit
cegar.maxIterations = no default value

# Which refinement algorithm to use? (give class name, required for CEGAR) If
# the package name starts with 'org.sosy_lab.cpachecker.', this prefix can be
# omitted.
cegar.refiner = no default value

# whether or not to use refinement selection to decide which domain to refine
cegar.useRefinementSelection = no default value

# Which functions should be interpreted as encoding assumptions
cfa.assumeFunctions = no default value

# dump a simple call graph
cfa.callgraph.export = no default value

# file name for call graph as .dot file
cfa.callgraph.file = no default value
cfa.callgraph.fileUsed = no default value

# how often do we clone a function?
cfa.cfaCloner.numberOfCopies = no default value

# while this option is activated, before each use of a PointerExpression, or
# a dereferenced field access the expression is checked if it is 0
cfa.checkNullPointers = no default value

# Whether to have a single target node per function for all invalid null
# pointer dereferences or to have separate nodes for each dereference
cfa.checkNullPointers.singleTargetPerFunction = no default value

# When a function pointer array element is written with a variable as index,
# create a series of if-else edges with explicit indizes instead.
cfa.expandFunctionPointerArrayAssignments = no default value

# export CFA as .dot file
cfa.export = no default value

# export individual CFAs for function as .dot files
cfa.exportPerFunction = no default value

# export CFA as C file
cfa.exportToC = no default value
cfa.exportToC.file = no default value

# produce C programs more similar to the input program
# (only possible for a single input file)
cfa.exportToC.stayCloserToInput = no default value

# export CFA as .dot file
cfa.file = no default value

# By enabling this option the variables that are live are computed for each
# edge of the cfa. Live means that their value is read later on.
cfa.findLiveVariables = no default value

# how often can a function appear in the callstack as a clone of the original
# function?
cfa.functionCalls.recursionDepth = no default value

# Also initialize local variables with default values, or leave them
# uninitialized.
cfa.initializeAllVariables = no default value

# With this option, all declarations in each function will be movedto the
# beginning of each function. Do only use this option if you arenot able to
# handle initializer lists and designated initializers (like they can be used
# for arrays and structs) in your analysis anyway. this option will otherwise
# create c code which is not the same as the original one
cfa.moveDeclarationsToFunctionStart = no default value

# Which functions should be interpreted as never returning to their call site
cfa.nonReturningFunctions = no default value

# Export CFA as pixel graphic to the given file name. The suffix is added
# corresponding to the value of option pixelgraphic.export.formatIf set to
# 'null', no pixel graphic is exported.
cfa.pixelGraphicFile = no default value

# Show messages when dead code is encountered during parsing.
cfa.showDeadCode = no default value

# Remove all edges which don't have any effect on the program
cfa.simplifyCfa = no default value

# simplify simple const expressions like 1+2
cfa.simplifyConstExpressions = no default value

# simplify pointer expressions like s->f to (*s).f with this option the cfa
# is simplified until at maximum one pointer is allowed for left- and
# rightHandSide
cfa.simplifyPointerExpressions = no default value

# A name of thread_create function
cfa.threads.threadCreate = no default value

# A name of thread_join function
cfa.threads.threadJoin = no default value

# A name of thread_create_N function
cfa.threads.threadSelfCreate = no default value

# A name of thread_join_N function
cfa.threads.threadSelfJoin = no default value

# clone functions of the CFA, such that there are several identical CFAs for
# each function, only with different names.
cfa.useCFACloningForMultiThreadedPrograms = no default value

# unwind recursive functioncalls (bounded to max call stack size)
cfa.useFunctionCallUnwinding = no default value

# Dump domain type statistics to a CSV file.
cfa.variableClassification.domainTypeStatisticsFile = no default value

# Dump variable classification to a file.
cfa.variableClassification.logfile = no default value

# Print some information about the variable classification.
cfa.variableClassification.printStatsOnStartup = no default value

# Dump variable type mapping to a file.
cfa.variableClassification.typeMapFile = no default value

# Output an input file, with invariants embedded as assume constraints.
cinvariants.export = no default value

# File name for exporting invariants. Only supported if invariant export for
# specified lines is enabled.
cinvariants.external.file = no default value

# Specify lines for which an invariant should be written. Lines are specified
# as comma separated list of individual lines x and line ranges x-y.
cinvariants.forLines = no default value

# If enabled only export invariants for specified lines.
cinvariants.onlyForSpecifiedLines = no default value

# Prefix to add to an output file, which would contain assumed invariants.
cinvariants.prefix = no default value

# Attempt to simplify the invariant before exporting [may be very expensive].
cinvariants.simplify = no default value

# If adaptTimeLimits is set and all configurations support progress reports,
# in each cycle the time limits per configuration are newly calculated based
# on the progress
compositionAlgorithm.circular.adaptTimeLimits = no default value

# where to store initial condition, when generated
compositionAlgorithm.condition.file = no default value

# list of files with configurations to use, which are optionally suffixed
# according to one of the followig schemes:either ::MODE or ::MODE_LIMIT,
# where MODE and LIMIT are place holders.MODE may take one of the following
# values continue (i.e., continue analysis with same CPA and reached set),
# reuse-precision (i.e., reuse the aggregation of the precisions from the
# previous analysis run), noreuse (i.e., start from scratch).LIMIT is a
# positive integer number specifying the time limit of the analysis in each
# round.If no (correct) limit is given a default limit is used.
compositionAlgorithm.configFiles = no default value

# Whether or not to create an initial condition, that excludes no paths,
# before first analysis is run.Required when first analysis uses condition
# from conditional model checking
compositionAlgorithm.initCondition = no default value

# print the statistics of each component of the composition algorithm
# directly after the component's computation is finished
compositionAlgorithm.intermediateStatistics = no default value
  enum:     [EXECUTE, NONE, PRINT]

# Enable when composition algorithm is used to check a specification
compositionAlgorithm.propertyChecked = no default value

# Qualified name for class which implements strategy that decides how to
# compose given analyses
compositionAlgorithm.strategy = no default value

# let each analysis part of the composition algorithm write output files and
# not only the last one that is executed
compositionAlgorithm.writeIntermediateOutputFiles = no default value

# configuration of the residual program generator
conditional.verifier.generatorConfig = no default value

# configuration for the verification of the residual program which is
# constructed from another verifier's condition
conditional.verifier.verifierConfig = no default value

# The input file with all goals that were previously reached
conditional_testing.inputfile = no default value

# The strategy to use
conditional_testing.strategy = no default value
  enum:     [NAIVE, PROPAGATION]

# Dump the complete configuration to a file.
configuration.dumpFile = no default value

# True if the path to the error state can not always be uniquely determined
# from the ARG.
# This is the case e.g. for Slicing Abstractions, where the abstraction
# states in the ARG
# do not form a tree!
counterexample.ambigiousARG = no default value

# Which model checker to use for verifying counterexamples as a second check.
# Currently CBMC or CPAchecker with a different config or the concrete
# execution 
# checker can be used.
counterexample.checker = no default value
  enum:     [CBMC, CPACHECKER, CONCRETE_EXECUTION]

# counterexample information should provide more precise information from
# counterexample check, if available
counterexample.checker.changeCEXInfo = no default value

# configuration file for counterexample checks with CPAchecker
counterexample.checker.config = no default value

# counterexample check should fully replace existing counterexamples with own
# ones, if available
counterexample.checker.forceCEXChange = no default value

# File name where to put the path specification that is generated as input
# for the counterexample check. A temporary file is used if this is
# unspecified.
counterexample.checker.path.file = no default value

# The file in which the generated C code is saved.
counterexample.concrete.dumpFile = no default value

# Path to the compiler. Can be absolute or only the name of the program if it
# is in the PATH
counterexample.concrete.pathToCompiler = no default value

# Maximum time limit for the concrete execution checker.
# This limit is used for compilation as well as execution so overall, twice
# the time of this limit may be consumed.
# (use milliseconds or specify a unit; 0 for infinite)
counterexample.concrete.timelimit = no default value

# continue analysis after an counterexample was found that was denied by the
# second check
counterexample.continueAfterInfeasibleError = no default value

# An imprecise counterexample of the Predicate CPA is usually a bug, but
# expected in some configurations. Should it be treated as a bug or accepted?
counterexample.export.allowImpreciseCounterexamples = no default value

# Always use imprecise counterexamples of the predicate analysis. If this
# option is set to true, counterexamples generated by the predicate analysis
# will be exported as-is. This means that no information like variable
# assignments will be added and imprecise or potentially wrong program paths
# will be exported as counterexample.
counterexample.export.alwaysUseImpreciseCounterexamples = no default value

# If the option assumeLinearArithmetics is set, this option can be used to
# allow division and modulo by constants.
counterexample.export.assumptions.allowDivisionAndModuloByConstants = no default value

# If the option assumeLinearArithmetics is set, this option can be used to
# allow multiplication between operands with at least one constant.
counterexample.export.assumptions.allowMultiplicationWithConstants = no default value

# Try to avoid using operations that exceed the capabilities of linear
# arithmetics when extracting assumptions from the model. This option aims to
# prevent witnesses that are inconsistent with  models that are, due to an
# analysis limited to linear arithmetics, actually incorrect.
#  This option does not magically produce a correct witness from an incorrect
# model, and since the difference between an incorrect witness consistent
# with the model and an incorrect witness that is inconsistent with the model
# is academic, you usually want this option to be off.
counterexample.export.assumptions.assumeLinearArithmetics = no default value

# export counterexample as automaton
counterexample.export.automaton = no default value

# exports either CMBC format or a concrete path program
counterexample.export.codeStyle = no default value
  enum:     [CBMC, CONCRETE_EXECUTION]

# compress the produced error-witness automata using GZIP compression.
counterexample.export.compressWitness = no default value

# export counterexample core as text file
counterexample.export.core = no default value

# export counterexample to file, if one is found
counterexample.export.enabled = no default value

# export error paths to files immediately after they were found, including
# spurious error-paths before executing a refinement. Note that we do not
# track already exported error-paths and export them at every refinement as
# long as they are not removed from the reached-set. Most helpful for
# debugging refinements.
counterexample.export.exportAllFoundErrorPaths = no default value

# export counterexample as source file
counterexample.export.exportAsSource = no default value

# export coverage information for every witness: requires using an Assumption
# Automaton as part of the specification. Lines are considered to be covered
# only when the path reaching the statement does not reach the __FALSE state
# in the Assumption Automaton.
counterexample.export.exportCounterexampleCoverage = no default value

# Export extended witness in addition to regular witness
counterexample.export.exportExtendedWitness = no default value

# exports a JSON file describing found faults, if fault localization is
# activated
counterexample.export.exportFaults = no default value

# export test harness
counterexample.export.exportHarness = no default value

# export error paths to files immediately after they were found
counterexample.export.exportImmediately = no default value

# export test case that represents the counterexample. Further options can be
# set with options 'testcase.*'
counterexample.export.exportTestCase = no default value

# export counterexample as witness/graphml file
counterexample.export.exportWitness = no default value

# Extended witness with specific analysis information file
counterexample.export.extendedWitnessFile = no default value

# export counterexample as text file
counterexample.export.file = no default value

# Filter for irrelevant counterexamples to reduce the number of similar
# counterexamples reported. Only relevant with analysis.stopAfterError=false
# and counterexample.export.exportImmediately=true. Put the weakest and
# cheapest filter first, e.g., PathEqualityCounterexampleFilter.
counterexample.export.filters = no default value

# where to dump the counterexample formula in case a specification violation
# is found
counterexample.export.formula = no default value

# export counterexample as Dot/Graphviz visualization
counterexample.export.graph = no default value

# export counterexample witness as GraphML automaton
counterexample.export.graphml = no default value

# export test harness to file as code
counterexample.export.harness = no default value

# where to dump the counterexample model in case a specification violation is
# found
counterexample.export.model = no default value

# export counterexample coverage information, considering only spec prefix as
# covered (up until reaching __FALSE state in Assumption Automaton).
counterexample.export.prefixCoverageFile = no default value

# The files where the BDDCPARestrictionAlgorithm should write the presence
# conditions for the counterexamples to.
counterexample.export.presenceCondition = no default value

# File name for analysis report in case a counterexample was found.
counterexample.export.report = no default value

# export counterexample as source file
counterexample.export.source = no default value

# export counterexample witness as Dot/Graphviz visualization
counterexample.export.witnessGraph = no default value

# The template from which the different versions of the violation witnesses
# will be exported. Each version replaces the string '%s' with its version
# number. The string %d is replace with the number of the counterexample.
counterexample.export.yaml = no default value

# If continueAfterInfeasibleError is true, remove the error state that is
# proven to be unreachable before continuing. Set this to false if
# analyis.collectAssumptions=true is also set.
counterexample.removeInfeasibleErrorState = no default value

# If continueAfterInfeasibleError is true, attempt to remove the whole path
# of the infeasible counterexample before continuing. Setting this to false
# may prevent a lot of similar infeasible counterexamples to get discovered,
# but is unsound
counterexample.removeInfeasibleErrors = no default value

# If true, the counterexample checker will not assume a counterexample as
# infeasible because of unsupported code. But will try different paths
# anyway.
counterexample.skipCounterexampleForUnsupportedCode = no default value

# Compute and export information about the verification coverage?
coverage.enabled = no default value

# print coverage info to file
coverage.file = no default value

# CPA to use (see doc/Configuration.md for more documentation on this)
cpa = no default value

# Where to perform abstraction
cpa.abe.abstractionLocations = no default value
  enum:     [ALL, LOOPHEAD, MERGE]

# Check target states reachability
cpa.abe.checkTargetStates = no default value

# Cache formulas produced by path formula manager
cpa.abe.useCachingPathFormulaManager = no default value

# only store pure C expressions without ACSL-specific constructs
cpa.acsl.usePureExpressionsOnly = no default value

# Use this to change the underlying abstract domain in the APRON library
cpa.apron.domain = no default value
  enum:     [BOX, OCTAGON, POLKA, POLKA_STRICT, POLKA_EQ]

# get an initial precision from file
cpa.apron.initialPrecisionFile = no default value

# this option determines which initial precision should be used
cpa.apron.initialPrecisionType = no default value
  allowed values: [STATIC_FULL, REFINEABLE_EMPTY]

# with this option enabled the states are only merged at loop heads
cpa.apron.mergeop.onlyMergeAtLoopHeads = no default value

# of which type should the merge be?
cpa.apron.mergeop.type = no default value
  allowed values: [SEP, JOIN, WIDENING]

# target file to hold the exported precision
cpa.apron.precisionFile = no default value

# Timelimit for the backup feasibility check with the apron analysis.(use
# seconds or specify a unit; 0 for infinite)
cpa.apron.refiner.timeForApronFeasibilityCheck = no default value

# split disequalities considering integer operands into two states or use
# disequality provided by apron library 
cpa.apron.splitDisequalities = no default value

# translate final ARG into this C file
cpa.arg.CTranslation.file = no default value

# minimum ratio of branch compared to whole program to be exported
cpa.arg.automaton.branchRatio = no default value

# what data should be exported from the ARG nodes? A different strategy might
# result in a smaller automaton.
cpa.arg.automaton.dataStrategy = no default value
  enum:     [LOCATION, CALLSTACK]

# translate final ARG into an automaton
cpa.arg.automaton.export = no default value

# export as zip-files, depends on 'automaton.export=true'
cpa.arg.automaton.exportCompressed = no default value

# translate final ARG into an automaton, depends on 'automaton.export=true'
cpa.arg.automaton.exportDotFile = no default value
cpa.arg.automaton.exportSpcFile = no default value
cpa.arg.automaton.exportSpcZipFile = no default value

# export all automata into one zip-file, depends on 'automaton.export=true'
cpa.arg.automaton.exportZipped = no default value

# after determining branches, which one of them should be exported?
cpa.arg.automaton.selectionStrategy = no default value
  enum:     [NONE, ALL, LEAVES, WEIGHTED, FIRST_BFS]

# minimum ratio of siblings such that one of them will be exported
cpa.arg.automaton.siblingRatio = no default value

# when using FIRST_BFS, how many nodes should be skipped? ZERO will only
# export the root itself, MAX_INT will export only LEAFS.
cpa.arg.automaton.skipFirstNum = no default value

# which coarse strategy should be applied when analyzing the ARG?
cpa.arg.automaton.splitStrategy = no default value
  enum:     [NONE, GLOBAL_CONDITIONS, LEAVES, TARGETS]

# compress the produced correctness-witness automata using GZIP compression.
cpa.arg.compressWitness = no default value

# prevent the stop-operator from aborting the stop-check early when it
# crosses a target state
cpa.arg.coverTargetStates = no default value

# inform merge operator in CPA enabled analysis that it should delete the
# subgraph of the merged node which is required to get at most one successor
# per CFA edge.
cpa.arg.deleteInCPAEnabledAnalysis = no default value

# Dump all ARG related statistics files after each iteration of the CPA
# algorithm? (for debugging and demonstration)
cpa.arg.dumpAfterIteration = no default value

# Enable reduction for nested abstract states when entering or leaving a
# block abstraction for BAM. The reduction can lead to a higher
# cache-hit-rate for BAM and a faster sub-analysis for blocks.
cpa.arg.enableStateReduction = no default value

# export final ARG as .dot file
cpa.arg.export = no default value

# Enable the integration of __VERIFIER_assume statements for non-true
# assumption in states. Disable if you want to create residual programs.
cpa.arg.export.code.addAssumptions = no default value

# Only enable CLOSEFUNCTIONBLOCK if you are sure that the ARG merges
# different flows through a function at the end of the function.
cpa.arg.export.code.blockAtFunctionEnd = no default value
  enum:     [CLOSEFUNCTIONBLOCK, ADDNEWBLOCK, KEEPBLOCK]

# How to deal with target states during code generation
cpa.arg.export.code.handleTargetStates = no default value
  enum:     [NONE, RUNTIMEVERIFICATION, ASSERTFALSE, FRAMACPRAGMA, VERIFIERERROR,
             REACHASMEMSAFETY, REACHASOVERFLOW, REACHASTERMINATION]

# write include directives
cpa.arg.export.code.header = no default value

# If specified, metadata about the produced C program will be exported to
# this file
cpa.arg.export.code.metadataOutput = no default value

# when enabled also write invariant true to correctness-witness automata
cpa.arg.exportTrueInvariants = no default value

# export final ARG as .dot file
cpa.arg.file = no default value

# inform ARG CPA if it is run in an analysis with enabler CPA because then it
# must behave differently during merge.
cpa.arg.inCPAEnabledAnalysis = no default value

# whether to keep covered states in the reached set as addition to keeping
# them in the ARG
cpa.arg.keepCoveredStatesInReached = no default value

# What do to on a late merge, i.e., if the second parameter of the merge
# already has child states (cf. issue #991):
# - ALLOW: Just merge as usual.
# - ALLOW_WARN: Log a warning the first time this happens, then ALLOW.
# - PREVENT: Do not merge, i.e., enforce merge-sep for such situations.
# - PREVENT_WARN: Log a warning the first time this happens, then PREVENT.
# - CRASH: Crash CPAchecker as soon as this happens
#   (useful for cases where a late merge should never happen).
cpa.arg.lateMerge = no default value
  enum:     [ALLOW, ALLOW_WARN, PREVENT, PREVENT_WARN, CRASH]

# write the ARG at various stages during execution into dot files whose name
# is specified by this option. Only works if 'cpa.arg.logARGs=true'
cpa.arg.log.fileTemplate = no default value

# Enable logging of ARGs at various positions
cpa.arg.logARGs = no default value

# If this option is enabled, ARG states will also be merged if the first
# wrapped state is subsumed by the second wrapped state (and the parents are
# not yet subsumed).
cpa.arg.mergeOnWrappedSubsumption = no default value

# Export final ARG as pixel graphic to the given file name. The suffix is
# added  corresponding to the value of option pixelgraphic.export.formatIf
# set to 'null', no pixel graphic is exported.
cpa.arg.pixelGraphicFile = no default value

# export a proof as .graphml file
cpa.arg.proofWitness = no default value

# export a proof as dot/graphviz file
cpa.arg.proofWitness.dot = no default value

# export simplified ARG that shows all refinements to .dot file
cpa.arg.refinements.file = no default value

# export final ARG as .dot file, showing only loop heads and function
# entries/exits
cpa.arg.simplifiedARG.file = no default value

# translate final ARG into C program
cpa.arg.translateToC = no default value

# Verification witness: Include the considered case of an assume?
cpa.arg.witness.exportAssumeCaseInfo = no default value

# Verification witness: Include assumptions (C statements)?
cpa.arg.witness.exportAssumptions = no default value

# Verification witness: Include function calls and function returns?
cpa.arg.witness.exportFunctionCallsAndReturns = no default value

# Export invariants in correctness witness also if location was not explored
cpa.arg.witness.exportInvariantsForNonExploredStates = no default value

# Export witness that is a combination of multiple (partial) correctness
# witnesses, do not export default invariants
cpa.arg.witness.exportJointWitnesses = no default value

# Verification witness: Include the (starting) line numbers of the operations
# on the transitions?
cpa.arg.witness.exportLineNumbers = no default value

# Verification witness: Export labels for nodes in GraphML for easier visual
# representation?
cpa.arg.witness.exportNodeLabel = no default value

# Verification witness: Include the offset within the file?
cpa.arg.witness.exportOffset = no default value

# Always export source file name, even default
cpa.arg.witness.exportSourceFileName = no default value

# Verification witness: Include the sourcecode of the operations?
cpa.arg.witness.exportSourcecode = no default value

# Verification witness: Include an thread-identifier within the file?
cpa.arg.witness.exportThreadId = no default value

# Verification witness: Include (not necessarily globally unique) thread
# names for concurrent tasks for debugging?
cpa.arg.witness.exportThreadName = no default value

# Shrink ARG graph into a smaller witness graph by merging edges
cpa.arg.witness.minimizeARG = no default value

# Produce an invariant witness instead of a correctness witness. Constructing
# an invariant witness makes use of a different merge for quasi-invariants:
# Instead of computing the disjunction of two invariants present when merging
# nodes, 'true' is ignored when constructing the disjunction. This may be
# unsound in some situations, so be careful when using this option.
cpa.arg.witness.produceInvariantWitnesses = no default value

# Some redundant transitions will be removed
cpa.arg.witness.removeInsufficientEdges = no default value

# Verification witness: Revert escaping/renaming of functions for threads?
cpa.arg.witness.revertThreadFunctionRenaming = no default value

# The template from which the different versions of the correctness witnesses
# will be exported. Each version replaces the string '%s' with its version
# number.
cpa.arg.yamlProofWitness = no default value

# signal the analysis to break in case the given number of error state is
# reached. Use -1 to disable this limit.
cpa.automaton.breakOnTargetState = no default value

# export automaton to file
cpa.automaton.dotExport = no default value

# file for saving the automaton in DOT format (%s will be replaced with
# automaton name)
cpa.automaton.dotExportFile = no default value

# the maximum number of iterations performed after the initial error is
# found, despite the limit given as cpa.automaton.breakOnTargetState is not
# yet reached. Use -1 to disable this limit.
cpa.automaton.extraIterationsLimit = no default value

# file with automaton specification for ObserverAutomatonCPA and
# ControlAutomatonCPA
cpa.automaton.inputFile = no default value

# Merge two automata states if one of them is TOP.
cpa.automaton.mergeOnTop = no default value

# An implicit precision: consider states with a self-loop and no other
# outgoing edges as TOP.
cpa.automaton.prec.topOnFinalSelfLoopingState = no default value

# file for saving the automaton in spc format (%s will be replaced with
# automaton name)
cpa.automaton.spcExportFile = no default value

# Whether to treat automaton states with an internal error state as targets.
# This should be the standard use case.
cpa.automaton.treatErrorsAsTargets = no default value

# If enabled, cache queries also consider blocks with non-matching precision
# for reuse.
cpa.bam.aggressiveCaching = no default value

# export blocked ARG as .dot file
cpa.bam.argFile = no default value

# Type of partitioning (FunctionAndLoopPartitioning or
# DelayedFunctionAndLoopPartitioning)
# or any class that implements a PartitioningHeuristic
cpa.bam.blockHeuristic = no default value

# only consider functions with a matching name, i.e., select only some
# functions directly.
cpa.bam.blockHeuristic.functionPartitioning.matchFunctions = no default value

# only consider function with a minimum number of calls. This approach is
# similar to 'inlining' functions used only a few times. Info: If a function
# is called several times in a loop, we only count 'one' call.
cpa.bam.blockHeuristic.functionPartitioning.minFunctionCalls = no default value

# only consider function with a minimum number of CFA nodes. This approach is
# similar to 'inlining' small functions, when using BAM.
cpa.bam.blockHeuristic.functionPartitioning.minFunctionSize = no default value

# file for exporting detailed statistics about blocks
cpa.bam.blockStatisticsFile = no default value

# abort current analysis when finding a missing block abstraction
cpa.bam.breakForMissingBlock = no default value

# This flag determines which precisions should be updated during refinement.
# We can choose between the minimum number of states and all states that are
# necessary to re-explore the program along the error-path.
cpa.bam.doPrecisionRefinementForAllStates = no default value

# Heuristic: This flag determines which precisions should be updated during
# refinement. This flag also updates the precision of the most inner block.
cpa.bam.doPrecisionRefinementForMostInnerBlock = no default value

# export blocks
cpa.bam.exportBlocksPath = no default value

# If enabled, the reached set cache is analysed for each cache miss to find
# the cause of the miss.
cpa.bam.gatherCacheMissStatistics = no default value

# BAM allows to analyse recursive procedures. This strongly depends on the
# underlying CPA. The current support includes only ValueAnalysis and
# PredicateAnalysis (with tree interpolation enabled).
cpa.bam.handleRecursiveProcedures = no default value

# export single blocked ARG as .dot files, should contain '%d'
cpa.bam.indexedArgFile = no default value

# if we cannot determine a repeating/covering call-state, we will run into
# CallStackOverflowException. Thus we bound the stack size (unsound!). This
# option only limits non-covered recursion, but not a recursion where we find
# a coverage and re-use the cached block several times. The value '-1'
# disables this option.
cpa.bam.maximalDepthForExplicitRecursion = no default value

# By default, the CPA algorithm terminates when finding the first target
# state, which makes it easy to identify this last state. For special
# analyses, we need to search for more target states in the reached-set, when
# reaching a block-exit. This flag is needed if the option
# 'cpa.automaton.breakOnTargetState' is unequal to 1.
cpa.bam.searchTargetStatesOnExit = no default value

# export used parts of blocked ARG as .dot file
cpa.bam.simplifiedArgFile = no default value

# Should the nested CPA-algorithm be wrapped with CEGAR within BAM?
cpa.bam.useCEGAR = no default value

# This flag determines which refinement procedure we should use. We can
# choose between an in-place refinement and a copy-on-write refinement.
cpa.bam.useCopyOnWriteRefinement = no default value

# In some cases BAM cache can not be easily applied. If the option is enabled
# CPAs can inform BAM that the result states should not be used even if there
# will a cache hit.
cpa.bam.useDynamicAdjustment = no default value

# max bitsize for values and vars, initial value
cpa.bdd.bitsize = no default value

# use a smaller bitsize for all vars, that have only intEqual values
cpa.bdd.compressIntEqual = no default value

# add some additional variables (with prefix) for each variable that can be
# used for more complex BDD operations later. In the ordering, we declare
# them as narrow as possible to the original variable, such that the overhead
# for using them stays small. A value 0 disables this feature.
cpa.bdd.initAdditionalVariables = no default value

# declare the bits of a var from 0 to N or from N to 0
cpa.bdd.initBitsIncreasing = no default value

# declare first bit of all vars, then second bit,...
cpa.bdd.initBitwise = no default value

# declare vars partitionwise
cpa.bdd.initPartitions = no default value

# declare partitions ordered
cpa.bdd.initPartitionsOrdered = no default value

# Dump tracked variables to a file.
cpa.bdd.logfile = no default value

# mergeType
cpa.bdd.merge = no default value
  allowed values: [sep, join]

# reduce and expand BDD states for BAM, otherwise use plain identity
cpa.bdd.useBlockAbstraction = no default value

# Dump tracked variables to a file.
cpa.bdd.variablesFile = no default value

# depth of recursion bound
cpa.callstack.depth = no default value

# which abstract domain to use for callstack cpa, typically FLAT which is
# faster since it uses only object equivalence
cpa.callstack.domain = no default value
  allowed values: [FLAT, FLATPCC]

# whether DCPAs should ignore forward callstack
cpa.callstack.ignoreForwardCallstackTransfers = no default value

# Skip recursion if it happens only by going via a function pointer (this is
# unsound). Imprecise function pointer tracking often lead to false
# recursions.
cpa.callstack.skipFunctionPointerRecursion = no default value

# Skip recursion (this is unsound). Treat function call as a statement (the
# same as for functions without bodies)
cpa.callstack.skipRecursion = no default value

# Skip recursion if it happens only by going via a void function with no
# pointers passed as parameters. This is unsound if the function modifies
# global variables.
cpa.callstack.skipVoidRecursion = no default value

# analyse the CFA backwards
cpa.callstack.traverseBackwards = no default value

# Blacklist of extern functions that will make the analysis abort if called
cpa.callstack.unsupportedFunctions = no default value

# By enabling this option the CompositeTransferRelation will compute abstract
# successors for as many edges as possible in one call. For any chain of
# edges in the CFA which does not have more than one outgoing or leaving edge
# the components of the CompositeCPA are called for each of the edges in this
# chain. Strengthening is still computed after every edge. The main
# difference is that while this option is enabled not every ARGState may have
# a single edge connecting to the child/parent ARGState but it may instead be
# a list.
cpa.composite.aggregateBasicBlocks = no default value

# inform Composite CPA if it is run in a CPA enabled analysis because then it
# must behave differently during merge.
cpa.composite.inCPAEnabledAnalysis = no default value

# which composite merge operator to use (plain or agree)
# Both delegate to the component cpas, but agree only allows merging if all
# cpas agree on this. This is probably what you want.
cpa.composite.merge = no default value
  allowed values: [PLAIN, AGREE]

# Limit for Java heap memory used by CPAchecker (in MB, not MiB!; -1 for
# infinite)
cpa.conditions.global.memory.heap = no default value

# Limit for process memory used by CPAchecker (in MB, not MiB!; -1 for
# infinite)
cpa.conditions.global.memory.process = no default value

# Limit for size of reached set (-1 for infinite)
cpa.conditions.global.reached.size = no default value

# Limit for cpu time used by CPAchecker (use milliseconds or specify a unit;
# -1 for infinite)
cpa.conditions.global.time.cpu = no default value

# Hard limit for cpu time used by CPAchecker (use milliseconds or specify a
# unit; -1 for infinite)
# When using adjustable conditions, analysis will end after this threshold
cpa.conditions.global.time.cpu.hardlimit = no default value

# Limit for wall time used by CPAchecker (use milliseconds or specify a unit;
# -1 for infinite)
cpa.conditions.global.time.wall = no default value

# Hard limit for wall time used by CPAchecker (use milliseconds or specify a
# unit; -1 for infinite)
# When using adjustable conditions, analysis will end after this threshold
cpa.conditions.global.time.wall.hardlimit = no default value

# Number of times the path condition may be adjusted, i.e., the path
# condition threshold may be increased (-1 to always adjust)
cpa.conditions.path.adjustment.threshold = no default value

# determines if there should be one single assignment state per state, one
# per path segment between assume edges, or a global one for the whole
# program.
cpa.conditions.path.assignments.scope = no default value
  enum:     [STATE, PATH, PROGRAM]

# sets the threshold for assignments (-1 for infinite), and it is upto, e.g.,
# ValueAnalysisPrecisionAdjustment to act accordingly to this threshold
# value.
cpa.conditions.path.assignments.threshold = no default value

# maximum number of assume edges length (-1 for infinite)
cpa.conditions.path.assumeedges.limit = no default value

# The condition
cpa.conditions.path.condition = no default value

# maximum path length (-1 for infinite)
cpa.conditions.path.length.limit = no default value

# maximum repetitions of any edge in a path (-1 for infinite)
cpa.conditions.path.repetitions.limit = no default value

# Generate congruences for sums of variables (<=> x and y have same/different
# evenness)
cpa.congruence.trackCongruenceSum = no default value

# Cache formulas produced by path formula manager
cpa.congruence.useCachingPathFormulaManager = no default value

# Whether to perform caching of constraint satisfiability results
cpa.constraints.cache = no default value

# Whether to use subset caching
cpa.constraints.cacheSubsets = no default value

# Whether to use superset caching
cpa.constraints.cacheSupersets = no default value

# Type of less-or-equal operator to use
cpa.constraints.lessOrEqualType = no default value
  enum:     [SUBSET]

# Type of merge operator to use
cpa.constraints.mergeType = no default value
  enum:     [SEP, JOIN_FITTING_CONSTRAINT]

# Whether to perform SAT checks only for the last added constraint
cpa.constraints.minimalSatCheck = no default value

# enable if variables from value precision should be considered in variable's
# scope instead of scope specified in precision
cpa.constraints.refinement.applyInScope = no default value

# derive an initial constraint precision from value precision stored in this
# file
cpa.constraints.refinement.initialValuePrecisionFile = no default value

# enable to track constraints based on value precision only if all variables
# occurring in constraint are relevant in variable precision. If disabled it
# is sufficient that one variable is relevant.
cpa.constraints.refinement.mustTrackAll = no default value

# Type of precision to use. Has to be LOCATION if PredicateExtractionRefiner
# is used.
cpa.constraints.refinement.precisionType = no default value
  enum:     [CONSTRAINTS, LOCATION]

# Whether to remove constraints that can't add any more information
# toanalysis during simplification
cpa.constraints.removeOutdated = no default value

# Whether to remove trivial constraints from constraints states during
# simplification
cpa.constraints.removeTrivial = no default value

# Resolve definite assignments
cpa.constraints.resolveDefinites = no default value

# When to check the satisfiability of constraints
cpa.constraints.satCheckStrategy = no default value
  enum:     [AT_ASSUME, AT_TARGET]

# Export the trace-abtraction automaton to a file in dot-format.
cpa.dca.refiner.dotExport = no default value

# Filename that the interpolation automaton will be written to. %s will get
# replaced by the automaton name.
cpa.dca.refiner.dotExportFile = no default value

# The max amount of refinements for the trace abstraction algorithm. Setting
# it to 0 leads to an analysis of the ARG without executing any refinements.
# This is used for debugging purposes.
cpa.dca.refiner.maxRefinementIterations = no default value

# Skip the analysis (including the refinement) entirely, so that the ARG is
# left unmodified. This is used for debugging purposes.
cpa.dca.refiner.skipAnalysis = no default value

# which merge operator to use for DefUseCPA
cpa.defuse.merge = no default value
  allowed values: [sep, join]

# Which strategy to use for forced coverings (empty for none)
cpa.forcedCovering = no default value

# When an invalid function pointer is called, do not assume all functions as
# possible targets and instead call no function.
cpa.functionpointer.ignoreInvalidFunctionPointerCalls = no default value

# When an unknown function pointer is called, do not assume all functions as
# possible targets and instead call no function (this is unsound).
cpa.functionpointer.ignoreUnknownFunctionPointerCalls = no default value

# whether function pointers with invalid targets (e.g., 0) should be tracked
# in order to find calls to such pointers
cpa.functionpointer.trackInvalidFunctionPointers = no default value

# which type of merge operator to use for IntervalAnalysisCPA
cpa.interval.merge = no default value
  allowed values: [SEP, JOIN]

# decides whether one (false) or two (true) successors should be created when
# an inequality-check is encountered
cpa.interval.splitIntervals = no default value

# at most that many intervals will be tracked per variable, -1 if number not
# restricted
cpa.interval.threshold = no default value

# controls whether to use abstract evaluation always, never, or depending on
# entering edges.
cpa.invariants.abstractionStateFactory = no default value
  enum:     [ALWAYS, ENTERING_EDGES, NEVER]

# enables the over-approximation of unsupported features instead of failing
# fast; this is imprecise
cpa.invariants.allowOverapproximationOfUnsupportedFeatures = no default value

# determine variables relevant to the decision whether or not a target path
# assume edge is taken and limit the analyis to those variables.
cpa.invariants.analyzeRelevantVariablesOnly = no default value

# determine target locations in advance and analyse paths to the target
# locations only.
cpa.invariants.analyzeTargetPathsOnly = no default value

# controls the condition adjustment logic: STATIC means that condition
# adjustment is a no-op, INTERESTING_VARIABLES increases the interesting
# variable limit, MAXIMUM_FORMULA_DEPTH increases the maximum formula depth,
# ABSTRACTION_STRATEGY tries to choose a more precise abstraction strategy,
# COMPOUND combines the other strategies (minus STATIC).
cpa.invariants.conditionAdjusterFactory = no default value
  enum:     [STATIC, INTERESTING_VARIABLES, MAXIMUM_FORMULA_DEPTH,
             ABSTRACTION_STRATEGY, COMPOUND]

# include type information for variables, such as x >= MIN_INT && x <=
# MAX_INT
cpa.invariants.includeTypeInformation = no default value

# the maximum number of variables to consider as interesting. -1 one disables
# the limit, but this is not recommended. 0 means that no variables are
# considered to be interesting.
cpa.invariants.interestingVariableLimit = no default value

# the maximum number of adjustments of the interestingVariableLimit. -1 one
# disables the limit
cpa.invariants.maxInterestingVariableAdjustments = no default value

# the maximum tree depth of a formula recorded in the environment.
cpa.invariants.maximumFormulaDepth = no default value

# which merge operator to use for InvariantCPA
cpa.invariants.merge = no default value
  allowed values: [JOIN, SEP, PRECISIONDEPENDENT]

# use modulo-2 template during widening if applicable.
cpa.invariants.useMod2Template = no default value

# use pointer-alias information in strengthening, if available.
cpa.invariants.usePointerAliasStrengthening = no default value

# With this option the handling of global variables during the analysis can
# be fine-tuned. For example while doing a function-wise analysis it is
# important to assume that all global variables are live. In contrast to
# that, while doing a global analysis, we do not need to assume global
# variables being live.
cpa.liveVar.assumeGlobalVariablesAreAlwaysLive = no default value

# functions, which allocate new free memory
cpa.local.allocateFunctionPattern = no default value
cpa.local.allocatefunctions = no default value

# functions, which do not change sharedness of parameters
cpa.local.conservativefunctions = no default value

# variables, which are always local
cpa.local.localvariables = no default value

# With this option enabled, function calls that occur in the CFA are
# followed. By disabling this option one can traverse a function without
# following function calls (in this case FunctionSummaryEdges are used)
cpa.location.followFunctionCalls = no default value

# What are we searching for: race or deadlock
cpa.lock.analysisMode = no default value
  enum:     [RACE, DEADLOCK]

#  annotated functions, which are known to works right
cpa.lock.annotate = no default value

# contains all lock names
cpa.lock.lockinfo = no default value

# which merge operator to use for LockCPA
cpa.lock.merge = no default value
  allowed values: [SEP, JOIN]

# reduce recursive locks to a single access
cpa.lock.reduceLockCounters = no default value
  enum:     [NONE, BLOCK, ALL]

# reduce unused locks
cpa.lock.reduceUselessLocks = no default value

# Enable refinement procedure
cpa.lock.refinement = no default value

# stop path exploration if a lock limit is reached
cpa.lock.stopAfterLockLimit = no default value

# Consider or not special cases with empty lock sets
cpa.lock.stopMode = no default value
  enum:     [DEFAULT, EMPTYLOCKSET]

# Only checks for targets after loops were unrolled exactly a number of times
# that is contained in this list. The default is an empty list, which means
# targets are checked in every iteration
cpa.loopbound.checkOnlyAtBounds = no default value

# Use a stop operator that will identify loop states who's depth is congruent
# regarding the modulus of this number. Values smaller or equal to zero will
# deactivate this feature.
cpa.loopbound.cyclicStopModulus = no default value

# Number of loop iterations before the loop counter is abstracted. Zero is
# equivalent to no limit.
cpa.loopbound.loopIterationsBeforeAbstraction = no default value

# This option controls how the maxLoopIterations condition is adjusted when a
# condition adjustment is invoked.
cpa.loopbound.maxLoopIterationAdjusterFactory = no default value
  enum:     [STATIC, INCREMENT, DOUBLE]

# Bound for number of loop-head visits (number of loop unrollings + 1)
# of the program (0 is used for no bound).
# Works only if assumption storage CPA is enabled, because otherwise it would
# be unsound.
cpa.loopbound.maxLoopIterations = no default value

# Maximum for adjusting the bound for number of loop-head visits of the
# program
# (0 is used for no maximum).
# Only relevant in combination with a non-static adjuster for the bound for
# loop-head visits.
cpa.loopbound.maxLoopIterationsUpperBound = no default value

# Only checks for error after loops were unrolled at least this amount of
# times.
cpa.loopbound.startAtBound = no default value

# enable stack-based tracking of loops
cpa.loopbound.trackStack = no default value

# Where to perform abstraction
cpa.lpi.abstractionLocations = no default value
  enum:     [ALL, LOOPHEAD, MERGE]

# Attach extra invariant from other CPAs during the value determination
# computation
cpa.lpi.attachExtraInvariantDuringValueDetermination = no default value

# Check whether the policy depends on the initial value
cpa.lpi.checkPolicyInitialCondition = no default value

# Check target states reachability
cpa.lpi.checkTargetStates = no default value

# Compute abstraction for larger templates using decomposition
cpa.lpi.computeAbstractionByDecomposition = no default value

# Do not compute the abstraction until strengthen is called. This speeds up
# the computation, but does not let other CPAs use the output of LPI.
cpa.lpi.delayAbstractionUntilStrengthen = no default value

# Value to substitute for the epsilon
cpa.lpi.epsilon = no default value

# Generate new templates using polyhedra convex hull
cpa.lpi.generateTemplatesUsingConvexHull = no default value

# Remove UFs and ITEs from policies.
cpa.lpi.linearizePolicy = no default value

# Attempt to weaken interpolants in order to make them more general
cpa.lpi.refinement.generalizeInterpolants = no default value

# Run naive value determination first, switch to namespaced if it fails.
cpa.lpi.runHopefulValueDetermination = no default value

# Remove redundant items when abstract values.
cpa.lpi.simplifyDotOutput = no default value

# Algorithm for converting a formula to a set of lemmas
cpa.lpi.toLemmasAlgorithm = no default value
  allowed values: [CNF, RCNF, NONE]

# Number of refinements after which the unrolling depth is increased.Set to
# -1 to never increase the depth.
cpa.lpi.unrollingRefinementThreshold = no default value

# Cache formulas produced by path formula manager
cpa.lpi.useCachingPathFormulaManager = no default value

# Syntactically pre-compute dependencies for value determination
cpa.lpi.valDetSyntacticCheck = no default value

# Number of value determination steps allowed before widening is run. Value
# of '-1' runs value determination until convergence.
cpa.lpi.wideningThreshold = no default value

# time limit for a single post computation (use milliseconds or specify a
# unit; 0 for infinite)
cpa.monitor.limit = no default value

# time limit for all computations on a path in milliseconds (use milliseconds
# or specify a unit; 0 for infinite)
cpa.monitor.pathcomputationlimit = no default value

# keep tracking nondeterministically-assigned variables even if they are used
# in assumptions
cpa.nondeterminism.acceptConstrained = no default value

# this option determines which initial precision should be used
cpa.octagon.initialPrecisionType = no default value
  allowed values: [STATIC_FULL, REFINEABLE_EMPTY]

# with this option enabled the states are only merged at loop heads
cpa.octagon.mergeop.onlyMergeAtLoopHeads = no default value

# of which type should the merge be?
cpa.octagon.mergeop.type = no default value
  allowed values: [SEP, JOIN, WIDENING]

# with this option the number representation in the library will be changed
# between floats and ints.
cpa.octagon.octagonLibrary = no default value
  allowed values: [INT, FLOAT]

# Timelimit for the backup feasibility check with the octagon analysis.(use
# seconds or specify a unit; 0 for infinite)
cpa.octagon.refiner.timeForOctagonFeasibilityCheck = no default value

# which merge operator to use for PointerCPA
cpa.pointer2.merge = no default value
  allowed values: [JOIN, SEP]

# which merge operator to use for PointerACPA
cpa.pointerA.merge = no default value
  allowed values: [SEP, JOIN]

# which stop operator to use for PointerACPA
cpa.pointerA.stop = no default value
  allowed values: [SEP, JOIN, NEVER]

# Whether to give up immediately if a very large array is encountered
# (heuristic, often we would just waste time otherwise)
cpa.predicate.abortOnLargeArrays = no default value

# Predicate ordering
cpa.predicate.abs.predicateOrdering.method = no default value
  enum:     [CHRONOLOGICAL, FRAMEWORK_RANDOM, FRAMEWORK_SIFT, FRAMEWORK_SIFTITE,
             FRAMEWORK_WIN2, FRAMEWORK_WIN2ITE, FRAMEWORK_WIN3, FRAMEWORK_WIN3ITE]

# use caching of abstractions
# use caching of region to formula conversions
cpa.predicate.abs.useCache = no default value

# DEPRECATED: whether to use Boolean (false) or Cartesian (true) abstraction
cpa.predicate.abstraction.cartesian = no default value

# whether to use Boolean or Cartesian abstraction or both
cpa.predicate.abstraction.computation = no default value
  enum:     [CARTESIAN, CARTESIAN_BY_WEAKENING, BOOLEAN, COMBINED, ELIMINATION]

# dump the abstraction formulas if they took to long
cpa.predicate.abstraction.dumpHardQueries = no default value

# Identify those predicates where the result is trivially known before
# abstraction computation and omit them.
cpa.predicate.abstraction.identifyTrivialPredicates = no default value

# get an initial map of predicates from a list of files (see source
# doc/examples/predmap.txt for an example)
cpa.predicate.abstraction.initialPredicates = no default value

# Apply location-specific predicates to all locations in their function
cpa.predicate.abstraction.initialPredicates.applyFunctionWide = no default value

# Apply location- and function-specific predicates globally (to all locations
# in the program)
cpa.predicate.abstraction.initialPredicates.applyGlobally = no default value

# when reading predicates from file, convert them from Integer- to BV-theory
# or reverse.
cpa.predicate.abstraction.initialPredicates.encodePredicates = no default value
  enum:     [DISABLE, INT2BV, BV2INT]

# initial predicates are added as atomic predicates
cpa.predicate.abstraction.initialPredicates.splitIntoAtoms = no default value

# An initial set of comptued abstractions that might be reusable
cpa.predicate.abstraction.reuseAbstractionsFrom = no default value

# Simplify the abstraction formula that is stored to represent the state
# space. Helpful when debugging (formulas get smaller).
cpa.predicate.abstraction.simplify = no default value

# What to use for storing abstractions
cpa.predicate.abstraction.type = no default value
  allowed values: [BDD, FORMULA]

# Export abstraction formulas as (way more readable) expressions.
cpa.predicate.abstractions.asExpressions = no default value

# Export one abstraction formula for each abstraction state into a file?
cpa.predicate.abstractions.export = no default value

# file that consists of one abstraction formula for each abstraction state
cpa.predicate.abstractions.file = no default value

# Add constraints for the range of the return-value of a nondet-method. For
# example the assignment 'X=nondet_int()' produces the constraint
# 'MIN<=X<=MAX', where MIN and MAX are computed from the type of the method
# (signature, not name!).
cpa.predicate.addRangeConstraintsForNondet = no default value

# Allow the given extern functions and interpret them as pure functions
# although the predicate analysis does not support their semantics and this
# can produce wrong results.
cpa.predicate.allowedUnsupportedFunctions = no default value

# Check satisfiability for plain conjunction of edge and assumptions.
cpa.predicate.assumptionStrengtheningSatCheck = no default value

# Enable/disable abstraction reduction at the BAM block entry
cpa.predicate.bam.useAbstractionReduction = no default value

# Enable/disable precision reduction at the BAM block entry
cpa.predicate.bam.usePrecisionReduction = no default value

# The bitsize is used to encode integers as bitvectors.
cpa.predicate.bitsize = no default value

# force abstractions immediately after threshold is reached (no effect if
# threshold = 0)
cpa.predicate.blk.alwaysAfterThreshold = no default value

# abstraction always and only on explicitly computed abstraction nodes.
cpa.predicate.blk.alwaysAndOnlyAtExplicitNodes = no default value

# force abstractions at each branch node, regardless of threshold
cpa.predicate.blk.alwaysAtBranch = no default value

# force abstractions at the head of the analysis-entry function (first node
# in the body), regardless of threshold
cpa.predicate.blk.alwaysAtEntryFunctionHead = no default value

# abstraction always at explicitly computed abstraction nodes.
cpa.predicate.blk.alwaysAtExplicitNodes = no default value

# force abstractions at each function call (node before entering the body),
# regardless of threshold
cpa.predicate.blk.alwaysAtFunctionCallNodes = no default value

# abstraction always at function exit nodes.
cpa.predicate.blk.alwaysAtFunctionExit = no default value

# force abstractions at each function head (first node in the body),
# regardless of threshold
cpa.predicate.blk.alwaysAtFunctionHeads = no default value

# force abstractions at each function calls/returns, regardless of threshold
cpa.predicate.blk.alwaysAtFunctions = no default value

# abstraction always at nodes with outgoing ghost edges
cpa.predicate.blk.alwaysAtGhostEdges = no default value

# force abstractions at each join node, regardless of threshold
cpa.predicate.blk.alwaysAtJoin = no default value

# force abstractions at loop heads, regardless of threshold
cpa.predicate.blk.alwaysAtLoops = no default value

# force abstractions at program exit (program end, abort, etc.), regardless
# of threshold
cpa.predicate.blk.alwaysAtProgramExit = no default value

# abstractions at function calls/returns if threshold has been reached (no
# effect if threshold = 0)
cpa.predicate.blk.functions = no default value

# abstractions at CFA nodes with more than one incoming edge if threshold has
# been reached (no effect if threshold = 0)
cpa.predicate.blk.join = no default value

# abstractions at loop heads if threshold has been reached (no effect if
# threshold = 0)
cpa.predicate.blk.loops = no default value

# maximum blocksize before abstraction is forced
# (non-negative number, special values: 0 = don't check threshold, 1 = SBE)
cpa.predicate.blk.threshold = no default value

# use caching of path formulas
cpa.predicate.blk.useCache = no default value

# always check satisfiability at end of block, even if precision is empty
cpa.predicate.checkBlockFeasibility = no default value

# The default size in bytes for memory allocations when the value cannot be
# determined.
cpa.predicate.defaultAllocationSize = no default value

# The length for arrays we assume for variably-sized arrays.
cpa.predicate.defaultArrayLength = no default value

# Use deferred allocation heuristic that tracks void * variables until the
# actual type of the allocation is figured out.
cpa.predicate.deferUntypedAllocations = no default value

# Direction of the analysis?
cpa.predicate.direction = no default value
  enum:     [FORWARD, BACKWARD]

# Enable the possibility to precompute explicit abstraction locations.
cpa.predicate.enableBlockreducer = no default value

# Enable handling of functions memset, memcopy, memmove. If disabled, using
# these functions will result in an error.
cpa.predicate.enableMemoryAssignmentFunctions = no default value

# Enable to share the information via serialization storage.
cpa.predicate.enableSharedInformation = no default value

# Theory to use as backend for bitvectors. If different from BITVECTOR, the
# specified theory is used to approximate bitvectors. This can be used for
# solvers that do not support bitvectors, or for increased performance. If
# UNSUPPORTED, solvers can be used that support none of the possible
# alternatives, but CPAchecker will crash if bitvectors are required by the
# analysis.
cpa.predicate.encodeBitvectorAs = no default value
  enum:     [UNSUPPORTED, INTEGER, RATIONAL, BITVECTOR, FLOAT]

# Theory to use as backend for floats. If different from FLOAT, the specified
# theory is used to approximate floats. This can be used for solvers that do
# not support floating-point arithmetic, or for increased performance. If
# UNSUPPORTED, solvers can be used that support none of the possible
# alternatives, but CPAchecker will crash if floats are required by the
# analysis.
cpa.predicate.encodeFloatAs = no default value
  enum:     [UNSUPPORTED, INTEGER, RATIONAL, BITVECTOR, FLOAT]

# Theory to use as backend for integers. If different from INTEGER, the
# specified theory is used to approximate integers. This can be used for
# solvers that do not support integers, or for increased performance. If
# UNSUPPORTED, solvers can be used that support none of the possible
# alternatives, but CPAchecker will crash if integers are required by the
# analysis.
cpa.predicate.encodeIntegerAs = no default value
  enum:     [UNSUPPORTED, INTEGER, RATIONAL, BITVECTOR, FLOAT]

# Replace possible overflows with an ITE-structure, which returns either the
# normal value or an UF representing the overflow.
cpa.predicate.encodeOverflowsWithUFs = no default value

# Name of an external function that will be interpreted as if the function
# call would be replaced by an externally defined expression over the program
# variables. This will only work when all variables referenced by the dimacs
# file are global and declared before this function is called.
cpa.predicate.externModelFunctionName = no default value

# where to dump interpolation and abstraction problems (format string)
cpa.predicate.formulaDumpFilePattern = no default value

# Handle field access via extract and concat instead of new variables.
cpa.predicate.handleFieldAccess = no default value

# If disabled, all implicitly initialized fields and elements are treated as
# non-dets
cpa.predicate.handleImplicitInitialization = no default value

# Handle aliasing of pointers. This adds disjunctions to the formulas, so be
# careful when using cartesian abstraction.
cpa.predicate.handlePointerAliasing = no default value

# When a string literal initializer is encountered, initialize the contents
# of the char array with the contents of the string literal instead of just
# assigning a fresh non-det address to it
cpa.predicate.handleStringLiteralInitializers = no default value

# Ignore Extract and Extend operations instead of encoding them with a UF
# when Bitvector theory is replaced with Integer or Rational. This is unsound
# but sometimes more practical in order to not make casts return
# nondeterministic values.
cpa.predicate.ignoreExtractExtend = no default value

# Ignore fields that are not relevant for reachability properties. This is
# unsound in case fields are accessed by pointer arithmetic with hard-coded
# field offsets. Only relvant if ignoreIrrelevantVariables is enabled.
cpa.predicate.ignoreIrrelevantFields = no default value

# Ignore variables that are not relevant for reachability properties.
cpa.predicate.ignoreIrrelevantVariables = no default value

# do not include assumptions of states into path formula during strengthening
cpa.predicate.ignoreStateAssumptions = no default value

# Prevent functions memset, memcopy, memmove from stopping verification if
# there is unrecognized code. Instead, they will just be skipped (unsound).
# Only relevant if enableMemoryAssignmentFunctions is set to true.
cpa.predicate.ignoreUnrecognizedCodeInMemoryAssignmentFunctions = no default value

# Add computed invariants to the precision. Invariants do not need to be
# generated with the PredicateCPA they can also be given from outside.
cpa.predicate.invariants.addToPrecision = no default value

# Strengthen the abstraction formula during abstraction with invariants if
# some are generated. Invariants do not need to be generated with the
# PredicateCPA they can also be given from outside.
cpa.predicate.invariants.appendToAbstractionFormula = no default value

# Strengthen the pathformula during abstraction with invariants if some are
# generated. Invariants do not need to be generated with the PredicateCPA
# they can also be given from outside.
cpa.predicate.invariants.appendToPathFormula = no default value

# Should the automata used for invariant generation be dumped to files?
cpa.predicate.invariants.dumpInvariantGenerationAutomata = no default value

# Where to dump the automata that are used to narrow the analysis used for
# invariant generation.
cpa.predicate.invariants.dumpInvariantGenerationAutomataFile = no default value

# export final loop invariants
cpa.predicate.invariants.export = no default value

# export invariants as precision file?
cpa.predicate.invariants.exportAsPrecision = no default value

# file for exporting final loop invariants
cpa.predicate.invariants.file = no default value

# Which strategy should be used for generating invariants, a comma separated
# list can be specified. Usually later specified strategies serve as fallback
# for earlier ones. (default is no invariant generation at all)
cpa.predicate.invariants.generationStrategy = no default value

# How often should generating invariants from sliced prefixes with
# k-induction be tried?
cpa.predicate.invariants.kInductionTries = no default value

# file for precision that consists of invariants.
cpa.predicate.invariants.precisionFile = no default value

# Timelimit for invariant generation which may be used during refinement.
# (Use seconds or specify a unit; 0 for infinite)
cpa.predicate.invariants.timeForInvariantGeneration = no default value

# Should the strategies be used all-together or only as fallback. If all
# together, the computation is done until the timeout is hit and the results
# up to this point are taken.
cpa.predicate.invariants.useAllStrategies = no default value

# Provide invariants generated with other analyses via the
# PredicateCPAInvariantsManager.
cpa.predicate.invariants.useGlobalInvariants = no default value

# Invariants that are not strong enough to refute the counterexample can be
# ignored with this option. (Weak invariants will lead to repeated
# counterexamples, thus taking time which could be used for the rest of the
# analysis, however, the found invariants may also be better for loops as
# interpolation.)
cpa.predicate.invariants.useStrongInvariantsOnly = no default value

# Max. number of edge of the abstraction tree to prescan for reuse
cpa.predicate.maxAbstractionReusePrescan = no default value

# The maximum length up to which bulk assignments (e.g., initialization) for
# arrays will be handled. With option useArraysForHeap=false, elements beyond
# this bound will be ignored completely. Use -1 to disable the limit.
cpa.predicate.maxArrayLength = no default value

# When builtin functions like memcmp/strlen/etc. are called, unroll them up
# to this bound.If the passed arguments are longer, the return value will be
# overapproximated.
cpa.predicate.maxPreciseStrFunctionSize = no default value

# Set of functions that non-deterministically provide new memory on the heap,
# i.e. they can return either a valid pointer or zero.
cpa.predicate.memoryAllocationFunctions = no default value

# Memory allocation functions of which all parameters but the first should be
# ignored.
cpa.predicate.memoryAllocationFunctionsWithSuperfluousParameters = no default value

# Set of functions that non-deterministically provide new zeroed memory on
# the heap, i.e. they can return either a valid pointer or zero.
cpa.predicate.memoryAllocationFunctionsWithZeroing = no default value

# Setting this to true makes memoryAllocationFunctions always return a valid
# pointer.
cpa.predicate.memoryAllocationsAlwaysSucceed = no default value

# Function that is used to free allocated memory.
cpa.predicate.memoryFreeFunctionName = no default value

# which merge operator to use for predicate cpa (usually ABE should be used)
cpa.predicate.merge = no default value
  allowed values: [SEP, ABE]

# merge two abstraction states if their preceeding abstraction states are the
# same
cpa.predicate.merge.mergeAbstractionStatesWithSamePredecessor = no default value

# Set of functions that should be considered as giving a non-deterministic
# return value. If you specify this option, the default values are not added
# automatically to the list, so you need to specify them explicitly if you
# need them. Mentioning a function in this list has only an effect, if it is
# an 'external function', i.e., no source is given in the code for this
# function.
cpa.predicate.nondetFunctions = no default value

# Regexp pattern for functions that should be considered as giving a
# non-deterministic return value (c.f. cpa.predicate.nondedFunctions)
cpa.predicate.nondetFunctionsRegexp = no default value

# Do not ignore variables that could lead to an overflow (only makes sense if
# ignoreIrrelevantVariables is set to true)
cpa.predicate.overflowVariablesAreRelevant = no default value

# Which path-formula builder to use.Depending on this setting additional
# terms are added to the path formulas,e.g. SYMBOLICLOCATIONS will add track
# the program counter symbolically with a special variable %pc
cpa.predicate.pathFormulaBuilderVariant = no default value
  enum:     [DEFAULT, SYMBOLICLOCATIONS]

# Where to apply the found predicates to?
cpa.predicate.precision.sharing = no default value
  enum:     [GLOBAL, SCOPE, FUNCTION, LOCATION, LOCATION_INSTANCE]

# generate statistics about precisions (may be slow)
cpa.predicate.precisionStatistics = no default value

# export final predicate map
cpa.predicate.predmap.export = no default value

# file for exporting final predicate map
cpa.predicate.predmap.file = no default value

# Format for exporting predicates from precisions.
cpa.predicate.predmap.predicateFormat = no default value
  enum:     [PLAIN, SMTLIB2]

# Specify whether to overapproximate quantified formula, if one or more
# quantifiers couldn't be eliminated.(Otherwise an exception will be thrown)
cpa.predicate.pseudoExistQE.overapprox = no default value

# Which solver tactic to use for Quantifier Elimination(Only used if
# useRealQuantifierElimination=true)
cpa.predicate.pseudoExistQE.solverQeTactic = no default value
  enum:     [NONE, LIGHT, FULL]

# Use Destructive Equality Resolution as simplification method
cpa.predicate.pseudoExistQE.useDER = no default value

# Use Unconnected Parameter Drop as simplification method
cpa.predicate.pseudoExistQE.useUPD = no default value

# If an abstraction is computed during refinement, use only the interpolant
# as input, not the concrete block.
cpa.predicate.refinement.abstractInterpolantOnly = no default value

# use only the atoms from the interpolantsas predicates, and not the whole
# interpolant
cpa.predicate.refinement.atomicInterpolants = no default value

# Direction for doing counterexample analysis: from start of trace, from end
# of trace, or in more complex patterns. In combination with
# incrementalCexTraceCheck=true the generated interpolants will refer to the
# minimal infeasible part of the trace according to this strategy (e.g., with
# FORWARDS a minimal infeasible prefix is found).
cpa.predicate.refinement.cexTraceCheckDirection = no default value
  enum:     [FORWARDS, BACKWARDS, ZIGZAG, LOOP_FREE_FIRST, RANDOM, LOWEST_AVG_SCORE,
             HIGHEST_AVG_SCORE, LOOP_FREE_FIRST_BACKWARDS]

# Actually compute an abstraction, otherwise just convert the interpolants to
# BDDs as they are.
cpa.predicate.refinement.doAbstractionComputation = no default value

# dump all interpolation problems
cpa.predicate.refinement.dumpInterpolationProblems = no default value

# After each refinement, dump the newly found predicates.
cpa.predicate.refinement.dumpPredicates = no default value

# File name for the predicates dumped after refinements.
cpa.predicate.refinement.dumpPredicatesFile = no default value

# apply deletion-filter to the abstract counterexample, to get a minimal set
# of blocks, before applying interpolation-based refinement
cpa.predicate.refinement.getUsefulBlocks = no default value

# Do a complete restart (clearing the reached set) after the refinement
cpa.predicate.refinement.global.restartAfterRefinement = no default value

# Instead of updating precision and arg we say that the refinement was not
# successful after N times of refining. A real error state is not necessary
# to be found. Use 0 for unlimited refinements (default).
cpa.predicate.refinement.global.stopAfterNRefinements = no default value

# BlockFormulaStrategy for graph-like ARGs (e.g. Slicing Abstractions)
cpa.predicate.refinement.graphblockformulastrategy = no default value

# Enable/Disable adding partial state invariants into the PathFormulas
cpa.predicate.refinement.includePartialInvariants = no default value

# Use incremental search in counterexample analysis to find a minimal
# infeasible part of the trace. This will typically lead to interpolants that
# refer to this part only. The option cexTraceCheckDirection defines in which
# order the blocks of the trace are looked at.
cpa.predicate.refinement.incrementalCexTraceCheck = no default value

# Max. number of prefixes to extract
cpa.predicate.refinement.maxPrefixCount = no default value

# Max. length of feasible prefixes to extract from if at least one prefix was
# already extracted
cpa.predicate.refinement.maxPrefixLength = no default value

# skip refinement if input formula is larger than this amount of bytes
# (ignored if 0)
cpa.predicate.refinement.maxRefinementSize = no default value

# sets the level of the pathformulas to use for abstraction. 
#   EDGE : Based on Pathformulas of every edge in ARGPath
#   BLOCK: Based on Pathformulas at Abstractionstates
cpa.predicate.refinement.newtonrefinement.abstractionLevel = no default value
  enum:     [BLOCK, EDGE]

# Activate fallback to interpolation. Typically in case of a repeated
# counterexample.
cpa.predicate.refinement.newtonrefinement.fallback = no default value

# use unsatisfiable Core in order to abstract the predicates produced while
# NewtonRefinement
cpa.predicate.refinement.newtonrefinement.infeasibleCore = no default value

# use live variables in order to abstract the predicates produced while
# NewtonRefinement
cpa.predicate.refinement.newtonrefinement.liveVariables = no default value

# use heuristic to extract predicates from the CFA statically on first
# refinement
cpa.predicate.refinement.performInitialStaticRefinement = no default value

# Which predicates should be used as basis for the new precision that will be
# attached to the refined part of the ARG:
# ALL: Collect predicates from the complete ARG.
# SUBGRAPH: Collect predicates from the removed subgraph of the ARG.
# CUTPOINT: Only predicates from the cut-point's (pivot state) precision are
# kept.
# TARGET: Only predicates from the target state's precision are kept.
cpa.predicate.refinement.predicateBasisStrategy = no default value
  enum:     [ALL, SUBGRAPH, TARGET, CUTPOINT]

# which sliced prefix should be used for interpolation
cpa.predicate.refinement.prefixPreference = no default value

# Do a complete restart (clearing the reached set) after N refinements. 0 to
# disable, 1 for always.
cpa.predicate.refinement.restartAfterRefinements = no default value

# Use a single SMT solver environment for all interpolation queries and keep
# formulas pushed on solver stack between interpolation queries.
cpa.predicate.refinement.reuseInterpolationEnvironment = no default value

# In case we apply sequential interpolation, forward and backward directions
# return valid interpolants. We can either choose one of the directions,
# fallback to the other if one does not succeed, or even widen the
# interpolants.
cpa.predicate.refinement.sequentialStrategy = no default value
  enum:     [FWD, FWD_FALLBACK, BWD, BWD_FALLBACK, CONJUNCTION, DISJUNCTION, WEIGHTED,
             RANDOM]

# During refinement, add all new predicates to the precisions of all abstract
# states in the reached set.
cpa.predicate.refinement.sharePredicates = no default value

# slice block formulas, experimental feature!
cpa.predicate.refinement.sliceBlockFormulas = no default value

# split each arithmetic equality into two inequalities when extracting
# predicates from interpolants
cpa.predicate.refinement.splitItpAtoms = no default value

# Stop after refining the n-th spurious counterexample and export that. If 0,
# stop after finding the first spurious counterexample but before refinement.
# If -1, never stop. If this option is used with a value different from -1,
# option counterexample.export.alwaysUseImpreciseCounterexamples=true should
# be set. Then, an actually infeasible counterexample will be handed to
# export. So this option will also not work with additional counterexample
# checks or similar, because these may reject the (infeasible)
# counterexample.
cpa.predicate.refinement.stopAfter = no default value

# Strategy how to interact with the intepolating prover. The analysis must
# support the strategy, otherwise the result will be useless!
# - SEQ_CPACHECKER: Generate an inductive sequence of interpolants by asking
# the solver individually for each of them. This allows us to fine-tune the
# queries with the option sequentialStrategy and is supported by all solvers.
# - SEQ: Generate an inductive sequence of interpolants by asking the solver
# for the whole sequence at once.
# - TREE: Use the tree-interpolation feature of the solver to get
# interpolants.
# - TREE_WELLSCOPED: Return each interpolant for i={0..n-1} for the
# partitions A=[lastFunctionEntryIndex..i] and
# B=[0..lastFunctionEntryIndex-1]+[i+1..n]. Based on a tree-like scheme.
# - TREE_NESTED: Use callstack and previous interpolants for next
# interpolants (cf. 'Nested Interpolants').
# - TREE_CPACHECKER: similar to TREE_NESTED, but the algorithm is taken from
# 'Tree Interpolation in Vampire'
cpa.predicate.refinement.strategy = no default value
  enum:     [SEQ, SEQ_CPACHECKER, TREE, TREE_WELLSCOPED, TREE_NESTED, TREE_CPACHECKER]

# time limit for refinement (use milliseconds or specify a unit; 0 for
# infinite)
cpa.predicate.refinement.timelimit = no default value

# After a failed interpolation query, try to solve the formulas again with
# different options instead of giving up immediately.
cpa.predicate.refinement.tryAgainOnInterpolationError = no default value

# When interpolation query fails, attempt to check feasibility of the current
# counterexample without interpolation
cpa.predicate.refinement.tryWithoutInterpolation = no default value

# Use BDDs to simplify interpolants (removing irrelevant predicates)
cpa.predicate.refinement.useBddInterpolantSimplification = no default value

# use Newton-based Algorithm for the CPA-Refinement, experimental feature!
cpa.predicate.refinement.useNewtonRefinement = no default value

# Should the path invariants be created and used (potentially additionally to
# the other invariants)
cpa.predicate.refinement.usePathInvariants = no default value

# use UCB predicates for the CPA-Refinement, experimental feature!
cpa.predicate.refinement.useUCBRefinement = no default value

# verify if the interpolants fulfill the interpolant properties
cpa.predicate.refinement.verifyInterpolants = no default value

# Enable the option to allow detecting the allocation type by type of the LHS
# of the assignment, e.g. char *arr = malloc(size) is detected as char[size]
cpa.predicate.revealAllocationTypeFromLhs = no default value

# maximum blocksize before a satisfiability check is done
# (non-negative number, 0 means never, if positive should be smaller than
# blocksize)
cpa.predicate.satCheck = no default value

# Enables sat checks at abstraction location.
# Infeasible paths are already excluded by transfer relation and not later by
# precision adjustment. This property is required in proof checking.
cpa.predicate.satCheckAtAbstraction = no default value

# Call 'simplify' on generated formulas.
cpa.predicate.simplifyGeneratedPathFormulas = no default value

# Whether to perform dynamic block encoding as part of each refinement
# iteration
cpa.predicate.slicingabstractions.dynamicBlockEncoding = no default value

# Only slices the minimal amount of edges to guarantuee progress
cpa.predicate.slicingabstractions.minimalslicing = no default value

# Reduces the amount of solver calls by directely slicing some edgesthat are
# mathematically proven to be infeasible in any case
cpa.predicate.slicingabstractions.optimizeslicing = no default value

# Whether to remove parts fo the ARG from which no target state is reachable
cpa.predicate.slicingabstractions.removeSafeRegions = no default value

# C99 only defines the overflow of unsigned integer type.
cpa.predicate.solver.ufCheckingProver.isSignedOverflowSafe = no default value

# How often should we try to get a better evaluation?
cpa.predicate.solver.ufCheckingProver.maxIterationNum = no default value

# which stop operator to use for predicate cpa (usually SEP should be used in
# analysis). SEPNAA works the same as SEP, except that it Never stops At
# Abstraction states. SEPNAA is used in bmc-IMC.properties for config
# bmc-incremental-ABEl to keep exploring covered states.
cpa.predicate.stop = no default value
  allowed values: [SEP, SEPPCC, SEPNAA]

# Use formula reporting states for strengthening.
cpa.predicate.strengthenWithFormulaReportingStates = no default value

# try to reuse old abstractions from file during strengthening
cpa.predicate.strengthenWithReusedAbstractions = no default value

# file that consists of old abstractions, to be used during strengthening
cpa.predicate.strengthenWithReusedAbstractionsFile = no default value

# The function used to model successful heap object allocation. This is only
# used, when pointer analysis with UFs is enabled.
cpa.predicate.successfulAllocFunctionName = no default value

# The function used to model successful heap object allocation with zeroing.
# This is only used, when pointer analysis with UFs is enabled.
cpa.predicate.successfulZallocFunctionName = no default value

# whether to include the symbolic path formula in the coverage checks or do
# only the fast abstract checks
cpa.predicate.symbolicCoverageCheck = no default value

# check satisfiability when a target state has been found
cpa.predicate.targetStateSatCheck = no default value

# Whether to track values stored in variables of function-pointer type.
cpa.predicate.trackFunctionPointers = no default value

# Use SMT arrays for encoding heap memory instead of uninterpreted function
# (ignored if useByteArrayForHeap=true). This is more precise but may lead to
# interpolation failures.
cpa.predicate.useArraysForHeap = no default value

# try to add some useful static-learning-like axioms for bitwise operations
# (which are encoded as UFs): essentially, we simply collect all the numbers
# used in bitwise operations, and add axioms like (0 & n = 0)
cpa.predicate.useBitwiseAxioms = no default value

# Use SMT byte array for encoding heap memory instead of uninterpreted
# function. This is more close to c heap implementation but may be to
# expensive.
cpa.predicate.useByteArrayForHeap = no default value

# Use an optimisation for constraint generation
cpa.predicate.useConstraintOptimization = no default value

# For multithreaded programs this is an overapproximation of possible values
# of shared variables.
cpa.predicate.useHavocAbstraction = no default value

# Use regions for pointer analysis. So called Burstall&Bornat (BnB) memory
# regions will be used for pointer analysis. BnB regions are based not only
# on type, but also on structure field names. If the field is not accessed by
# an address then it is placed into a separate region.
cpa.predicate.useMemoryRegions = no default value

# add special information to formulas about non-deterministic functions
cpa.predicate.useNondetFlags = no default value

# Insert tmp-variables for parameters at function-entries. The variables are
# similar to return-variables at function-exit.
cpa.predicate.useParameterVariables = no default value

# Insert tmp-parameters for global variables at function-entries. The global
# variables are also encoded with return-variables at function-exit.
cpa.predicate.useParameterVariablesForGlobals = no default value

# Use quantifiers when encoding heap accesses. This requires an SMT solver
# that is capable of quantifiers (e.g. Z3 or PRINCESS).
cpa.predicate.useQuantifiersOnArrays = no default value

# Do not follow states which can not syntactically lead to a target location
cpa.property_reachability.noFollowBackwardsUnreachable = no default value

# Qualified name for class which checks that the computed abstraction adheres
# to the desired property.
cpa.propertychecker.className = no default value

# List of parameters for constructor of propertychecker.className. Parameter
# values are specified in the order the parameters are defined in the
# respective constructor. Every parameter value is finished with ",". The
# empty string represents an empty parameter list.
cpa.propertychecker.parameters = no default value

# Whether to consider constraints on program variables (e.g., x > 10) as
# definitions)
cpa.reachdef.constraintIsDef = no default value

# which merge operator to use for ReachingDefCPA
cpa.reachdef.merge = no default value
  allowed values: [SEP, JOIN, IGNORECALLSTACK]

# which stop operator to use for ReachingDefCPA
cpa.reachdef.stop = no default value
  allowed values: [SEP, JOIN, IGNORECALLSTACK]

# Do not report 'False' result, return UNKNOWN instead.  Useful for
# incomplete analysis with no counterexample checking.
cpa.reportFalseAsUnknown = no default value

# which merge operator to use for SignCPA
cpa.sign.merge = no default value
  allowed values: [SEP, JOIN]

# which stop operator to use for SignCPA
cpa.sign.stop = no default value
  allowed values: [SEP, JOIN]

# max length of a chain of states, -1 for infinity
cpa.singleSuccessorCompactor.maxChainLength = no default value

# Apply AND- LBE transformation to loop transition relation.
cpa.slicing.applyLBETransformation = no default value

# Check target states reachability
cpa.slicing.checkTargetStates = no default value

# Filter lemmas by liveness
cpa.slicing.filterByLiveness = no default value

# Depth limit for the 'LEAST_REMOVALS' strategy.
cpa.slicing.leastRemovalsDepthLimit = no default value

# Pre-run syntactic weakening
cpa.slicing.preRunSyntacticWeakening = no default value

# Whether to use a refinable slicing precision that starts with an empty
# slice, or a statically computed, fixed slicing precision
cpa.slicing.refinableSlice = no default value

# Allow counterexamples that are valid only on the program slice. If you set
# this to `false`, you may have to set takeEagerSlice=true to avoid failed
# refinements. If this is set to true, the counterexample check won't work
# (in general), so you have to turn it off.
cpa.slicing.refinement.counterexampleCheckOnSlice = no default value

# Which prefix provider to use? (give class name) If the package name starts
# with 'org.sosy_lab.cpachecker.', this prefix can be omitted.
cpa.slicing.refinement.prefixProvider = no default value

# How to refine the slice:
# - CEX_ASSUME_DEPS: Add the dependencies of all counterexample assume edges
# to the slice.
# - INFEASIBLE_PREFIX_ASSUME_DEPS: Find an infeasible prefix and add the
# dependencies of all assume edges that are part of the infeasible prefix to
# the slice. Requires a prefix provider
# ('cpa.slicing.refinement.prefixProvider').
# - CEX_FIRST_ASSUME_DEPS: Add the dependencies of the first counterexample
# assume edges, that is not already part of the slice, to the slice.
# - CEX_LAST_ASSUME_DEPS: Add the dependencies of the last counterexample
# assume edges, that is not already part of the slice, to the slice.
cpa.slicing.refinement.refineStrategy = no default value
  enum:     [CEX_ASSUME_DEPS, INFEASIBLE_PREFIX_ASSUME_DEPS, CEX_FIRST_ASSUME_DEPS,
             CEX_LAST_ASSUME_DEPS]

# What kind of restart to do after a successful refinement
cpa.slicing.refinement.restartStrategy = no default value
  enum:     [PIVOT, ROOT]

# Use all assumptions of a target path as slicing criteria, not just the edge
# to the target location.
cpa.slicing.refinement.takeEagerSlice = no default value

# Strategy for abstracting children during CEX weakening
cpa.slicing.removalSelectionStrategy = no default value
  enum:     [ALL, FIRST, RANDOM, LEAST_REMOVALS]

# Time for loop generation before aborting.
# (Use seconds or specify a unit; 0 for infinite)
cpa.slicing.timeForLoopGeneration = no default value

# Inductive weakening strategy
cpa.slicing.weakeningStrategy = no default value
  enum:     [SYNTACTIC, DESTRUCTIVE, CEX]

# Enable GCC extension 'Arrays of Length Zero'.
cpa.smg.GCCZeroLengthArray = no default value

# Allocate memory on declaration of external variable
cpa.smg.allocateExternalVariables = no default value

# Array allocation functions
cpa.smg.arrayAllocationFunctions = no default value

# with this option enabled, a check for unreachable memory occurs whenever a
# function returns, and not only at the end of the main function
cpa.smg.checkForMemLeaksAtEveryFrameDrop = no default value

# Crash on unknown array dereferences
cpa.smg.crashOnUnknown = no default value

# Deallocation functions
cpa.smg.deallocationFunctions = no default value

# with this option enabled, heap abstraction will be enabled.
cpa.smg.enableHeapAbstraction = no default value

# If this Option is enabled, failure of malloc is simulated
cpa.smg.enableMallocFail = no default value

# Filename format for SMG graph dumps
cpa.smg.exportSMG.file = no default value

# Describes when SMG graphs should be dumped.
cpa.smg.exportSMGwhen = no default value
  enum:     [NEVER, LEAF, INTERESTING, EVERY]

# Functions which indicate on external allocated memory
cpa.smg.externalAllocationFunction = no default value

# Default size of externally allocated memory
cpa.smg.externalAllocationSize = no default value

# Allocation size of memory that cannot be calculated.
cpa.smg.guessSize = no default value

# Size of memory that cannot be calculated will be guessed.
cpa.smg.guessSizeOfUnknownMemorySize = no default value

# Handle external variables with incomplete type (extern int array[]) as
# external allocation
cpa.smg.handleIncompleteExternalVariableAsExternalAllocation = no default value

# with this option enabled, memory that is not freed before the end of main
# is reported as memleak even if it is reachable from local variables in main
cpa.smg.handleNonFreedMemoryInMainAsMemLeak = no default value

# Handle unknown dereference as safe and check error based on error
# predicate, depends on trackPredicates
cpa.smg.handleUnknownDereferenceAsSafe = no default value

# Sets how unknown functions are handled.
cpa.smg.handleUnknownFunctions = no default value
  enum:     [STRICT, ASSUME_SAFE, ASSUME_EXTERNAL_ALLOCATED]

# Perform merge SMGStates by SMGJoin on ends of code block. Works with
# 'merge=JOIN'
cpa.smg.joinOnBlockEnd = no default value

# Memory allocation functions
cpa.smg.memoryAllocationFunctions = no default value

# Size parameter of memory allocation functions
cpa.smg.memoryAllocationFunctionsSizeParameter = no default value

# Position of element size parameter for array allocation functions
cpa.smg.memoryArrayAllocationFunctionsElemSizeParameter = no default value

# Position of number of element parameter for array allocation functions
cpa.smg.memoryArrayAllocationFunctionsNumParameter = no default value

# Determines if memory errors are target states
cpa.smg.memoryErrors = no default value

# which merge operator to use for the SMGCPA
cpa.smg.merge = no default value
  allowed values: [SEP, JOIN]

# export interpolant smgs for every path interpolation to this path template
cpa.smg.refinement.exportInterpolantSMGs = no default value

# when to export the interpolation tree
# NEVER:   never export the interpolation tree
# FINAL:   export the interpolation tree once after each refinement
# ALWAYS:  export the interpolation tree once after each interpolation, i.e.
# multiple times per refinement
cpa.smg.refinement.exportInterpolationTree = no default value
  allowed values: [NEVER, FINAL, ALWAYS]

# export interpolant smgs for every path interpolation to this path template
cpa.smg.refinement.exportRefinementSMGs = no default value

# export interpolation trees to this file template
cpa.smg.refinement.interpolationTreeExportFile = no default value

# Sets the level of runtime checking: NONE, HALF, FULL
cpa.smg.runtimeCheck = no default value
  enum:     [FORCED, NONE, HALF, FULL]

# Patterns of unknown functions which are always considered as safe
# functions, i.e., free of memory-related side-effects.
cpa.smg.safeUnknownFunctionsPatterns = no default value

# which stop operator to use for the SMGCPA
cpa.smg.stop = no default value
  allowed values: [SEP, NEVER, END_BLOCK]

# Enable track predicates for possible memory safety error on SMG state
cpa.smg.trackErrorPredicates = no default value

# Enable track predicates on SMG state
cpa.smg.trackPredicates = no default value

# Emit messages when we encounter non-target undefined behavior
cpa.smg.unknownOnUndefined = no default value

# Allow SMG to check predicates
cpa.smg.verifyPredicates = no default value

# Allocation functions which set memory to zero
cpa.smg.zeroingMemoryAllocation = no default value

# Enable GCC extension 'Arrays of Length Zero'.
cpa.smg2.GCCZeroLengthArray = no default value

# aborts the analysis for a non-concrete (this includes symbolic values)
# memory allocation of any kind.
cpa.smg2.abortOnNonConcreteMemorySize = no default value

# If heap values are to be abstracted based on CEGAR.
cpa.smg2.abstraction.abstractHeapValues = no default value

# Abstraction of all detected linked lists at loop heads.
cpa.smg2.abstraction.abstractLinkedLists = no default value

# Abstraction of program variables via CEGAR.
cpa.smg2.abstraction.abstractProgramVariables = no default value

# restrict abstraction computations to branching points
cpa.smg2.abstraction.alwaysAtBranch = no default value

# restrict abstraction computations to function calls/returns
cpa.smg2.abstraction.alwaysAtFunction = no default value

# restrict abstraction computations to join points
cpa.smg2.abstraction.alwaysAtJoin = no default value

# If enabled, abstraction computations at loop-heads are enabled. List
# abstraction has to be enabled for this.
cpa.smg2.abstraction.alwaysAtLoop = no default value

# threshold for level of determinism, in percent, up-to which abstraction
# computations are performed (and iteration threshold was reached)
cpa.smg2.abstraction.determinismThreshold = no default value

# toggle liveness abstraction. Is independent of CEGAR, but dependent on the
# CFAs liveness variables being tracked.
cpa.smg2.abstraction.doLivenessAbstraction = no default value

# skip abstraction computations until the given number of iterations are
# reached, after that decision is based on then current level of determinism,
# setting the option to -1 always performs abstraction computations
cpa.smg2.abstraction.iterationThreshold = no default value

# The minimum list segments that are needed for abstraction may be increased
# during the analysis based on a heuristic in fixed sized loops. This is the
# maximum increase that is allowed. E.g. all lists with the length given here
# are abstracted in any case. If you want to prevent dynamic increase of list
# abstraction min threshold set this to the same value as
# listAbstractionMinimumLengthThreshold.
cpa.smg2.abstraction.listAbstractionMaximumIncreaseLengthThreshold = no default value

# The minimum list segments directly following each other with the same value
# needed to abstract them.Minimum is 2.
cpa.smg2.abstraction.listAbstractionMinimumLengthThreshold = no default value

# restrict liveness abstractions to nodes with more than one entering and/or
# leaving edge
cpa.smg2.abstraction.onlyAtNonLinearCFA = no default value

# Allocate memory on declaration of external variable
cpa.smg2.allocateExternalVariables = no default value

# Array allocation functions
cpa.smg2.arrayAllocationFunctions = no default value

# Use equality assumptions to assign values (e.g., (x == 0) => x = 0)
cpa.smg2.assignEqualityAssumptions = no default value

# Whether to perform caching of constraint satisfiability results
cpa.smg2.cache = no default value

# Whether to use subset caching
cpa.smg2.cacheSubsets = no default value

# Whether to use superset caching
cpa.smg2.cacheSupersets = no default value

# with this option enabled, memory addresses (pointers) are transformed into
# a numeric assumption upon casting the pointer to a number. This assumption
# can be returned to a proper pointer by casting it back. This enables
# numeric operations beyond pointer arithmetics, but loses precision for
# comparisons/assumptions, as the numeric assumption is static. May be
# unsound!
cpa.smg2.castMemoryAddressesToNumeric = no default value

# with this option enabled, a check for unreachable memory occurs whenever a
# function returns, and not only at the end of the main function
cpa.smg2.checkForMemLeaksAtEveryFrameDrop = no default value

# Crash on unknown value when creating constraints of any form.
cpa.smg2.crashOnUnknownInConstraint = no default value

# Deallocation functions
cpa.smg2.deallocationFunctions = no default value

# with this option enabled, heap abstraction will be enabled.
cpa.smg2.enableHeapAbstraction = no default value

# If this Option is enabled, failure of malloc is simulated
cpa.smg2.enableMallocFail = no default value

# Filename format for SMG graph dumps
cpa.smg2.exportSMG.file = no default value

# Describes when SMG graphs should be dumped.
cpa.smg2.exportSMGwhen = no default value
  enum:     [NEVER, LEAF, INTERESTING, EVERY]

# Functions which indicate on external allocated memory
cpa.smg2.externalAllocationFunction = no default value

# Default size of externally allocated memory
cpa.smg2.externalAllocationSize = no default value

# Allocation size of memory that cannot be calculated.
cpa.smg2.guessSize = no default value

# Size of memory that cannot be calculated will be guessed.
cpa.smg2.guessSizeOfUnknownMemorySize = no default value

# Handle external variables with incomplete type (extern int array[]) as
# external allocation
cpa.smg2.handleIncompleteExternalVariableAsExternalAllocation = no default value

# with this option enabled, memory that is not freed before the end of main
# is reported as memleak even if it is reachable from local variables in main
cpa.smg2.handleNonFreedMemoryInMainAsMemLeak = no default value

# Handle unknown dereference as safe and check error based on error
# predicate, depends on trackPredicates
cpa.smg2.handleUnknownDereferenceAsSafe = no default value

# Sets how unknown functions are handled.
cpa.smg2.handleUnknownFunctions = no default value
  enum:     [STRICT, ASSUME_SAFE, ASSUME_EXTERNAL_ALLOCATED]

# If this option is enabled, a memory allocation (e.g. malloc or array
# declaration) for unknown memory sizes does not abort, but also does not
# create any memory.
cpa.smg2.handleUnknownMemoryAllocation = no default value
  enum:     [IGNORE, MEMORY_ERROR, STOP_ANALYSIS]

# if there is an assumption like (x!=0), this option sets unknown
# (uninitialized) variables to 1L, when the true-branch is handled.
cpa.smg2.initAssumptionVars = no default value

# get an initial precision from file
cpa.smg2.initialPrecisionFile = no default value

# get an initial precision from a predicate precision file
cpa.smg2.initialPredicatePrecisionFile = no default value

# Perform merge SMGStates by SMGJoin on ends of code block. Works with
# 'merge=JOIN'
cpa.smg2.joinOnBlockEnd = no default value

# If this option is enabled, a call to malloc with value zero results in a
# return value that is equal to zero. If this option is disabled, a non-zero
# memory section that may not be accessed but freed is returned.
cpa.smg2.mallocZeroReturnsZero = no default value

# Memory allocation functions
cpa.smg2.memoryAllocationFunctions = no default value

# Size parameter of memory allocation functions
cpa.smg2.memoryAllocationFunctionsSizeParameter = no default value

# Position of element size parameter for array allocation functions
cpa.smg2.memoryArrayAllocationFunctionsElemSizeParameter = no default value

# Position of number of element parameter for array allocation functions
cpa.smg2.memoryArrayAllocationFunctionsNumParameter = no default value

# Determines if memory errors are target states
cpa.smg2.memoryErrors = no default value

# which merge operator to use for the SMGCPA
cpa.smg2.merge = no default value
  allowed values: [SEP]

# Whether to perform SAT checks only for the last added constraint
cpa.smg2.minimalSatCheck = no default value

# Assume that variables used only in a boolean context are either zero or
# one.
cpa.smg2.optimizeBooleanVariables = no default value

# If this Option is enabled, all values of a memory region that is written to
# with a symbolic and non unique offset are deleted and the value itself is
# overapproximated to unknown in the memory region.
cpa.smg2.overapproximateForSymbolicWrite = no default value

# If this Option is enabled, all values of a memory region that is written to
# with a symbolic and non-unique offset in symbolically sized memory are
# deleted and the value itself is overapproximated to unknown in the memory
# region.
cpa.smg2.overapproximateValuesForSymbolicSize = no default value

# with this option enabled, we try to gather information on memory reads from
# values that are overlapping but not exactly fitting to the read parameters.
# Example: int value = 1111; char a = (char)((char[])&value)[1];
cpa.smg2.preciseSMGRead = no default value

# target file to hold the exported precision
cpa.smg2.precisionFile = no default value

# whether or not to use heuristic to avoid similar, repeated refinements
cpa.smg2.refinement.avoidSimilarRepeatedRefinement = no default value

# Which base precision should be used for a new precision? ALL: During
# refinement, collect precisions from the complete ARG. SUBGRAPH: During
# refinement, keep precision from all removed parts (subgraph) of the ARG.
# CUTPOINT: Only the cut-point's precision is kept. TARGET: Only the target
# state's precision is kept.
cpa.smg2.refinement.basisStrategy = no default value
  enum:     [ALL, SUBGRAPH, TARGET, CUTPOINT]

# whether or not to do lazy-abstraction
cpa.smg2.refinement.doLazyAbstraction = no default value

# whether to perform (more precise) edge-based interpolation or (more
# efficient) path-based interpolation
cpa.smg2.refinement.performEdgeBasedInterpolation = no default value

# whether or not to do lazy-abstraction
cpa.smg2.refinement.restart = no default value
  enum:     [ROOT, PIVOT, COMMON]

# Resolve definite assignments
cpa.smg2.resolveDefinites = no default value

# Sets the level of runtime checking: NONE, HALF, FULL
cpa.smg2.runtimeCheck = no default value
  enum:     [FORCED, NONE, HALF, FULL]

# Which unknown function are always considered as safe functions, i.e., free
# of memory-related side-effects?
cpa.smg2.safeUnknownFunctions = no default value

# When to check the satisfiability of constraints
cpa.smg2.satCheckStrategy = no default value
  enum:     [AT_ASSUME, AT_TARGET]

# which stop operator to use for the SMGCPA
cpa.smg2.stop = no default value
  allowed values: [SEP, NEVER, END_BLOCK]

# Enable track predicates for possible memory safety error on SMG state
cpa.smg2.trackErrorPredicates = no default value

# Enable track predicates on SMG state
cpa.smg2.trackPredicates = no default value

# Treat symbolic values as unknowns and assign new concrete values to them.
cpa.smg2.treatSymbolicValuesAsUnknown = no default value

# Emit messages when we encounter non-target undefined behavior
cpa.smg2.unknownOnUndefined = no default value

# Allocation functions which set memory to zero
cpa.smg2.zeroingMemoryAllocation = no default value

# set this to true when you only want to do a code analysis. If StatisticsCPA
# is combined with other CPAs to do queries use false.
cpa.statistics.analysis = no default value

# which merge operator to use for StatisticsCPA? Ignored when analysis is set
# to true
cpa.statistics.mergeSep = no default value
  allowed values: [sep, join]

# count the number of traversed arithmetic operations.
cpa.statistics.metric.arithmeticOperationCount = no default value

# count the number of traversed variable definitions with array type.
cpa.statistics.metric.arrayVariablesCount = no default value

# count the number of traversed assume statements.
cpa.statistics.metric.assumeCount = no default value

# count the number of traversed bitwise operations.
cpa.statistics.metric.bitwiseOperationCount = no default value

# count the number of traversed edges with more then one outgoing edge.
cpa.statistics.metric.branchCount = no default value

# count the number of traversed dereference operations.
cpa.statistics.metric.dereferenceCount = no default value

# count the number of traversed variable definitions with floating type
# (float or double).
cpa.statistics.metric.floatVariablesCount = no default value

# count the number of traversed function calls.
cpa.statistics.metric.functionCallCount = no default value

# count the number of traversed function definitions.
cpa.statistics.metric.functionDefCount = no default value

# count the number of traversed global variable definitions.
cpa.statistics.metric.globalVariablesCount = no default value

# count the number of traversed gotos.
cpa.statistics.metric.gotoCount = no default value

# count the number of traversed variable definitions with integer type.
cpa.statistics.metric.integerVariablesCount = no default value

# count the number of traversed jumps.
cpa.statistics.metric.jumpCount = no default value

# count the number of traversed local variable definitions.
cpa.statistics.metric.localVariablesCount = no default value

# count the number of traversed loops.
cpa.statistics.metric.loopCount = no default value

# count the number of traversed nodes.
cpa.statistics.metric.nodeCount = no default value

# count the number of traversed variable definitions with pointer type.
cpa.statistics.metric.pointerVariablesCount = no default value

# count the number of traversed variable definitions with a complex structure
# type.
cpa.statistics.metric.structVariablesCount = no default value

# target file to hold the statistics
cpa.statistics.statisticsCPAFile = no default value

# Which refinement algorithm to use? (give class name, required for
# termination algorithm with CEGAR) If the package name starts with
# 'org.sosy_lab.cpachecker.', this prefix can be omitted.
cpa.termination.refiner = no default value

# Simple thread analysis from theory paper
cpa.thread.simpleMode = no default value

# The case when the same thread is created several times we do not support.We
# may skip or fail in this case.
cpa.thread.skipTheSameThread = no default value

# The case when the same thread is created several times we do not support.We
# may try to support it with self-parallelizm.
cpa.thread.supportSelfCreation = no default value

# allow assignments of a new thread to the same left-hand-side as an existing
# thread.
cpa.threading.allowMultipleLHS = no default value

# the maximal number of parallel threads, -1 for infinite. When combined with
# 'useClonedFunctions=true', we need at least N cloned functions. The option
# 'cfa.cfaCloner.numberOfCopies' should be set to N.
cpa.threading.maxNumberOfThreads = no default value

# in case of witness validation we need to check all possible function calls
# of cloned CFAs.
cpa.threading.useAllPossibleClones = no default value

# atomic locks are used to simulate atomic statements, as described in the
# rules of SV-Comp.
cpa.threading.useAtomicLocks = no default value

# do not use the original functions from the CFA, but cloned ones. See
# cfa.postprocessing.CFACloner for detail.
cpa.threading.useClonedFunctions = no default value

# local access locks are used to avoid expensive interleaving, if a thread
# only reads and writes its own variables.
cpa.threading.useLocalAccessLocks = no default value

# The max amount of refinements for the trace abstraction algorithm. Setting
# it to 0 leads to an analysis of the ARG without executing any refinements.
# This is used for debugging purposes.
cpa.traceabstraction.refinementStrategy.maxRefinementIterations = no default value

# which merge operator to use for UninitializedVariablesCPA?
cpa.uninitvars.merge = no default value
  allowed values: [sep, join]

# print warnings during analysis when uninitialized variables are used
cpa.uninitvars.printWarnings = no default value

# which stop operator to use for UninitializedVariablesCPA?
cpa.uninitvars.stop = no default value
  allowed values: [sep, join]

# functions, which stops analysis
cpa.usage.abortfunctions = no default value

# functions, which are used to bind variables (like list elements are binded
# to list variable)
cpa.usage.binderFunctions = no default value

# export counterexample core as text file
cpa.usage.export.witnessTemplate = no default value

# path to write results
cpa.usage.falseUnsafesOutput = no default value

# if a file do not exist, do not include the corresponding edge
cpa.usage.filterMissedFiles = no default value

# filtered unsafes, which can not be removed using precision, may be hidden
cpa.usage.hideFilteredUnsafes = no default value

# The functions, which cannot be executed in parallel with themselves
cpa.usage.notSelfParallelFunctions = no default value

# path to write results
cpa.usage.output = no default value

# all variables should be printed to the one file or to the different
cpa.usage.outputType = no default value
  enum:     [ETV, KLEVER, KLEVER_OLD]

# The way how to identify two paths as equal
cpa.usage.pathEquality = no default value
  enum:     [ARGStateId, CFANodeId]

# The value of marked unsafes, after which the precision should be cleaned
cpa.usage.precisionReset = no default value

# print all unsafe cases in report
cpa.usage.printFalseUnsafes = no default value

# output only true unsafes
cpa.usage.printOnlyTrueUnsafes = no default value

# print found unsafes in case of unknown verdict
cpa.usage.printUnsafesIfUnknown = no default value

# The order of refinement blocks
cpa.usage.refinementChain = no default value

# use single file for output or dump every error trace to its own file
cpa.usage.singleFileOutput = no default value

# The functions, which are executed in one thread
cpa.usage.singleThreadFunctions = no default value

# functions, which we don't analize
cpa.usage.skippedfunctions = no default value

# variables, which will be filtered by function location
cpa.usage.skippedvariables.byFunction = no default value

# variables, which will be filtered by function prefix
cpa.usage.skippedvariables.byFunctionPrefix = no default value

# variables, which will be filtered by its name
cpa.usage.skippedvariables.byName = no default value

# variables, which will be filtered by its name prefix
cpa.usage.skippedvariables.byNamePrefix = no default value

# variables, which will be filtered by its type
cpa.usage.skippedvariables.byType = no default value

# clean all ARG or try to reuse some parts of it (memory consuming)
cpa.usage.totalARGCleaning = no default value

# ignore unsafes only with empty callstacks
cpa.usage.unsafedetector.ignoreEmptyLockset = no default value

# A name of interrupt lock for checking deadlock free
cpa.usage.unsafedetector.intLock = no default value

# defines what is unsafe
cpa.usage.unsafedetector.unsafeMode = no default value
  enum:     [RACE, DEADLOCKCIRCULAR, DEADLOCKDISPATCH]

# functions, which are marked as write access
cpa.usage.writeAccessFunctions = no default value

# which merge operator to use for ValidVarsCPA
cpa.validVars.merge = no default value
  allowed values: [SEP, JOIN]

# restrict abstraction computations to branching points
cpa.value.abstraction.alwaysAtBranch = no default value

# restrict abstraction computations to function calls/returns
cpa.value.abstraction.alwaysAtFunction = no default value

# restrict abstraction computations to join points
cpa.value.abstraction.alwaysAtJoin = no default value

# restrict abstraction computations to loop heads
cpa.value.abstraction.alwaysAtLoop = no default value

# threshold for level of determinism, in percent, up-to which abstraction
# computations are performed (and iteration threshold was reached)
cpa.value.abstraction.determinismThreshold = no default value

# toggle liveness abstraction
cpa.value.abstraction.doLivenessAbstraction = no default value

# skip abstraction computations until the given number of iterations are
# reached, after that decision is based on then current level of determinism,
# setting the option to -1 always performs abstraction computations
cpa.value.abstraction.iterationThreshold = no default value

# restrict liveness abstractions to nodes with more than one entering and/or
# leaving edge
cpa.value.abstraction.onlyAtNonLinearCFA = no default value

# Allow the given extern functions and interpret them as pure functions
# although the value analysis does not support their semantics and this can
# produce wrong results.
cpa.value.allowedUnsupportedFunctions = no default value

# Use equality assumptions to assign values (e.g., (x == 0) => x = 0)
cpa.value.assignEqualityAssumptions = no default value

# configure when to export loop invariants
cpa.value.exportLoopInvariants = no default value
  enum:     [ALWAYS, IF_NOT_FALSE, IF_TRUE]

# Fixed set of values for function calls to VERIFIER_nondet_*. Does only
# work, if ignoreFunctionValueExceptRandom is enabled 
cpa.value.functionValuesForRandom = no default value

# Track or not function pointer values
cpa.value.ignoreFunctionValue = no default value

# If 'ignoreFunctionValue' is set to true, this option allows to provide a
# fixed set of values in the TestComp format. It is used for function-calls
# to calls of VERIFIER_nondet_*. The file is provided via the option
# functionValuesForRandom 
cpa.value.ignoreFunctionValueExceptRandom = no default value

# if there is an assumption like (x!=0), this option sets unknown
# (uninitialized) variables to 1L, when the true-branch is handled.
cpa.value.initAssumptionVars = no default value

# get an initial precision from file
cpa.value.initialPrecisionFile = no default value

# get an initial precision from a predicate precision file
cpa.value.initialPredicatePrecisionFile = no default value

# apply optimizations based on equality of input interpolant and candidate
# interpolant
cpa.value.interpolation.applyItpEqualityOptimization = no default value

# apply optimizations based on CFA edges with only variable-renaming
# semantics
cpa.value.interpolation.applyRenamingOptimization = no default value

# apply optimizations based on infeasibility of suffix
cpa.value.interpolation.applyUnsatSuffixOptimization = no default value

# whether or not to manage the callstack, which is needed for BAM
cpa.value.interpolation.manageCallstack = no default value

# Enable invariants that use  an arithmetic operator(linear invariants are
# enabled separately)
cpa.value.invExport.exportArithmetic = no default value

# Enable to export invariants that include two variables
cpa.value.invExport.exportBinary = no default value

# Enable invariants that use a bit operator
cpa.value.invExport.exportBitops = no default value

# Enable to export linear equalities or inequalities over variables, e.g., ax
# + by + c = 0, ax + bx + c <= 0, ax + bx + c >= 0, or ax + by + cy + d = 0
cpa.value.invExport.exportLinear = no default value

# Enable invariants that use a shift operator, note that additionally
# exportBitops must be enabled
cpa.value.invExport.exportShiftops = no default value

# Enable to export invariants that include three variables, currently only
# effective if exportLinear is enabled, too
cpa.value.invExport.exportTernary = no default value

# enable if loop invariant export should consider context
cpa.value.invExport.invariantsContextSensitive = no default value

# target file to hold the exported loop invariants
cpa.value.loopInvariantsFile = no default value

# which merge operator to use for ValueAnalysisCPA
cpa.value.merge = no default value
  allowed values: [SEP, JOIN]

# Assume that variables used only in a boolean context are either zero or
# one.
cpa.value.optimizeBooleanVariables = no default value

# target file to hold the exported precision
cpa.value.precisionFile = no default value

# whether or not to add assumptions to counterexamples, e.g., for supporting
# counterexample checks
cpa.value.refinement.addAssumptionsToCex = no default value

# whether or not to use heuristic to avoid similar, repeated refinements
cpa.value.refinement.avoidSimilarRepeatedRefinement = no default value

# Which base precision should be used for a new precision? ALL: During
# refinement, collect precisions from the complete ARG. SUBGRAPH: During
# refinement, keep precision from all removed parts (subgraph) of the ARG.
# CUTPOINT: Only the cut-point's precision is kept. TARGET: Only the target
# state's precision is kept.
cpa.value.refinement.basisStrategy = no default value
  enum:     [ALL, SUBGRAPH, TARGET, CUTPOINT]

# completely disable the tracking of found error paths in the refiner, i.e.,
# disable the detection of repeated counterexamples
cpa.value.refinement.disableErrorPathTracking = no default value

# whether or not to do lazy-abstraction
cpa.value.refinement.doLazyAbstraction = no default value

# when to export the interpolation tree
# NEVER:   never export the interpolation tree
# FINAL:   export the interpolation tree once after each refinement
# ALWAYS:  export the interpolation tree once after each interpolation, i.e.
# multiple times per refinement
cpa.value.refinement.exportInterpolationTree = no default value
  allowed values: [NEVER, FINAL, ALWAYS]

# export interpolation trees to this file template
cpa.value.refinement.interpolationTreeExportFile = no default value

# heuristic to sort targets based on the quality of interpolants derivable
# from them
cpa.value.refinement.itpSortedTargets = no default value

# File to which path constraints should be written.
cpa.value.refinement.pathConstraintsFile = no default value

# whether or not to perform path slicing before interpolation
cpa.value.refinement.pathSlicing = no default value

# whether to perform (more precise) edge-based interpolation or (more
# efficient) path-based interpolation
cpa.value.refinement.performEdgeBasedInterpolation = no default value

# which prefix of an actual counterexample trace should be used for
# interpolation
cpa.value.refinement.prefixPreference = no default value

# whether or not to do lazy-abstraction
cpa.value.refinement.restart = no default value
  enum:     [ROOT, PIVOT, COMMON]

# instead of reporting a repeated counter-example, search and refine another
# error-path for the same target-state.
cpa.value.refinement.searchForFurtherErrorPaths = no default value

# store all refined paths
cpa.value.refinement.storeAllRefinedPaths = no default value

# if this option is set to false, constraints are never kept
cpa.value.refinement.trackConstraints = no default value

# whether to use the top-down interpolation strategy or the bottom-up
# interpolation strategy
cpa.value.refinement.useTopDownInterpolationStrategy = no default value

# Whether to write symbolic trace (including path constraints) for found
# erexamples
cpa.value.refinement.writePathConstraints = no default value

# Overall timelimit for computing initial value precision from given
# predicate precision(use seconds or specify a unit; 0 for infinite)
cpa.value.reuse.precision.predicate.adaptionLimit = no default value

# also consider other binary operators then ==, !== when considering control
# dependencies while adapting predicate precision
cpa.value.reuse.precision.predicate.includeControlNonEquiv = no default value

# comma-separated list of files with property specifications that should be
# considered when determining the relevant edges for predicate precision
# adaption
cpa.value.reuse.precision.predicate.relevantProperties = no default value

# which strategy to use to convert predicate to value precision
cpa.value.reuse.precision.predicate.strategy = no default value
  enum:     [CONVERT_ONLY, CONVERT_AND_ADD_FLOW_BACKWARD,
             CONVERT_AND_ADD_FLOW_BIDIRECTED]

# also consider control dependencies during adaption of predicate precision
cpa.value.reuse.precision.predicate.useControl = no default value

# which stop operator to use for ValueAnalysisCPA
cpa.value.stop = no default value
  allowed values: [SEP, JOIN, NEVER, EQUALS]

# Default size of arrays whose length can't be determined.
cpa.value.symbolic.defaultArraySize = no default value

# If this option is set to true, an own symbolic identifier is assigned to
# each array slot when handling non-deterministic arrays of fixed length. If
# the length of the array can't be determined, it won't be handled in either
# cases.
cpa.value.symbolic.handleArrays = no default value

# Whether to handle non-deterministic pointers in symbolic value analysis.
cpa.value.symbolic.handlePointers = no default value

# If this option is set to true, an own symbolic identifier is assigned to
# each struct member when handling non-deterministic structs.
cpa.value.symbolic.handleStructs = no default value

# Whether to try to not use any constraints in refinement
cpa.value.symbolic.refinement.avoidConstraints = no default value

# The refinement strategy to use
cpa.value.symbolic.refinement.strategy = no default value
  enum:     [CONSTRAINTS_FIRST, VALUES_FIRST, ALTERNATING, VALUES_ONLY]

# Whether to simplify symbolic expressions, if possible.
cpa.value.symbolic.simplifySymbolics = no default value

# Track Java array values in explicit value analysis. This may be costly if
# the verified program uses big or lots of arrays. Arrays in C programs will
# always be tracked, even if this value is false.
cpa.value.trackJavaArrayValues = no default value

# Tells the value analysis how to handle unknown values.
cpa.value.unknownValueHandling = no default value
  enum:     [DISCARD, INTRODUCE_SYMBOLIC]

# Specify simple custom instruction by specifying the binary operator op. All
# simple cis are of the form r = x op y. Leave empty (default) if you specify
# a more complex custom instruction within code.
custominstructions.binaryOperatorForSimpleCustomInstruction = no default value
  enum:     [MULTIPLY, DIVIDE, MODULO, PLUS, MINUS, SHIFT_LEFT, SHIFT_RIGHT, LESS_THAN,
             GREATER_THAN, LESS_EQUAL, GREATER_EQUAL, BINARY_AND, BINARY_XOR, BINARY_OR,
             EQUALS, NOT_EQUALS]

# Name of function containing the custom instruction definition
custominstructions.ciFun = no default value

# Signature for custom instruction, describes names and order of input and
# output variables of a custom instruction
custominstructions.ciSignature = no default value

# File specifying start locations of custom instruction applications
# File to dump start location of identified custom instruction applications
custominstructions.definitionFile = no default value

# Where to dump the requirements on custom instruction extracted from
# analysis
custominstructions.dumpCIRequirements = no default value

# Try to remove parts of requirements that are not related to custom
# instruction and are, thus, irrelevant for custom instruction behavior
custominstructions.enableRequirementsSlicing = no default value

# Specifies the mode how custom instruction applications in program are
# identified.
custominstructions.mode = no default value
  enum:     [MANUAL, OPERATOR, AUTOMATIC]

# Try to remove requirements that are covered by another requirment and are,
# thus, irrelevant for custom instruction behavior
custominstructions.removeCoveredRequirements = no default value

# Qualified name of class for abstract state which provides custom
# instruction requirements.
custominstructions.requirementsStateClassName = no default value

# Option to change the behaviour of the loop detection for generating the
# Counterexample-C-Code that will probably be used to generate invariants.
# Note that last loop means the first loop encountered when backwards
# traversing the given ARGPath, thus, the last loop may contain other loops,
# which are in turn also counted to the last loop.
cwriter.withLoops.loopDetectionStrategy = no default value
  enum:     [ALL_LOOPS, ONLY_LAST_LOOP]

# toggle checking forward conditions
dar.checkForwardConditions = no default value

# toggle falling back if interpolation or forward-condition is disabled
dar.fallBack = no default value

# toggle removing unreachable stop states in ARG
dar.removeUnreachableStopStates = no default value

# toggle replace global phase with BMC
dar.replaceGlobalPhaseWithBMC = no default value

# When checking for the data race property, use this configuration file
# instead of the current one.
datarace.config = no default value

# Whether to consider pointees. Only if this option is set to true, a pointer
# analysis is run during system dependence graph (SDG) construction and
# dependencies of pointees are inserted into the SDG. If this option is set
# to false, pointers are completely ignored and the resulting SDG is an
# under-approximation that lacks all pointee dependencies.
dependencegraph.considerPointees = no default value

# Whether to take an assumption edge 'p' as control dependence if edge 'not
# p' is a control dependence. This creates a larger slice, but may reduce the
# size of the state space for deterministic programs. This behavior is also
# closer to the static program slicing based on control-flow graphs (CFGs),
# where branching is represented by a single assumption (with true- and
# false-edges)
dependencegraph.controldeps.considerInverseAssumption = no default value

# Whether to consider control dependencies.
dependencegraph.controldeps.use = no default value

# File to export dependence graph to. If `null`, dependence graph will not be
# exported as dot.
dependencegraph.exportDot = no default value

# Whether to consider (data-)flow dependencies.
dependencegraph.flowdeps.use = no default value

# Whether to include only functions reachable from the main function in the
# dependence graph.
dependencegraph.onlyReachableFunctions = no default value

# The maximum duration a single pointer analysis method is allowed to run
# (use seconds or specify a unit; 0 for infinite).
dependencegraph.pointerAnalysisTime = no default value

# The computation methods used for pointer analysis. If no method is
# specified, an imprecise over-approximation of the global pointer state is
# created without running any actual pointer analysis. If at least one
# computation method is specified, the first one in the list is run with the
# time limit set by 'dependencegraph.pointerAnalysisTime'. If this method is
# able to create a valid global pointer state in time, the state is used and
# no other methods are run. Otherwise, if a second computation method is
# specified, the second method is run with the same time limit. If the method
# is able to create a valid global pointer state in time, the state is used
# and no other methods are run. The same is true for all subsequent
# computation methods specified in the list. If no computation method is able
# to create a valid global pointer state in time, an imprecise
# over-approximation of the global pointer state is created without running
# any actual pointer analysis. A pointer analysis is only run if
# 'dependencegraph.considerPointees' is set to true. Available computation
# methods: PointerStateComputationMethod.FLOW_SENSITIVE,
# PointerStateComputationMethod.FLOW_INSENSITIVE
dependencegraph.pointerStateComputationMethods = no default value

# comma-separated list of files with property specifications that should be
# considered when determining the nodes that are in the reachability
# property.
differential.badstateProperties = no default value

# ignore declarations when detecting modifications, be careful when variables
# are renamed (could be unsound)
differential.ignoreDeclarations = no default value

# perform assumption implication check
differential.implicationCheck = no default value

# perform preprocessing to detect states from which error locations are
# reachable
differential.performPreprocessing = no default value

# Program to check against
differential.program = no default value

# safely stop analysis on pointer accesses and similar
differential.stopOnPointers = no default value

# Switch on/off to form the union of variable sets at identical location
# pairs. Set cpa.automaton.deleteDoubleEdges as well!
differential.variableSetMerge = no default value

# Abstraction nodes are added to each block after they are created. They are
# needed to strengthen the preconditions of blocks. Missing blocks make the
# analysis slower but not impossible.
distributedSummaries.allowMissingAbstractionNodes = no default value

# The number of blocks is dependent by the number of functions in the
# program.A tolerance of 1 means, that we subtract 1 of the total number of
# functions.
distributedSummaries.allowSingleBlockDecompositionWhenMerging = no default value

# Where to store the block graph in JSON format
distributedSummaries.blockCFAFile = no default value

# Allows to set the algorithm for decomposing the CFA. LINEAR_DECOMPOSITION
# creates blocks from each merge/branching point to the next merge/branching
# point. MERGE_DECOMPOSITION merges blocks obtained by LINEAR_DECOMPOSITION.
# The final number of blocks should converge to the number of functions in
# the program. NO_DECOMPOSITION creates one block around the CFA.
distributedSummaries.decompositionType = no default value
  enum:     [LINEAR_DECOMPOSITION, MERGE_DECOMPOSITION, BRIDGE_DECOMPOSITION,
             NO_DECOMPOSITION]

# Whether to stop after exporting the blockgraph
distributedSummaries.generateBlockGraphOnly = no default value

# Import an existing decomposition from a file
distributedSummaries.importDecomposition = no default value

# List of input files that contain preconditions and verification conditions
# that should be assumed as 'known' by block-summary analysis. Each file must
# contain a single, valid JSON BlockSummaryMessage. If at least one file is
# provided, the block-summary analysis assumes these pre- and
# verification-conditions. If no file is provided, the block-summary analysis
# assumes the precondition 'true' and the verification condition 'false'.
# List of input files that contain preconditions and verification conditions
# that should be assumed as 'known' by block-summary analysis. Each file must
# contain a single, valid JSON DSSMessage. If at least one file is provided,
# the block-summary analysis assumes these pre- and verification-conditions.
# If no file is provided, the block-summary analysis assumes the precondition
# 'true' and the verification condition 'false'.
distributedSummaries.knownConditions = no default value

# List of input files that contain preconditions and verification conditions
# that should be assumed as 'new' by block-summary analysis. For each message
# in this list, block-summary analysis will perform a new analysis run in the
# order of occurrence. Each file must contain a single, valid JSON
# BlockSummaryMessage. If at least one file is provided, the block-summary
# analysis assumes these pre- and verification-conditions. If no file is
# provided, the block-summary analysis assumes the precondition 'true' and
# the verification condition 'false'.
# List of input files that contain preconditions and verification conditions
# that should be assumed as 'new' by block-summary analysis. For each message
# in this list, block-summary analysis will perform a new analysis run in the
# order of occurrence. Each file must contain a single, valid JSON
# DSSMessage. If at least one file is provided, the block-summary analysis
# assumes these pre- and verification-conditions. If no file is provided, the
# block-summary analysis assumes the precondition 'true' and the verification
# condition 'false'.
distributedSummaries.newConditions = no default value

# Where to write responses
distributedSummaries.outputMessages = no default value

# Write readable formulas to log file.
distributedSummaries.predicate.writeReadableFormulas = no default value

# Change the queue type. ERRROR_CONDITION prioritizes the processing
# ofErrorConditionMessages. DEFAULT does not differ between PostCondition and
# ErrorCondition messages.
distributedSummaries.queue = no default value
  enum:     [ERROR_CONDITION, DEFAULT]

# Whether to spawn util workers. Util workers listen to every message and
# create visual output for debugging. Workers consume resources and should
# not be used for benchmarks.
distributedSummaries.spawnUtilWorkers = no default value

# Whether to spawn a worker for only one block id
distributedSummaries.spawnWorkerForId = no default value

# How workers should behave. Unlike DSS, INVARIANTS works with guessed
# summaries.
distributedSummaries.strategy = no default value
  enum:     [DSS, INVARIANTS]

# Configuration for forward analysis in computation of distributed summaries
distributedSummaries.worker.forwardConfiguration = no default value

# Destination directory for the logfiles of all BlockSummaryWorkers. The
# logfiles have the same name as the ID of the worker.
distributedSummaries.worker.logDirectory = no default value

# output file for visualizing message exchange
dss.logging.reportFiles = no default value

# Enable to use lazy refinement in current analysis instead of restarting
# from root after each refinement.
enabledanalysis.allowLazyRefinement = no default value

# Which CPA is used as enabler in the current analysis.
enabledanalysis.enablerCPA = no default value
  enum:     [APRON, INTERVAL, OCTAGON, PREDICATE, VALUE]

# Ranking algorithm to use for fault localization
faultLocalization.by_coverage.type = no default value
  enum:     [TARANTULA, DSTAR, OCHIAI]

# Configuration to use for initial program-state exploration
faultLocalization.by_distance.analysis = no default value

# The distance metric that ought to be used for the computation of the
# distance
faultLocalization.by_distance.metric = no default value
  enum:     [ADM, CFDM, PG]

# Maximum number of explorations to run for collecting error paths, before
# performing fault localization.  Exploration runs stop when the program
# under analysis is fully explored or the specified number of runs is
# reached. Fault localization may be more precise if more error paths are
# available.
faultLocalization.by_distance.stopAfter = no default value

# whether to include variables beginning with
# __FAULT_LOCALIZATION_precondition
faultLocalization.by_traceformula.includeDeclared = no default value

# Do not show faults that contain a certain variable. Use, e.g., 'main::x' to
# ban variable 'x' in the main function. Use, e.g., '::x' to ban all
# variables named 'x'. This is especially useful to filter specific faults if
# the first run results in many candidates. Provide a comma separated string
# to add variables, e.g., main::x,doStuff::y,::z
faultLocalization.by_traceformula.maxsat.ban = no default value

# which post-condition type to use
faultLocalization.by_traceformula.postConditionType = no default value
  enum:     [LAST_ASSUME_EDGE, LAST_ASSUME_EDGES_ON_SAME_LINE,
             LAST_ASSUME_EDGE_CLUSTER]

# By default, the precondition only contains the failing variable assignment
# of all nondet variables. Choose INITIAL_ASSIGNMENT to add assignments like
# '<datatype> <variable-name> = <value>' to the precondition.
faultLocalization.by_traceformula.preconditionType = no default value
  enum:     [NONDETERMINISTIC_VARIABLES_ONLY, INITIAL_ASSIGNMENT, ALWAYS_TRUE]

# Whether the found counterexample needs to be precise
faultLocalization.by_traceformula.requirePreciseCounterexample = no default value

# Whether to stop searching for further faults if first fault was found.
faultLocalization.by_traceformula.stopAfterFirstFault = no default value

# which algorithm to use
faultLocalization.by_traceformula.type = no default value
  enum:     [UNSAT, MAXSAT, MAXORG, ERRINV]

# Whether to zip the resulting JSON file.
faultLocalization.export.compressed = no default value

# Where to write machine readable faults.
faultLocalization.export.outputFile = no default value

# Whether to run specified analysis
faultLocalization.import.algorithmActivated = no default value

# which explanations to use
faultLocalization.import.explanations = no default value

# path to the input json file with faults
faultLocalization.import.importFile = no default value

# which scoring functions to use
faultLocalization.import.scorings = no default value

# Configuration for programs containing more than @Option adressedRatio
# addressed vars.
heuristicSelection.addressedConfig = no default value

# Ratio of addressed vars. Values bigger than the passed value lead to
# @option addressedConfig.
heuristicSelection.addressedRatio = no default value

# Configuration for programs containing arrays.
heuristicSelection.arrayConfig = no default value

# Configuration for programs with loops and complex datastructures.
heuristicSelection.complexLoopConfig = no default value

# Configuration for programs containing composite types.
heuristicSelection.compositeTypeConfig = no default value

# Configuration for programs with loops.
heuristicSelection.loopConfig = no default value

# Configuration for loop-free programs.
heuristicSelection.loopFreeConfig = no default value

# Configuration for programs containing only relevant bool vars.
heuristicSelection.onlyBoolConfig = no default value

# Configuration for preliminary algorithm.
heuristicSelection.preAnalysisAlgorithmConfig = no default value

# Configuration for programs containing recursion.
heuristicSelection.recursionConfig = no default value

# Configuration for programs with a single loop.
heuristicSelection.singleLoopConfig = no default value

# toggle asserting targets at every iteration for IMC
imc.assertTargetsAtEveryIteration = no default value

# toggle whether to compute fixed-point backward by swapping initial-state
# (prefix) and assertion (target) formulas
imc.backwardAnalysis = no default value

# toggle checking forward conditions
imc.checkForwardConditions = no default value

# toggle checking whether the safety property is inductive
imc.checkPropertyInductiveness = no default value

# toggle falling back if interpolation or forward-condition is disabled
imc.fallBack = no default value

# toggle which strategy is used for computing fixed points in order to verify
# programs with loops. ITP enables IMC algorithm, and ITPSEQ enables ISMC
# algorithm. ITPSEQ_AND_ITP runs ISMC first, and if a fixed point is not
# reached by ISMC, IMC is invoked.
imc.fixedPointComputeStrategy = no default value
  enum:     [NONE, ITP, ITPSEQ, ITPSEQ_AND_ITP]

# toggle Impact-like covering for the ISMC fixed-point check
imc.impactLikeCovering = no default value

# toggle the strategy to determine the next loop iteration
# to execute BMC phase of IMC or ISMC
# CONST: increased by one (to guarantee a shortest counterexample)
# EAGER: skip all iterations where a bug cannot be found
imc.loopBoundIncrementStrategyForBMC = no default value
  enum:     [CONST, EAGER]

# toggle the strategy to determine the next loop iteration
# to execute interpolation phase of IMC
# CONST: increased by a constant (specified via
# loopBoundIncrementValueForIMC)
# EAGER: skip all iterations where a bug cannot be found
imc.loopBoundIncrementStrategyForIMC = no default value
  enum:     [CONST, EAGER]

# toggle the strategy to determine the next loop iteration
# to execute k-inductive check if "checkPropertyInductiveness" is enabled
# CONST: increased by by a constant (specified via
# loopBoundIncrementValueForKI)
# EAGER: skip all iterations where a bug cannot be found
imc.loopBoundIncrementStrategyForKI = no default value
  enum:     [CONST, EAGER]

# toggle the value to increment the loop bound by at each step for IMC
imc.loopBoundIncrementValueForIMC = no default value

# toggle the value to increment the loop bound by at each step for KI
imc.loopBoundIncrementValueForKI = no default value

# toggle removing unreachable stop states in ARG
imc.removeUnreachableStopStates = no default value

# enable the Forced Covering optimization
impact.useForcedCovering = no default value

# Configuration file for the K-Induction algorithm for checking candidates on
# invariance.
invariantChecker.kInductionConfig = no default value

# configuration file for invariant generation
invariantGeneration.config = no default value

# Check candidate invariants in a separate thread asynchronously.
invariantGeneration.kInduction.async = no default value

# Guess some candidates for the k-induction invariant generator from the CFA.
invariantGeneration.kInduction.guessCandidatesFromCFA = no default value
  enum:     [NONE, ASSUME_EDGES_PLAIN, ASSUME_EDGE_TEMPLATES, LINEAR_TEMPLATES]

# Provides additional candidate invariants to the k-induction invariant
# generator.
invariantGeneration.kInduction.invariantsAutomatonFile = no default value

# For correctness-witness validation: Shut down if a candidate invariant is
# found to be incorrect.
invariantGeneration.kInduction.terminateOnCounterexample = no default value

# Specify the class code path to search for java class or interface
# definitions
java.classpath = no default value

# use the following encoding for java files
java.encoding = no default value

# export TypeHierarchy as .dot file
java.exportTypeHierarchy = no default value

# Specify the source code path to search for java class or interface
# definitions
java.sourcepath = no default value

# export TypeHierarchy as .dot file
java.typeHierarchyFile = no default value

# Specifies the java version of source code accepted
java.version = no default value

# Programming language of the input program. If not given explicitly,
# auto-detection will occur
# C, Java, or LLVM IR?
language = no default value
  enum:     [C, JAVA, LLVM]

# Limit for cpu time used by CPAchecker (use seconds or specify a unit; -1
# for infinite)
limits.time.cpu = no default value

# Limit for thread cpu time used by CPAchecker. This option will in general
# not work when multi-threading is used in more than one place, use only with
# great caution! (use seconds or specify a unit; -1 for infinite)
limits.time.cpu.thread = no default value

# Enforce that the given CPU time limit is set as the value of
# limits.time.cpu.
limits.time.cpu::required = no default value

# Limit for wall time used by CPAchecker (use seconds or specify a unit; -1
# for infinite)
limits.time.wall = no default value

# By changing this option one can adjust the way how live variables are
# created. Function-wise means that each function is handled separately,
# global means that the whole cfa is used for the computation.
liveVar.evaluationStrategy = no default value
  enum:     [FUNCTION_WISE, GLOBAL]

# Overall timelimit for collecting the liveness information.(use seconds or
# specify a unit; 0 for infinite)
liveVar.overallLivenessCheckTime = no default value

# Timelimit for collecting the liveness information with one approach, (p.e.
# if global analysis is selected and fails in the specified timelimit the
# function wise approach will have the same time-limit afterwards to compute
# the live variables).(use seconds or specify a unit; 0 for infinite)
liveVar.partwiseLivenessCheckTime = no default value

# Write the tokenized version of the input program to this file.
locmapper.dumpTokenizedProgramToFile = no default value

# all used options are printed
log.usedOptions.export = no default value

# When checking for memory cleanup properties, use this configuration file
# instead of the current one.
memorycleanup.config = no default value

# When checking for memory safety properties, use this configuration file
# instead of the current one.
memorysafety.config = no default value

# which merge operator to use for LiveVariablesCPA
merge = no default value
  allowed values: [SEP, JOIN]

# List of property-files to be run by the subprocesses.
mpiAlgorithm.configFiles = no default value

# The MCA parameter ('Modular Component Architecture') is available only on
# Open MPI frameworks. It might thus need to be disabled if unavailable on
# the working machine.
mpiAlgorithm.disableMCAOptions = no default value

# File containing the ip addresses to be used by MPI.
mpiAlgorithm.hostfile = no default value

# Max. amount of processes to be used by MPI.
mpiAlgorithm.numberProcesses = no default value

# Find all violations of each checked property.
mpv.findAllViolations = no default value

# Ignore exceptions, which may be caused by checking of some properties, to
# successfully check the others.
mpv.ignoreInnerExceptions = no default value

# Adjust resource limitations during the analysis.
# - NONE: do not adjust resource limitations (default).
# - DISTRIBUTE_REMAINING: distribute resources, which were allocated for some
# already checked property, but were not fully spent, between other
# properties, which are still checking.
# - DISTRIBUTE_BY_PROPERTY: scale resources for each property in accordance
# with the given ratio in the property distribution file.
mpv.limits.adjustmentStrategy = no default value
  enum:     [NONE, DISTRIBUTE_REMAINING, DISTRIBUTE_BY_PROPERTY]

# Set CPU time limit per each property in multi-property verification (use
# seconds or specify a unit; -1 to disable)
mpv.limits.cpuTimePerProperty = no default value

# Change resource limitations for the first partition by the given ratio.
# This option will be ignored if NONE limits adjustment strategy is used.
mpv.limits.firstPartitionRatio = no default value

# The ratio of CPU time limit in the first phase of Joint partitioning
# operator to CPU time limit per each property.
mpv.limits.joint.firstPhaseRatio = no default value

# Get a resource limitation distribution per property from file. This option
# should be used only together with DISTRIBUTE_BY_PROPERTY limits adjustment
# strategy. The following format should be used in the file:
# '<property name>':<ratio>
mpv.limits.propertyDistributionFile = no default value

# The ratio of CPU time limit in the first phase of Relevance partitioning
# operator to CPU time limit per each property.
mpv.limits.relevance.firstPhaseRatio = no default value

# The ratio of CPU time limit in the second phase of Relevance partitioning
# operator to CPU time limit per each property.
mpv.limits.relevance.secondPhaseRatio = no default value

# Partitioning operator for multi-property verification.
mpv.partitionOperator = no default value

# Specifies how to separate a single property.
# - FILE: each .spc file represent a single property (i.e., property is
# represented by several automata).
# - AUTOMATON: each automaton represent a single property.
mpv.propertySeparator = no default value
  enum:     [FILE, AUTOMATON]

# Check for unsigned integer overflows
overflow.checkUnsigned = no default value

# When checking for the overflow property, use this configuration file
# instead of the current one.
overflow.config = no default value

# Simplify overflow assumptions.
overflow.simplifyExpressions = no default value

# Track overflows in additive(+/-) operations.
overflow.trackAdditiveOperations = no default value

# Track overflows in division(/ or %) operations.
overflow.trackDivisions = no default value

# Track overflows in left-shift operations.
overflow.trackLeftShifts = no default value

# Track overflows in multiplication operations.
overflow.trackMultiplications = no default value

# Track overflows in binary expressions involving pointers.
overflow.trackPointers = no default value

# Only check live variables for overflow, as compiler can remove dead
# variables.
overflow.useLiveness = no default value

# List of files with configurations to use. Files can be suffixed with
# ::supply-reached this signalizes that the (finished) reached set of an
# analysis can be used in other analyses (e.g. for invariants computation).
# If you use the suffix ::supply-reached-refinable instead this means that
# the reached set supplier is additionally continously refined (so one of the
# analysis has to be instanceof ReachedSetAdjustingCPA) to make this work
# properly.
parallelAlgorithm.configFiles = no default value

# The command line for calling the clang preprocessor. May contain binary
# name and arguments, but won't be expanded by a shell. The source file name
# will be appended to this string. Clang needs to print the output to stdout.
parser.clang = no default value

# Whether to dump the results of the preprocessor to disk.
parser.clang.dumpResults = no default value

# Whether to collect ACSL annotations if present
parser.collectACSLAnnotations = no default value

# C dialect for parser
parser.dialect = no default value
  enum:     [C99, GNUC]

# The command line for calling the preprocessor. May contain binary name and
# arguments, but won't be expanded by a shell. The source file name will be
# appended to this string. The preprocessor needs to print the output to
# stdout.
parser.preprocessor = no default value

# Directory where to dump the results of the preprocessor.
parser.preprocessor.dumpDirectory = no default value

# Whether to dump the results of the preprocessor to disk for debugging.
parser.preprocessor.dumpResults = no default value

# For C files, read #line preprocessor directives and use their information
# for outputting line numbers. (Always enabled when pre-processing is used.)
parser.readLineDirectives = no default value

# Preprocess the given C files before parsing: Put every single token onto a
# new line. Then the line number corresponds to the token number.
parser.transformTokensToLines = no default value

# For C files, convert to LLVM IR with clang first and then use the LLVM
# parser.
parser.useClang = no default value

# For C files, run the preprocessor on them before parsing. Note that all
# line numbers printed by CPAchecker will refer to the pre-processed file,
# not the original input file.
parser.usePreprocessor = no default value

# Specifies the mode how HW requirements are detected in the proof.
pcc.HWrequirements.extraction.mode = no default value
  enum:     [MANUAL, OPERATOR, AUTOMATIC]

# Enable if used property checker implements satisfiesProperty(AbstractState)
# and checked property is violated for a set iff an element in this set
# exists for which violates the property
pcc.arg.checkPropertyPerElement = no default value

# Enable to store ARG states instead of abstract states wrapped by ARG state
pcc.backwardtargets.certificateStatesAsARGStates = no default value

# List of files with configurations to use. 
pcc.cmc.configFiles = no default value

# write collected assumptions to file
pcc.cmc.file = no default value

# collects information about value analysis states in proof
pcc.collectValueAnalysisStateInfo = no default value

# The number of cores used exclusively for proof reading. Must be less than
# pcc.useCores and may not be negative. Value 0 means that the cores used for
# reading and checking are shared
pcc.interleaved.useReadCores = no default value

# enables parallel checking of partial certificate
pcc.parallel.io.enableParallelCheck = no default value

# Selects the strategy used for partial certificate construction
pcc.partial.certificateType = no default value
  enum:     [ALL, HEURISTIC, ARG, MONOTONESTOPARG]

# If enabled, distributes checking of partial elements depending on actual
# checking costs, else uses the number of elements
pcc.partial.enableLoadDistribution = no default value

# Enables proper PCC but may not work correctly for heuristics. Stops adding
# newly computed elements to reached set if size saved in proof is reached.
# If another element must be added, stops certificate checking and returns
# false.
pcc.partial.stopAddingAtReachedSetSize = no default value

# [Best-first] Balance criterion for pairwise optimization of partitions
pcc.partitioning.bestfirst.balancePrecision = no default value

# Evaluation function to determine exploration order of best-first-search
pcc.partitioning.bestfirst.chosenFunction = no default value
  enum:     [BREADTH_FIRST, DEPTH_FIRST, BEST_IMPROVEMENT_FIRST]

# Balance criterion for pairwise optimization of partitions
pcc.partitioning.fm.balanceCriterion = no default value

# Heuristic for computing an initial partitioning of proof
pcc.partitioning.fm.initialPartitioningStrategy = no default value
  enum:     [RANDOM]

# [FM-k-way] Balance criterion for pairwise optimization of partitions
pcc.partitioning.kwayfm.balancePrecision = no default value

# [FM-k-way] Partitioning method to compute initial partitioning.
pcc.partitioning.kwayfm.globalHeuristic = no default value
  enum:     [RANDOM, DFS, BFS, BEST_IMPROVEMENT_FIRST]

# [FM-k-way] Local optimization criterion to be minimized druing
# Fiduccia/Mattheyses refinment
pcc.partitioning.kwayfm.optimizationCriterion = no default value
  enum:     [EDGECUT, NODECUT]

# Specifies the maximum size of the partition. This size is used to compute
# the number of partitions if a proof (reached set) should be written.
# Default value 0 means always a single partition.
pcc.partitioning.maxNumElemsPerPartition = no default value

# Partitioning method applied in multilevel heuristic to compute initial
# partitioning.
pcc.partitioning.multilevel.globalHeuristic = no default value
  enum:     [RANDOM, DFS, BFS, BEST_IMPROVEMENT_FIRST]

# Matching method applied to coarsen graph down in multilevel heuristic.
pcc.partitioning.multilevel.matchingGenerator = no default value
  enum:     [RANDOM, HEAVY_EDGE]

# Refinement method applied in multilevel heuristic's uncoarsening phase.
pcc.partitioning.multilevel.refinementHeuristic = no default value
  enum:     [FM_NODECUT, FM_EDGECUT]

# Heuristic for computing partitioning of proof (partial reached set).
pcc.partitioning.partitioningStrategy = no default value
  enum:     [RANDOM, DFS, BFS, OPTIMAL, BEST_FIRST, FM, FM_K_WAY, MULTILEVEL]

# If enabled uses the number of nodes saved in certificate to compute
# partition number otherwise the number of states explored during analysis
pcc.partitioning.useGraphSizeToComputePartitionNumber = no default value

# file in which proof representation needed for proof checking is stored
pcc.proof = no default value

# file in which proof representation will be stored
pcc.proofFile = no default value

# Generate and dump a proof
pcc.proofgen.doPCC = no default value

# Configuration for proof checking if differs from analysis configuration
pcc.resultcheck.checkerConfig = no default value

# Enable to write proof and read it again for validation instead of using the
# in memory solution
pcc.resultcheck.writeProof = no default value

# Make proof more abstract, remove some of the information not needed to
# prove the property.
pcc.sliceProof = no default value

# writes the validation configuration required for checking to proof
pcc.storeConfig = no default value

# Qualified name for class which implements certification strategy, hence
# proof writing, to be used.
pcc.strategy = no default value

# number of cpus/cores which should be used in parallel for proof checking
pcc.useCores = no default value

# Which strategy to use to perform abstraction of successful proof results or
# when lifting with the lifting strategy ABSTRACTION_BASED_LIFTING.
pdr.abstractionStrategy = no default value
  enum:     [NO_ABSTRACTION, ALLSAT_BASED_PREDICATE_ABSTRACTION]

# Whether to adjust conditions (i.e. increment k) after frontier extension.
pdr.conditionAdjustmentCriterion = no default value
  enum:     [NEVER, ALWAYS]

# Which strategy to use to perform invariant refinement on successful proof
# results.
pdr.invariantRefinementStrategy = no default value
  enum:     [NO_STRENGTHENING, UNSAT_CORE_BASED_STRENGTHENING]

# Maximum number of ignored lifting abstraction failures within a
# proof-obligation trace.
pdr.liftingAbstractionFailureThreshold = no default value

# Which strategy to use to abstract counterexamples to inductivity.
pdr.liftingStrategy = no default value
  enum:     [NO_LIFTING, UNSAT_CORE_BASED_LIFTING, ABSTRACTION_BASED_LIFTING]

# Maximum number of accepted spurious transitions within a proof-obligation
# trace before a consecution abstraction failure triggers a refinement.
pdr.spuriousTransitionCountThreshold = no default value

# Format to use for image output
pixelgraphic.export.format = no default value

# Height of the bitmap in pixels. If set to -1, height is  computed in
# relation to the width. If both are set to -1, the optimal bitmap size to
# represent the graph is used. The final height is height*scaling
pixelgraphic.export.height = no default value

# Scaling of the bitmap. If set to 1, 1 pixel represents one graph node. If
# set to 2, 2 * 2 pixels represent one graph node, and so on.
pixelgraphic.export.scaling = no default value

# Highlight not only corresponding graph nodes, but background of
# corresponding line, too. This may give an better overview, but also
# introduces more clutter
pixelgraphic.export.strongHighlight = no default value

# Width of the bitmap in pixels. If set to -1, width is computed in relation
# to the height. If both are set to -1, the optimal bitmap size to represent
# the graph is used. The final width is width*scaling
pixelgraphic.export.width = no default value

# Padding of the bitmap on the left and right (each) in pixels
pixelgraphic.export.xPadding = no default value

# Padding of the bitmap on the top and bottom (each) in pixels
pixelgraphic.export.yPadding = no default value

# A path to a precision output
# A path to precision
precision.path = no default value

# whether to track relevant variables only at the exact program location
# (sharing=location), or within their respective (function-/global-) scope
# (sharing=scoped).
precision.sharing = no default value
  enum:     [SCOPE, LOCATION]

# Allowed coefficients in a template.
precision.template.allowedCoefficients = no default value

# Generate difference constraints.This option is redundant for
# `maxExpressionSize` >= 2.
precision.template.generateDifferences = no default value

# Generate templates from assert statements
precision.template.generateFromAsserts = no default value

# Generate templates from all program statements
precision.template.generateFromStatements = no default value

# Force the inclusion of function parameters into the generated templates.
# Required for summaries computation.
precision.template.includeFunctionParameters = no default value

# Maximum size for the generated template
precision.template.maxExpressionSize = no default value

# Perform refinement using enumerative template synthesis.
precision.template.performEnumerativeRefinement = no default value

# Do not generate templates with threshold larger than specified. Set to '-1'
# for no limit.
precision.template.templateConstantThreshold = no default value

# Strategy for filtering variables out of templates using liveness
precision.template.varFiltering = no default value
  enum:     [INTERPOLATION_BASED, ALL_LIVE, ONE_LIVE, ALL]

# If this option is used, variables that are addressed may get tracked
# depending on the rest of the precision. When this option is disabled, a
# variable that is addressed is definitely not tracked.
precision.trackAddressedVariables = no default value

# If this option is used, booleans from the cfa are tracked.
precision.trackBooleanVariables = no default value

# If this option is used, variables that have type double or float are
# tracked.
precision.trackFloatVariables = no default value

# If this option is used, variables, that are only used in simple
# calculations (add, sub, lt, gt, eq) are tracked.
precision.trackIntAddVariables = no default value

# If this option is used, variables that are only compared for equality are
# tracked.
precision.trackIntEqualVariables = no default value

# If this option is used, variables that are irrelevantare also tracked.
precision.trackIrrelevantVariables = no default value

# If this option is used, all variables that are of a different
# classification than IntAdd, IntEq and Boolean get tracked by the precision.
precision.trackVariablesBesidesEqAddBool = no default value

# blacklist regex for variables that won't be tracked by the CPA using this
# precision
precision.variableBlacklist = no default value

# whitelist regex for variables that will always be tracked by the CPA using
# this precision
precision.variableWhitelist = no default value

# where to export conditions
program.splitter.conditionFile = no default value

# export program splitting as conditions (assumption automata)
program.splitter.exportAsCondition = no default value

# Which program split heuristic to use
program.splitter.heuristic = no default value

# maximal number
program.splitter.max = no default value

# Quantifier elimination strategy
rcnf.boundVarsHandling = no default value
  enum:     [QE_LIGHT_THEN_DROP, QE, DROP]

# Expand equality atoms. E.g. 'x=a' gets expanded into 'x >= a AND x <= a'.
# Can lead to stronger weakenings.
rcnf.expandEquality = no default value

# Limit on the size of the resulting number of lemmas from the explicit
# expansion
rcnf.expansionResultSizeLimit = no default value

# print reached set to graph file
reachedSet.dot = no default value

# print reached set to text file
reachedSet.export = no default value
reachedSet.file = no default value

# Generate HTML report with analysis result.
report.export = no default value

# File name for analysis report in case no counterexample was found.
report.file = no default value

# set path to file which contains the condition
residualprogram.assumptionFile = no default value

# set specification file to automaton which guides analysis along assumption
# produced by incomplete analysis,e.g.,
# config/specification/AssumptionGuidingAutomaton.spc, to enable residual
# program from combination of program and assumption condition
residualprogram.assumptionGuider = no default value

# Export CFA of residual program as pixel graphic to the given file name. The
# suffix is added corresponding to the value of option
# pixelgraphic.export.formatIf set to 'null', no pixel graphic is exported.
residualprogram.cfa.pixelGraphicFile = no default value

# Export residual program as pixel graphic
residualprogram.export.pixel = no default value

# write residual program to file
residualprogram.file = no default value

# Define kind of folder to use when combining condition with folding approach
# in residual program generation
residualprogram.folderType = no default value
  enum:     [CFA, FOLD_EXCEPT_LOOPS, LOOP_ALWAYS, LOOP_BOUND, LOOP_BOUND_SAME_CONTEXT,
             LOOP_SAME_CONTEXT]

# Collect statistical data about size of residual program
residualprogram.statistics.size = no default value

# which strategy to use to generate the residual program
residualprogram.strategy = no default value
  enum:     [REACHABILITY, SLICING, CONDITION, CONDITION_PLUS_FOLD, COMBINATION]

# How often may a loop be unrolled before it must be folded
residualprogram.unrollBound = no default value

# wether to start next algorithm independently from the previous result
restartAlgorithm.alwaysRestart = no default value

# widen (partial) ARGs obtained by restarts of the analysis after an unknown
# result with a different configuration
restartAlgorithm.combineARGsAfterRestart = no default value

# List of files with configurations to use. A filename can be suffixed with
# :if-interrupted, :if-failed, and :if-terminated which means that this
# configuration will only be used if the previous configuration ended with a
# matching condition. What also can be added is :use-reached then the reached
# set of the preceding analysis is taken and provided to the next analysis.
restartAlgorithm.configFiles = no default value

# print the statistics of each component of the restart algorithm directly
# after the components computation is finished
restartAlgorithm.printIntermediateStatistics = no default value

# let each component of the restart algorithm write output files and not only
# the last one that is excuted
restartAlgorithm.writeIntermediateOutputFiles = no default value

# path to condition file
slicing.conditionFile = no default value

# path to condition files plus additional assumption guiding automaton when
# condition itself is in propriertary format and not in witness format
slicing.conditionFiles = no default value

# Export the used slicing criteria to file
slicing.exportCriteria.enable = no default value

# File template for export of used slicing criteria
slicing.exportCriteria.file = no default value

# Whether to export slices as C program files
slicing.exportToC.enable = no default value

# File template for exported C program slices
slicing.exportToC.file = no default value

# Whether to export program slices as DOT files.
slicing.exportToDot.enable = no default value

# File template for exported program slice DOT files.
slicing.exportToDot.file = no default value

# which type of extractor for slicing criteria to use
slicing.extractor = no default value
  enum:     [ALL, REDUCER, SYNTAX]

# Whether to allow edges in the resulting slice that are only partially
# relevant (e.g. function calls where not every parameter is relevant).
# Setting this parameter to true can decrease the size of the resulting
# slice.
slicing.partiallyRelevantEdges = no default value

# what kind of slicing to use
slicing.type = no default value
  enum:     [STATIC, IDENTITY]

# Extract and cache unsat cores for satisfiability checking
solver.cacheUnsatCores = no default value

# improve sat-checks with additional constraints for UFs
solver.checkUFs = no default value

# whether CPAchecker's logger should be used as logger for the solver,
# otherwise nothing is logged from the solver.
solver.enableLoggingInSolver = no default value

# Which solver to use specifically for interpolation (default is to use the
# main one).
solver.interpolationSolver = no default value
  enum:     [MATHSAT5, SMTINTERPOL, Z3, PRINCESS, BOOLECTOR, CVC4, CVC5, YICES2]

# Which SMT solver to use.
solver.solver = no default value
  enum:     [MATHSAT5, SMTINTERPOL, Z3, PRINCESS, BOOLECTOR, CVC4, CVC5, YICES2]

# Comma-separated list of files with specifications that should be checked
# (cf. config/specification/ for examples). Property files as used in SV-COMP
# can also be used here, but when these are specified inside a configuration
# file instead of on the command line, CPAchecker will ignore the entry
# function in the property file.
specification = no default value

# export abstract states as formula, e.g. for re-using them as
# PredicatePrecision.
statesToFormulas.exportFile = no default value

# export formulas for all program locations or just the important
# locations,which include loop-heads, funtion-calls and function-exits.
statesToFormulas.exportOnlyImporantLocations = no default value

# instead of writing the exact state-representation as a single formula,
# write its atoms as a list of formulas. Therefore we ignore operators for
# conjunction and disjunction.
statesToFormulas.splitFormulas = no default value
  enum:     [LOCATION, STATE, ATOM]

# Add all assumptions from the control flow automaton to the precision.
staticRefiner.addAllControlFlowAssumes = no default value

# Add all assumptions along a error trace to the precision.
staticRefiner.addAllErrorTraceAssumes = no default value

# Add all assumptions along the error trace to the precision.
staticRefiner.addAssumesByBoundedBackscan = no default value

# Apply mined predicates on the corresponding scope. false = add them to the
# global precision.
staticRefiner.applyScoped = no default value

# Dump CFA assume edges as SMTLIB2 formulas to a file.
staticRefiner.assumePredicatesFile = no default value

# split generated heuristic predicates into atoms
staticRefiner.atomicPredicates = no default value

# collect at most this number of assumes along a path, backwards from each
# target (= error) location
staticRefiner.maxBackscanPathAssumes = no default value

# write some statistics to disk
statistics.export = no default value
statistics.file = no default value

# track memory usage of JVM during runtime
statistics.memory = no default value

# print statistics to console
statistics.print = no default value

# which stop operator to use for LiveVariablesCPA
stop = no default value
  allowed values: [SEP, JOIN, NEVER]

# compress the produced violation-witness automata using GZIP compression.
termination.compressWitness = no default value

# When checking for the termination property, use this configuration file
# instead of the current one.
termination.config = no default value

# enable to also analyze whether recursive calls terminate
termination.considerRecursion = no default value

# Number of generalized eigenvectors in the geometric nontermination
# argument.
termination.lassoAnalysis.eigenvectors = no default value

# Shell command used to call the external SMT solver.
termination.lassoAnalysis.externalSolverCommand = no default value

# Analysis type used for synthesis of linear termination arguments.
termination.lassoAnalysis.linear.analysisType = no default value
  enum:     [DISABLED, LINEAR, LINEAR_WITH_GUESSES, NONLINEAR]

# If true, an external tool is used as SMT solver instead of SMTInterpol.
# This affects only synthesis of linear termination arguments.
termination.lassoAnalysis.linear.externalSolver = no default value

# Maximal number of functions used in a ranking function template.
termination.lassoAnalysis.maxTemplateFunctions = no default value

# Number of non-strict supporting invariants for each Motzkin transformation
# during synthesis of termination arguments.
termination.lassoAnalysis.nonStrictInvariants = no default value

# Analysis type used for synthesis of non-linear termination arguments.
termination.lassoAnalysis.nonlinear.analysisType = no default value
  enum:     [DISABLED, LINEAR, LINEAR_WITH_GUESSES, NONLINEAR]

# If true, an external tool is used as SMT solver instead of SMTInterpol.
# This affects only synthesis of non-linear termination arguments and
# non-termination arguments.
termination.lassoAnalysis.nonlinear.externalSolver = no default value

# Number of strict supporting invariants for each Motzkin transformation
# during synthesis of termination arguments.
termination.lassoAnalysis.strictInvariants = no default value

# Simplifies loop and stem formulas.
termination.lassoBuilder.simplify = no default value

# maximal number of repeated ranking functions per loop before stopping
# analysis
termination.maxRepeatedRankingFunctionsPerLoop = no default value

# Strategy used to prepare reched set and ARG for next iteration after
# successful refinement of the termination argument.
termination.resetReachedSetStrategy = no default value
  enum:     [REMOVE_TARGET_STATE, REMOVE_LOOP, RESET]

# A human readable representation of the synthesized (non-)termination
# arguments is exported to this file.
termination.resultFile = no default value

# consider counterexamples for loops for which only pointer variables are
# relevant or which check that pointer is unequal to null pointer to be
# imprecise
termination.useCexImpreciseHeuristic = no default value

# Export termination counterexample to file as GraphML automaton 
termination.violation.witness = no default value

# Export termination counterexample to file as dot/graphviz automaton 
termination.violation.witness.dot = no default value

# compress the produced violation-witness automata using GZIP compression.
terminationtoreach.compressWitness = no default value

# do not produce witness for validation
terminationtoreach.validation = no default value

# Export termination counterexample to file as GraphML automaton 
terminationtoreach.violation.witness = no default value

# Export termination counterexample to file as dot/graphviz automaton 
terminationtoreach.violation.witness.dot = no default value

# Only genenerate for __VERIFIER_nondet calls
testHarnessExport.onlyVerifierNondet = no default value

# Provide dummy values for external variable declarations. This is useful
# when definitions are not implemented yet or missing. But it may introduce
# conflicts with values from standard libraries.
testHarnessExport.provideDummyValues = no default value

# Use the counterexample model to provide test-vector values
testHarnessExport.useModel = no default value

# zip all exported test cases into a single file
testcase.compress = no default value

# Do not output values for variables that are not initialized when declared
testcase.excludeInitialization = no default value

# export test harness to file as code
testcase.file = no default value

# set to true if run multiple test case generation instances in parallel
testcase.generate.parallel = no default value

# display all test targets and non-covered test targets in statistics
testcase.inStats = no default value

# how many mutated test cases should be additionally generated (disabled if
# <= 0)
testcase.mutants = no default value

# Random seed for mutation of test cases
testcase.mutationSeed = no default value

# Number of random test cases that should be generated
testcase.numRandomTests = no default value

# Only convert literal value and do not add suffix, e.g., for unsigned, etc.
testcase.plainLiteralValue = no default value

# defines how progress is computed
testcase.progress = no default value
  enum:     [ABSOLUTE, RELATIVE_TOTAL]

# Maximum value randomly generated
testcase.random.max = no default value

# Number of random test cases that should be generated
testcase.random.maxLength = no default value

# Minimum value randomly generated
testcase.random.min = no default value

# Random seed for random test-case generation
testcase.randomInputSeed = no default value

# when generating tests covering error call stop as soon as generated one
# test case and report false (only possible in combination with error call
# property specification
testcase.reportCoveredErrorCallAsError = no default value

# CFA edge if only a specific edge should be considered, e.g., in
# counterexample check
testcase.targets.edge = no default value

# Name of target function if target type is FUN_CALL
testcase.targets.funName = no default value

# Set to enable optimizations to be applied to result of previous
# optimizations
testcase.targets.optimization.nested = no default value

# Which strategy or which strategies (comma separated list of strategies) to
# use to optimize set of test target edges. If more than one strategy is
# provided, all strategies are applied and if targets.optimization.nested is
# disabled the smallest result is taken otherwise see description of option
# targets.optimization.nested.If no strategy is provided, no optimization is
# performed. 
testcase.targets.optimization.strategy = no default value

# enable to track coverage of test targets removed in optimization
testcase.targets.optimization.trackAll = no default value

# Which CFA edges to use as test targets
testcase.targets.type = no default value
  enum:     [ASSUME, TEST_COMP_ASSUME, ERROR_CALL, FUN_CALL, STATEMENT]

# export test values to file (line separated)
testcase.values = no default value

# export test cases to xm file (Test-Comp format)
testcase.xml = no default value

# Zip file into which all test case files are bundled
testcase.zip.file = no default value

# Usually every statement that is not part of the precondition gets a
# selector. If a certain variable is known to not cause the error, add it to
# this option, e.g., main::x,doStuff::y
traceformula.disable = no default value

# The alternative precondition consists of all initial variable assignments
# and a failing variable assignment for all nondet variables. By default only
#  variables in the main function are part of the precondition. Overwrite the
# default by adding functions to this option, e.g., "main,doStuff"
traceformula.filter = no default value

# The alternative precondition consists of all initial variable assignments.
# If a variable assignment seems suspicious, it might be useful to exclude it
# from the precondition. To do this, add these variables to this option,
# e.g., main::x,doStuff::y. Make sure to add the function in which the
# variable is used as prefix, separated by two ':'
traceformula.ignore = no default value

# if enabled, nondet declarations get a selector, otherwise they don't
traceformula.inlinePrecondition = no default value

# Make trace formula flow-sensitive, i.e., assume edges imply the edges that
# are only reachable through the assume edge. Flow-sensitive traces remove
# assume edges from the trace. Hence, no assume edge will be part of a fault.
traceformula.makeFlowSensitive = no default value

# By default, every executed statement gets its own selector. If a loop is
# part of the program to analyze, the number of selectors can increase which
# also increases the run time of max-sat drastically. To use the same
# selector for equal statements (on the same line), set this option to true.
# Note that enabling this option  also decreases the quality of results.
traceformula.reduceSelectors = no default value

# Ignore functions that are defined by C11
undefinedFunctionsCollector.allowC11Functions = no default value

# Ignore functions that are defined by GNU C and not by C11/POSIX
undefinedFunctionsCollector.allowGnuCFunctions = no default value

# Ignore functions that are defined by POSIX
undefinedFunctionsCollector.allowPosixFunctions = no default value

# Set of functions that should be ignored
undefinedFunctionsCollector.allowedFunctions = no default value

# Regexp matching function names that are allowed to be undefined
undefinedFunctionsCollector.allowedFunctionsRegexp = no default value

# Regexp matching function names that need not be declared
undefinedFunctionsCollector.allowedUndeclaredFunctionsRegexp = no default value

# Memory-allocation function that will be used in stubs
undefinedFunctionsCollector.externAllocFunction = no default value

# export undefined functions as C file
undefinedFunctionsCollector.stubsFile = no default value

# select an analysis from a set of analyses after unknown result
useCompositionAnalysis = no default value

# Whether or not one wants to refine MemorySafety errors.
util.refinement.refineMemorySafety = no default value

# Instead of comments, output the assertions into the original program as
# violations to unreach_call.prp
wacsl.makeDirectAssertions = no default value

# The directory where generated, ACSL annotated programs are stored.
wacsl.outDir = no default value

# Makes the annotated file's name identical to the original source file's
# name.
wacsl.useSameFileName = no default value

# The witness from which ACSL annotations should be generated.
wacsl.witness = no default value

# File for exporting the witness automaton in DOT format.
witness.automatonDumpFile = no default value

# remove assumptions from transitions in the ISA where they are not strictly
# neccessary.This option is intended to be used with an ISA (c.f. option
# witness.invariantsSpecificationAutomaton)
witness.checkInvariantViolations = no default value

# Check that the value of the programhash field of the witness matches the
# SHA-256 hash value computed for the source code.
witness.checkProgramHash = no default value

# Consider assumptions that are provided with the path automaton?
witness.considerAssumptions = no default value

# Fail-fast if invariants in the witness exist that would not be accounted
# for. There are cases where unaccounted invariants are perfectly fine, e.g.
# if those states in the witness automaton are actually unreachable in the
# program. This is however rarely the intention of the original producer of
# the witness, so this options can be used to debug those cases.
witness.debug.checkForMissedInvariants = no default value

# Validate correctness witness by specifying an invariants specification
# automaton
witness.invariantsSpecificationAutomaton = no default value
  enum:     [NO_ISA, WITNESSBASED_ISA, TWOSTATES_ISA, CFABASED_ISA]

# Match the branching information at a branching location.
witness.matchAssumeCase = no default value

# Match the character offset within the file.
witness.matchOffset = no default value

# Match the line numbers within the origin (mapping done by preprocessor line
# markers).
witness.matchOriginLine = no default value

# This option can be used to ensure that no correctness witnesses are
# checked.
witness.noCorrectnessValidation = no default value

# This option can be used to ensure that no violation witnesses are checked.
witness.noViolationValidation = no default value

# remove assumptions from transitions in the ISA where they are not strictly
# neccessary.This option is intended to be used with an ISA (c.f. option
# witness.invariantsSpecificationAutomaton)
witness.optimizeInvariantsSpecificationAutomaton = no default value

# Represent sink states by bottom state instead of break state
witness.stopNotBreakAtSinkStates = no default value

# Enforce strict validity checks regarding the witness format, such as
# checking for the presence of required fields.
witness.strictChecking = no default value

# remove assumptions from transitions in the ISA where they are not strictly
# neccessary.This option is intended to be used with an ISA (c.f. option
# witness.invariantsSpecificationAutomaton)
witness.useInvariantsAsAssumptions = no default value

# extend name of each witness automaton with a unique id
witness.useUniqueName = no default value

# Validate program using invariants from ACSL annotations.
witness.validation.correctness.acsl = no default value

# When validating a correctness witness, use this configuration file instead
# of the current one.
witness.validation.correctness.config = no default value

# Use correctness witness as invariants specification automaton (ISA).
witness.validation.correctness.isa = no default value

# The witness to validate.
witness.validation.file = no default value

# Use this configuration when checking that when reach recurrent set,
# execution can be extended to an infinite one
witness.validation.termination.inspectCycle.config = no default value

# Use this configuration when checking that recurrent set (at cycle head) is
# reachable. Configuration must be precise, i.e., may only report real
# counterexamples
witness.validation.termination.reachCycle.config = no default value

# Report a successful validation of the witness, i.e., a confirmation of the
# nontermination, as termination violation.
witness.validation.termination.successAsViolation = no default value

# Path to automaton specification describing which statements let the program
# terminate.
witness.validation.termination.terminatingStatements = no default value

# When validating a violation witness, use this configuration file instead of
# the current one.
witness.validation.violation.config = no default value

# Export all information contained in the counterexample as a witness.
witness.yamlexporter.exportCompleteCounterexample = no default value

# The version for which to export the witness.
witness.yamlexporter.witnessVersions = no default value
