{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "License\n",
    "---\n",
    "This file is part of CPAchecker, a tool for configurable software verification:  \n",
    "https://cpachecker.sosy-lab.org\n",
    "\n",
    "SPDX-FileCopyrightText: 2020 Dirk Beyer (https://www.sosy-lab.org)\n",
    "\n",
    "SPDX-License-Identifier: Apache-2.0\n",
    "\n",
    "\n",
    "Instructions\n",
    "---\n",
    "*description*\n",
    "<br>You can set a threshold to substract the start-up time of CPAchecker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold in seconds. \n",
    "# Increase the time limit by <threshold> seconds to substract the time CPAchecker needs to start. Only applied on sequential analysis.\n",
    "threshold = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary to get tablegenerator versions >= 3.8 to work\n",
    "import decimal\n",
    "decimal.DefaultContext.rounding = decimal.ROUND_HALF_UP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell provides the util methods to convert the result sets to pandas dataframe format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from benchexec import tablegenerator\n",
    "import benchexec.result\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Optional, List, Union, Tuple\n",
    "from dataclasses import dataclass\n",
    "import os\n",
    "\n",
    "UNK = \"ERR/UNKNOWN/TIMEOUT\"\n",
    "\n",
    "def get_data(data_files: Union[List[str], str], table_definition=None) -> List[pd.DataFrame]:\n",
    "    if not isinstance(data_files, str):\n",
    "        return [d for f in data_files for d in get_data(f, table_definition)]\n",
    "    raw_data = _load_data(data_files, table_definition)\n",
    "    return [pd.DataFrame(data=_get_values(raw_data), columns=_get_column_titles(raw_data))]\n",
    "\n",
    "\n",
    "def _load_data(data_file: str, table_definition: Optional[str]=None) -> tablegenerator.RunSetResult:\n",
    "    parser = tablegenerator.create_argument_parser()\n",
    "    args = [data_file]\n",
    "    if table_definition:\n",
    "        args += ['-x', table_definition]\n",
    "    options = parser.parse_args(args)\n",
    "    if table_definition:\n",
    "        parsed_tabledef = tablegenerator.parse_table_definition_file(table_definition)\n",
    "        return list(tablegenerator.load_results_with_table_definition([data_file], parsed_tabledef, table_definition, options))[0]\n",
    "    else:\n",
    "        return tablegenerator.load_result(data_file, options)\n",
    "\n",
    "    \n",
    "def _get_column_titles(result_set: tablegenerator.RunSetResult):\n",
    "    return ['task_id', 'category'] + [col.title for col in result_set.columns]\n",
    "\n",
    "\n",
    "def _get_values(result_set):\n",
    "    return [[r.task_id[0], r.category] + cast_values(r) for r in result_set.results]\n",
    "\n",
    "\n",
    "def cast_values(r: tablegenerator.RunResult):\n",
    "    return [to_value(value, column) for value, column in zip(r.values, r.columns)]\n",
    "\n",
    "\n",
    "def to_value(value, column):\n",
    "    if not column.is_numeric() or value is None:\n",
    "        return value\n",
    "    if column.unit is None:\n",
    "        return value\n",
    "    return float(value[:-len(column.unit)])\n",
    "\n",
    "\n",
    "def merge_columns(category, status):\n",
    "    merge_dict = {\n",
    "        (\"correct\", \"false(unreach-call)\"): \"TP\",\n",
    "        (\"wrong\", \"false(unreach-call)\"): \"FP\",\n",
    "        (\"correct\", \"true\"): \"TN\",\n",
    "        (\"wrong\", \"true\"): \"FN\"\n",
    "    }\n",
    "    if (category, status) in merge_dict:\n",
    "        return merge_dict[(category, status)]\n",
    "    return UNK\n",
    "\n",
    "\n",
    "def read_benchmarks(*data_files):\n",
    "    frames = []\n",
    "    for df in get_data(data_files):\n",
    "        # skip tables with missing columns (e.g. analysis was aborted)\n",
    "        if not {'cputime', 'status', 'category'}.issubset(df.columns):\n",
    "            print(\"Skipped table because it is missing columns. The first 5 rows: \")\n",
    "            print(df.head(5))\n",
    "            frames.append(pd.DataFrame(columns=['task_id', 'result', 'cputime']))\n",
    "            continue\n",
    "        # skip aborted tasks\n",
    "        df = df[df['category'] != \"aborted\"]\n",
    "        df = df.drop(columns=['host'], errors='ignore')\n",
    "        df['result'] = df.apply(lambda row: merge_columns(row['category'], row['status']), axis=1)\n",
    "        frames.append(df[COLUMNS_USED])\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following methods are used to work with feature vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NamedTuple\n",
    "class FeatureVector(NamedTuple):\n",
    "    has_floats: int = -1\n",
    "    has_array: int = -1\n",
    "    has_recursion: int = -1\n",
    "    has_composite_handling: int = -1\n",
    "    has_loop: int = -1\n",
    "    has_alias_handling: int = -1\n",
    "\n",
    "    def matches(self, fv):\n",
    "        for elem in zip(self,fv):\n",
    "            if elem[0] == -1 or elem[1] == -1:\n",
    "                continue\n",
    "            if (elem[0] != elem[1]):\n",
    "                return False\n",
    "        return True\n",
    "    \n",
    "    def find_match(self, lookup: list):\n",
    "        for key in lookup:\n",
    "            if not isinstance(key, FeatureVector):\n",
    "                raise ValueError(f\"Key in given sequence not of type 'FeatureVector': {key}\")\n",
    "            if key.matches(self):\n",
    "                return key\n",
    "        raise ValueError(f\"Given sequence did contain no matching key. Did you forget the default case? Sequence: {lookup}\")\n",
    "    \n",
    "    @staticmethod\n",
    "    def from_dataframe_row(row):\n",
    "        return FeatureVector(row['has_floats'],\n",
    "                             row['has_arrays'],\n",
    "                             row['has_recursion'],\n",
    "                             row['has_composite_handling'],\n",
    "                             row['has_loop'],\n",
    "                             row['has_alias_handling'])\n",
    "\n",
    "    \n",
    "FeatureVector.default = FeatureVector()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following methods are used to calculate the final score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_frames(input_sets, sequential=False):\n",
    "    frames = []\n",
    "    for (df, timelimit) in input_sets:\n",
    "        if not timelimit:\n",
    "            frames.append(df)\n",
    "            continue\n",
    "        if sequential and threshold and frames:\n",
    "            df.cputime = df.cputime - threshold\n",
    "        condition = df.cputime > timelimit\n",
    "        df.loc[condition, 'result'] = UNK\n",
    "        df.loc[condition, 'cputime'] = timelimit\n",
    "        frames.append(df)\n",
    "    return frames\n",
    "\n",
    "\n",
    "def _join(frames):\n",
    "    join = sequence[0]\n",
    "    for idx, candidate in enumerate(sequence[1:], start=1):\n",
    "        join = pd.merge(join.copy(), candidate.copy(), left_on=\"task_id\", right_on=\"task_id\", suffixes=('', f'_{idx}'), how=\"outer\")\n",
    "    return join\n",
    "\n",
    "\n",
    "def sequential(*input_sets):\n",
    "    sequence = prepare_frames(input_sets, sequential=True)\n",
    "    join = _join(sequence)\n",
    "    results = join[COLUMNS_USED]\n",
    "    for idx, _ in enumerate(sequence[1:], start=1):\n",
    "        mask = (results.result == UNK)\n",
    "        if not results[mask].empty:\n",
    "            results.loc[mask,'result'] = join.loc[mask, f'result_{idx}']\n",
    "            results.loc[mask,'cputime'] = results.loc[mask,'cputime'] + join.loc[mask, f'cputime_{idx}']\n",
    "    return results\n",
    "\n",
    "\n",
    "def parallel(*input_sets):\n",
    "    prepared = prepare_frames([(df, None) for df in input_sets])\n",
    "    prepared = prepared[COLUMNS_USED]\n",
    "    distinct_ids = prepared.task_id.unique()\n",
    "    results = pd.DataFrame(columns = prepared.columns)\n",
    "    # loop through every distinct key\n",
    "    for key in distinct_ids:\n",
    "        selection = prepared[prepared['task_id'] == key]\n",
    "        col_result_distinct = selection.result.unique()\n",
    "        # if all results are unknown the tasks takes max(cputime)\n",
    "        if len(col_result_distinct) == 1:\n",
    "            if col_result_distinct[0] == UNK:\n",
    "                max_time = selection['cputime'].max()\n",
    "                new_row = pd.DataFrame([[key, UNK, max_time]], columns=prepared.columns)\n",
    "                results = results.append(new_row)\n",
    "                continue\n",
    "        # otherwise return result of first analysis that finishes min(cputime | result != \"UNKNOWN\")\n",
    "        selection = selection[selection['result'] != UNK]\n",
    "        selection = selection[selection['cputime'] == selection['cputime'].min()].head(1)\n",
    "        results = results.append(selection)\n",
    "    return results\n",
    "\n",
    "\n",
    "def select(fv_table, config):\n",
    "    df = pd.DataFrame(columns=fv_table.columns)\n",
    "    for index, row in fv_table.iterrows():\n",
    "        fv = FeatureVector.from_dataframe_row(row)\n",
    "        selected = config[fv.find_match(config.keys())]\n",
    "        selected_row = selected[selected[\"task_id\"] == row[\"task_id\"]]\n",
    "        df = pd.concat([df,selected_row])\n",
    "    return df\n",
    "        \n",
    "\n",
    "def evaluate(df):\n",
    "    counts = df.result.value_counts()\n",
    "    average_time = int(df.cputime.mean())\n",
    "    time = pd.Series([average_time], index=['Average time'])\n",
    "    return counts.append(time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 2 strategies available:\n",
    "- sequential:\n",
    "```\n",
    "simulates the sequential execution of all given analyses\n",
    "| analysis 0 | analysis 1 | ... | analysis n |\n",
    "```\n",
    "<br>\n",
    "- parallel:\n",
    "```file2\n",
    "simulates the parallel execution of all given analyses\n",
    "|      analysis 0     |\n",
    "|      analysis 1     |\n",
    "|      analysis 2     |\n",
    "```\n",
    "\n",
    "All analyses simulate an execution where the calculation terminates as soon as a result different from \"UNKNOWN\", \"ERROR\" or \"TIMEOUT\" occurs (if possible)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMNS_USED = ['task_id', 'result', 'cputime']\n",
    "\n",
    "# define your tasks here\n",
    "result_files = {\n",
    "    'valueAnalysis': 'results/svcomp21--bare--configs.2020-11-12_15-42-21.results.valueAnalysis.xml.bz2',\n",
    "    'valueAnalysis-itp': 'results/svcomp21--bare--configs.2020-11-12_15-42-21.results.valueAnalysis-itp.xml.bz2',\n",
    "    'predicateAnalysis': 'results/svcomp21--bare--configs.2020-11-12_15-42-21.results.predicateAnalysis.xml.bz2',\n",
    "    'bmc': 'results/svcomp21--bare--configs.2020-11-12_15-42-21.results.bmc.xml.bz2',\n",
    "}\n",
    "\n",
    "results = {\n",
    "    key: read_benchmarks(results_file)[0]\n",
    "    for key, results_file in result_files.items()\n",
    "}\n",
    "featureExtraction = get_data('results/featureExtraction.2020-11-13_14-08-04.results.SV-COMP21_unreach-call.ReachSafety-ECA.xml.bz2',\n",
    "                            table_definition='table-featureVectors.xml')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a configuration for feature vectors. A vector has 6 attributes with values `1, 0, -1`. Value `1` translates to `True`, `0` to `False` and `-1` to 'irrelevant'.\n",
    "\n",
    "Here you can see an example for a configuration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define your configuration here. Paths must be specified relative to the directory of this notebook.\n",
    "\n",
    "bmc = results['bmc']\n",
    "value_predicate_bmc = sequential((results['valueAnalysis'], 90),\n",
    "                         (results['valueAnalysis-itp'], 60),\n",
    "                         (results['predicateAnalysis'], 200),\n",
    "                         (bmc, None))\n",
    "\n",
    "value_bmc = sequential((results['valueAnalysis'], 90),\n",
    "                     (results['valueAnalysis-itp'], None),\n",
    "                     (bmc, None))\n",
    "\n",
    "configuration = {\n",
    "    FeatureVector(has_loop=0): bmc,\n",
    "    FeatureVector(has_loop=1, has_composite_handling=0): value_predicate_bmc,\n",
    "    FeatureVector.default: value_bmc,\n",
    "}\n",
    "\n",
    "strategy_selection = select(featureExtraction, configuration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
