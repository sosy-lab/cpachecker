{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "License\n",
    "---\n",
    "This file is part of CPAchecker,<br>\n",
    "a tool for configurable software verification:<br>\n",
    "https://cpachecker.sosy-lab.org<br>\n",
    "<br>\n",
    "SPDX-FileCopyrightText: 2020 Dirk Beyer <https://www.sosy-lab.org><br>\n",
    "<br>\n",
    "SPDX-License-Identifier: Apache-2.0<br>\n",
    "<br>\n",
    "---\n",
    "\n",
    "\n",
    "Instructions\n",
    "---\n",
    "*description*\n",
    "<br>You can set a threshold to substract the start-up time of CPAchecker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold in seconds. \n",
    "# Increase the time limit by <threshold> seconds to substract the time CPAchecker needs to start. Only applied on sequential analysis.\n",
    "threshold = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell provides the util methods to convert the result sets to pandas dataframe format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "from benchexec import tablegenerator\n",
    "import benchexec.result\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Optional, List, Union, Tuple\n",
    "from dataclasses import dataclass\n",
    "import os\n",
    "\n",
    "def get_data(data_files: Union[List[str], str], disable_fv=True) -> List[pd.DataFrame]:\n",
    "    if not isinstance(data_files, str):\n",
    "        return [d for f in data_files for d in get_data(f)]\n",
    "    if not data_files.endswith(\".xml.bz2\"):\n",
    "        data_files = data_files if data_files.startswith(\"/\") else \"/\" + data_files\n",
    "        path = os.getcwd() + data_files\n",
    "        if not os.path.isdir(path):\n",
    "            print(\"Argument is not a directory or a xml.bz2 file:\", data_files)\n",
    "            return []\n",
    "        files = os.listdir(path)\n",
    "        return get_data([os.path.join(data_files, file)[1:] for file in files if file.endswith(\".xml.bz2\")])\n",
    "    raw_data = _load_data(data_files) if disable_fv else [res for res in _load_data_with_fv(data_files) if res is not None][0]\n",
    "    return [pd.DataFrame(data=_get_values(raw_data), columns=_get_column_titles(raw_data))]\n",
    "\n",
    "\n",
    "def _load_data(data_file: str) -> tablegenerator.RunSetResult:\n",
    "    parser = tablegenerator.create_argument_parser()\n",
    "    options = parser.parse_args([data_file])\n",
    "    return tablegenerator.load_result(data_file, options)\n",
    "\n",
    "def _load_data_with_fv(data_file: str, table='table.xml'):\n",
    "    parser = tablegenerator.create_argument_parser()\n",
    "    options = parser.parse_args([data_file, '-x', table])\n",
    "    table_definition = tablegenerator.parse_table_definition_file(table)\n",
    "    return tablegenerator.load_results_with_table_definition([data_file], table_definition, table, options)\n",
    "\n",
    "def _get_column_titles(result_set: tablegenerator.RunSetResult):\n",
    "    return ['task_id', 'category'] + [col.title for col in result_set.columns]\n",
    "\n",
    "\n",
    "def _get_values(result_set):\n",
    "    return [[r.task_id[0], r.category] + cast_values(r) for r in result_set.results]\n",
    "\n",
    "\n",
    "def cast_values(r: tablegenerator.RunResult):\n",
    "    return [to_value(value, column) for value, column in zip(r.values, r.columns)]\n",
    "\n",
    "\n",
    "def to_value(value, column):\n",
    "    if not column.is_numeric() or value is None:\n",
    "        return value\n",
    "    if column.unit is None:\n",
    "        return value\n",
    "    return float(value[:-len(column.unit)])\n",
    "\n",
    "def merge_columns(category, status):\n",
    "    merge_dict = {\n",
    "        (\"correct\", \"true\"): \"TP\",\n",
    "        (\"incorrect\", \"true\"): \"FP\",\n",
    "        (\"correct\", \"false\"): \"TN\",\n",
    "        (\"incorrect\", \"true\"): \"FN\"\n",
    "    }\n",
    "    if (category, status) in merge_dict:\n",
    "        return merge_dict[(category, status)]\n",
    "    return \"ERR/UNKNOWN/TIMEOUT\"\n",
    "\n",
    "def read_benchmarks(data_files: Union[List[str], str]):\n",
    "    frames = []\n",
    "    for df in get_data(data_files):\n",
    "        # skip tables with missing columns (e.g. analysis was aborted)\n",
    "        if not {'cputime', 'status', 'category'}.issubset(df.columns):\n",
    "            print(\"Skipped table because it is missing columns. The first 5 rows: \")\n",
    "            print(df.head(5))\n",
    "            frames.append(pd.DataFrame(columns=['task_id', 'result', 'cputime']))\n",
    "            continue\n",
    "        # skip aborted tasks\n",
    "        df = df[df['category'] != \"aborted\"]\n",
    "        df = df.drop(columns=['host'], errors='ignore')\n",
    "        df['result'] = df.apply(lambda row: merge_columns(row['category'], row['status']), axis=1)\n",
    "        frames.append(df[['task_id', 'result', 'cputime']])\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following methods are used to work with feature vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class FeatureVector:\n",
    "    has_floats: Optional[bool] = None\n",
    "    has_array: Optional[bool] = None\n",
    "    has_recursion: Optional[bool] = None\n",
    "    has_composite_handling: Optional[bool] = None\n",
    "    has_loop: Optional[bool] = None\n",
    "    has_alias_handling: Optional[bool] = None\n",
    "        \n",
    "    default = FeatureVector.from_tuple((-1,-1,-1,-1,-1,-1))\n",
    "        \n",
    "    def to_tuple(self):\n",
    "        lookup = {\n",
    "            None : -1,\n",
    "            True : 1,\n",
    "            False: 0\n",
    "        }\n",
    "        return (lookup[self.has_floats],\n",
    "                lookup[self.has_array],\n",
    "                lookup[self.has_recursion],\n",
    "                lookup[self.has_composite_handling],\n",
    "                lookup[self.has_loop],\n",
    "                lookup[self.has_alias_handling])\n",
    "    \n",
    "    def matches(self, fv):\n",
    "        t1 = self.to_tuple()\n",
    "        t2 = fv.to_tuple()\n",
    "        for elem in zip(t1,t2):\n",
    "            if elem[0] == -1 or elem[1] == -1:\n",
    "                continue\n",
    "            if (elem[0] != elem[1]):\n",
    "                return False\n",
    "        return True\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        if isinstance(other, FeatureVector):\n",
    "            return self.matches(other)\n",
    "        return False\n",
    "    \n",
    "    def __hash__(self):\n",
    "        return hash(self.to_tuple())\n",
    "    \n",
    "    def find_result_set(self, lookup):\n",
    "        for key in lookup:\n",
    "            compare = key\n",
    "            if isinstance(key, tuple):\n",
    "                compare = FeatureVector.from_tuple(key)\n",
    "            if (compare == self):\n",
    "                return lookup[key]\n",
    "        return None\n",
    "    \n",
    "    @staticmethod\n",
    "    def from_tuple(fv_tuple):\n",
    "        lookup = {\n",
    "            -1: None,\n",
    "             0: False,\n",
    "             1: True\n",
    "        }\n",
    "        param_tuple = (lookup.get(t, None) for t in fv_tuple)\n",
    "        return FeatureVector(*param_tuple)\n",
    "    \n",
    "    @staticmethod\n",
    "    def from_dataframe_row(row):\n",
    "        return FeatureVector.from_tuple((row['has_floats'],\n",
    "                                         row['has_arrays'],\n",
    "                                         row['has_recursion'],\n",
    "                                         row['has_composite_handling'],\n",
    "                                         row['has_loop'],\n",
    "                                         row['has_alias_handling']))\n",
    "\n",
    "def config_to_df(lookup):\n",
    "    config = dict()\n",
    "    for key in lookup:\n",
    "        config[key] = get_data(lookup[key])[0]\n",
    "    return config\n",
    "\n",
    "def find_fitting_results(data_files: Union[List[str], str], lookup):\n",
    "    # TODO create fvs\n",
    "    config = config_to_df(lookup)\n",
    "    fv_tables = get_data(data_files, disable_fv=False)\n",
    "    frames = []\n",
    "    for fv_table in fv_tables:\n",
    "        df = pd.DataFrame(columns=fv_table.columns)\n",
    "        for index, row in fv_table.iterrows():\n",
    "            task_id = row[\"task_id\"]\n",
    "            fv = FeatureVector.from_dataframe_row(row)\n",
    "            table = fv.find_result_set(config)\n",
    "            table = table[table[\"task_id\"]==task_id]\n",
    "            df = pd.concat([df,table])\n",
    "        frames.append(df)\n",
    "        break\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following methods are used to calculate the final score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_frames(input_sets, sequential=False):\n",
    "    frames = []\n",
    "    for (df, time) in input_sets:\n",
    "        epsilon = 0 if not frames or not sequential else threshold\n",
    "        df['result'] = np.where((df['cputime'] > time) & (time != -1), 'ERR/UNKNOWN/TIMEOUT', df['result'])\n",
    "        df['cputime'] = np.where((df['cputime'] > time) & (time != -1), time, df['cputime'])\n",
    "        frames.append(df)\n",
    "    concat = pd.concat(frames)\n",
    "    return concat[['task_id', 'result', 'cputime']]\n",
    "\n",
    "def sequential(input_sets):\n",
    "    prepared = prepare_frames(input_sets, sequential=True)\n",
    "    distinct_ids = prepared.task_id.unique()\n",
    "    results = pd.DataFrame(columns = prepared.columns)\n",
    "    # loop through every distinct key\n",
    "    for key in distinct_ids:\n",
    "        selection = prepared[prepared['task_id'] == key]\n",
    "        col_result_distinct = selection.result.unique()\n",
    "        # if all results are unknown the tasks takes sum(cputime)\n",
    "        if (len(col_result_distinct) == 1):\n",
    "            if (col_result_distinct[0] == \"ERR/UNKNOWN/TIMEOUT\"):\n",
    "                sum_time = selection['cputime'].sum()\n",
    "                new_row = pd.DataFrame([[key, \"ERR/UNKNOWN/TIMEOUT\", sum_time]], columns=prepared.columns)\n",
    "                results = results.append(new_row)\n",
    "                continue\n",
    "        # otherwise return result of first analysis that finishes (sum cputime until result != \"ERR/UNKNOWN/TIMEOUT\")\n",
    "        col_result = \"\"\n",
    "        sum_time = 0\n",
    "        for index, row in selection.iterrows():\n",
    "            if (row[\"result\"] != \"ERR/UNKNOWN/TIMEOUT\"):\n",
    "                col_result = row[\"result\"]\n",
    "                sum_time = sum_time + row[\"cputime\"]\n",
    "                break\n",
    "            sum_time = sum_time + row[\"cputime\"]\n",
    "        new_row = pd.DataFrame([[key, col_result, sum_time]], columns=prepared.columns)\n",
    "        results = results.append(new_row)\n",
    "    return results\n",
    "\n",
    "def parallel(input_sets, timelimit=-1):\n",
    "    prepared = prepare_frames([(df, timelimit) for df in input_sets])\n",
    "    prepared = prepared[['task_id', 'result', 'cputime']]\n",
    "    distinct_ids = prepared.task_id.unique()\n",
    "    results = pd.DataFrame(columns = prepared.columns)\n",
    "    # loop through every distinct key\n",
    "    for key in distinct_ids:\n",
    "        selection = prepared[prepared['task_id'] == key]\n",
    "        col_result_distinct = selection.result.unique()\n",
    "        # if all results are unknown the tasks takes max(cputime)\n",
    "        if (len(col_result_distinct) == 1):\n",
    "            if (col_result_distinct[0] == \"ERR/UNKNOWN/TIMEOUT\"):\n",
    "                max_time = selection['cputime'].max()\n",
    "                new_row = pd.DataFrame([[key, \"ERR/UNKNOWN/TIMEOUT\", max_time]], columns=prepared.columns)\n",
    "                results = results.append(new_row)\n",
    "                continue\n",
    "        # otherwise return result of first analysis that finishes min(cputime | result != \"UNKNOWN\")\n",
    "        selection = selection[selection['result'] != \"ERR/UNKNOWN/TIMEOUT\"]\n",
    "        selection = selection[selection['cputime'] == selection['cputime'].min()].head(1)\n",
    "        results = results.append(selection)\n",
    "    return results\n",
    "\n",
    "def evaluate(df):\n",
    "    counts = df.result.value_counts()\n",
    "    average_time = int(df.cputime.mean())\n",
    "    time = pd.Series([average_time], index=['Average time'])\n",
    "    return counts.append(time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 2 strategies available:\n",
    "- sequential:\n",
    "```\n",
    "simulates the sequential execution of all given analysis\n",
    "| analysis 0 | analysis 1 | ... | analysis n |\n",
    "```\n",
    "<br>\n",
    "- parallel:\n",
    "```file2\n",
    "simulates the parallel execution of all given analysis\n",
    "|      analysis 0     |\n",
    "|        analysis 1        |\n",
    "|       analysis 2       |\n",
    "```\n",
    "\n",
    "All analysis simulate an execution where the calculation terminates as soon as a result different from \"UNKNOWN\", \"ERROR\" or \"TIMEOUT\" occurs (if possible).\n",
    "\n",
    "The format of the input should look like this:\n",
    "```python\n",
    "[sub1, sub2, sub3, sub4] = read_benchmarks(\n",
    "            ['path/to/file1.xml.bz2', \n",
    "              'path/to/file2.xml.bz2', \n",
    "              'path/to/file3.xml.bz2', \n",
    "              'path/to/file4.xml.bz2'\n",
    "             ]\n",
    ")\n",
    "```\n",
    "**Note**: You can pass a folder located in the same directory as this file as well. Pass \"folder/\" to run the script with all files in the specified folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define your tasks here\n",
    "[sub1] = read_benchmarks(\n",
    "            ['results/featureExtraction.2020-11-13_14-08-04.results.SV-COMP21_unreach-call.ReachSafety-ECA.xml.bz2']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a configuration for feature vectors. A vectors has 6 attributes with values `True, False, None`. You can either create a `FeatureVector` by hand or simply use a tuple. The first entry of the tuple sets the value for `has_floats` the last entry sets the value for `has_alias_handling`. The tuples are based on integer values. `0` will be translated to `False`, `1` to `True` and every other integer to `None`. `None` means that you don't care which value is on this position of the feature vector.\n",
    "\n",
    "The class `FeatureVector` (here you can see which entry of the tuple belongs to which attribute):\n",
    "```python\n",
    "@dataclass\n",
    "class FeatureVector:\n",
    "    has_floats: Optional[bool] = None\n",
    "    has_array: Optional[bool] = None\n",
    "    has_recursion: Optional[bool] = None\n",
    "    has_composite_handling: Optional[bool] = None\n",
    "    has_loop: Optional[bool] = None\n",
    "    has_alias_handling: Optional[bool] = None\n",
    "```\n",
    "\n",
    "Here you can see an example for all valid configuration. The tuples will automatically be transformed to `FeatureVectors`.\n",
    "```python\n",
    "configuration = {\n",
    "    (1,0,0): \"path/to/result1\",\n",
    "    (1,0,1,0,1,0) : \"path/to/result1\",\n",
    "    FeatureVector.from_tuple((1,1,1,1,0,1)): \"path/to/result3\",\n",
    "    FeatureVector(has_floats=True, has_loop=False): \"path/to/result4\",\n",
    "    FeatureVector.default: \"path/to/default/result\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define your configuration here\n",
    "configuration = {\n",
    "    FeatureVector.default: \"results/featureExtraction.2020-11-13_14-08-04.results.SV-COMP21_unreach-call.ReachSafety-ProductLines.xml.bz2\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe based on feature vectors:\n",
    "[subN] = find_fitting_results('results/featureExtraction.2020-11-13_14-08-04.results.SV-COMP21_unreach-call.ReachSafety-Recursive.xml.bz2', configuration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now all your tables are dataframes and you can use the provided methods. Compose your tasks, for example, as follows:\n",
    "```python\n",
    "strategy = sequential(\n",
    "        [\n",
    "           (parallel([sub1, sub2], timelimit0=200), timelimit1),\n",
    "           (subN, timelimit2)\n",
    "        ]\n",
    ")         \n",
    "```\n",
    "Set `timelimitN = -1` to use the actual time limit of the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#strategy = sequential(result_sets)\n",
    "strategy = sequential(dirname = os.path.dirname(__file__)\n",
    "    [\n",
    "        (parallel([sub1, sub3]), 400),\n",
    "        (parallel([sub2, sub4]), 800)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can rate your chosen timelimits. The output shows how often a result (e.g. \"UNKNOWN, \"TP\", \"FN\", ...) occured. \"Average time\" displays the mean of the cputime in seconds to find a result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(strategy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
