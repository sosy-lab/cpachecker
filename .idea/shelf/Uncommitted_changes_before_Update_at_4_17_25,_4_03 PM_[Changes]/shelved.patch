Index: config/globalvar.properties
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>ISO-8859-1
===================================================================
diff --git a/config/globalvar.properties b/config/unseqBehaviorAnalysis.properties
rename from config/globalvar.properties
rename to config/unseqBehaviorAnalysis.properties
--- a/config/globalvar.properties	(revision 994693c6616e755015ebf8f13b83d23d2f5cd593)
+++ b/config/unseqBehaviorAnalysis.properties	(date 1744786983540)
@@ -6,5 +6,10 @@
 #
 # SPDX-License-Identifier: Apache-2.0
 
-cpa = cpa.globalvar.GlobalVarAnalysisCPA
+cpa = cpa.arg.ARGCPA
+
+ARGCPA.cpa = cpa.composite.CompositeCPA
+
+CompositeCPA.cpas = cpa.location.LocationCPA, cpa.callstack.CallstackCPA, cpa.unsequenced.UnseqBehaviorAnalysisCPA
+
 specification = specification/default.spc
\ No newline at end of file
Index: src/org/sosy_lab/cpachecker/cpa/unsequenced/SideEffectInfo.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>// This file is part of CPAchecker,\n// a tool for configurable software verification:\n// https://cpachecker.sosy-lab.org\n//\n// SPDX-FileCopyrightText: 2025 Dirk Beyer <https://www.sosy-lab.org>\n//\n// SPDX-License-Identifier: Apache-2.0\n\npackage org.sosy_lab.cpachecker.cpa.unsequenced;\n\nimport java.util.Objects;\nimport org.sosy_lab.cpachecker.cfa.model.CFAEdge;\nimport org.sosy_lab.cpachecker.util.states.MemoryLocation;\n\npublic class SideEffectInfo {\n\n  public enum AccessType {\n    WRITE,\n    READ\n  }\n\n  private final MemoryLocation memoryLocation;\n  private final AccessType accessType;\n  private final CFAEdge cfaEdge;\n\n  public SideEffectInfo(MemoryLocation pMemoryLocation, AccessType pAccessType, CFAEdge pCfaEdge) {\n    memoryLocation = pMemoryLocation;\n    accessType = pAccessType;\n    cfaEdge = pCfaEdge;\n  }\n\n  public MemoryLocation getMemoryLocation() {\n    return memoryLocation;\n  }\n\n  public AccessType getAccessType() {\n    return accessType;\n  }\n\n  public CFAEdge getCfaEdge() {\n    return cfaEdge;\n  }\n\n  public boolean isWrite() {\n    return accessType == AccessType.WRITE;\n  }\n\n  public boolean isRead() {\n    return accessType == AccessType.READ;\n  }\n\n  @Override\n  public boolean equals(Object o) {\n    if (this == o) return true;\n    if (!(o instanceof SideEffectInfo)) return false;\n    SideEffectInfo that = (SideEffectInfo) o;\n    return Objects.equals(memoryLocation, that.memoryLocation)\n        && accessType == that.accessType\n        && Objects.equals(cfaEdge, that.cfaEdge);\n  }\n\n  @Override\n  public int hashCode() {\n    return Objects.hash(memoryLocation, accessType, cfaEdge);\n  }\n\n  @Override\n  public String toString() {\n    return String.format(\n        \"SideEffect[%s at %s, stmt=\\\"%s\\\" in %s at line %d, column %d]\",\n        accessType,\n        memoryLocation.getExtendedQualifiedName(),\n        cfaEdge.getRawStatement(),\n        cfaEdge.getFileLocation().getNiceFileName(),\n        cfaEdge.getLineNumber(),\n        cfaEdge.getFileLocation().getStartColumnInLine());\n  }\n\n  public String toStringSimple(){\n    return String.format(\n        \"SideEffect[%s at %s]\",\n        accessType,\n        memoryLocation.getExtendedQualifiedName());\n  }\n}\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/org/sosy_lab/cpachecker/cpa/unsequenced/SideEffectInfo.java b/src/org/sosy_lab/cpachecker/cpa/unsequenced/SideEffectInfo.java
--- a/src/org/sosy_lab/cpachecker/cpa/unsequenced/SideEffectInfo.java	(revision 994693c6616e755015ebf8f13b83d23d2f5cd593)
+++ b/src/org/sosy_lab/cpachecker/cpa/unsequenced/SideEffectInfo.java	(date 1744842118793)
@@ -67,19 +67,20 @@
   @Override
   public String toString() {
     return String.format(
-        "SideEffect[%s at %s, stmt=\"%s\" in %s at line %d, column %d]",
-        accessType,
+        "%s@%s [%s] at %s:%d:%d",
         memoryLocation.getExtendedQualifiedName(),
+        accessType,
         cfaEdge.getRawStatement(),
         cfaEdge.getFileLocation().getNiceFileName(),
         cfaEdge.getLineNumber(),
         cfaEdge.getFileLocation().getStartColumnInLine());
   }
 
-  public String toStringSimple(){
-    return String.format(
-        "SideEffect[%s at %s]",
-        accessType,
-        memoryLocation.getExtendedQualifiedName());
+  public String toStringSimple() {
+    String varName = memoryLocation.getExtendedQualifiedName();
+    String access = accessType.toString();
+    int line = cfaEdge.getLineNumber();
+
+    return String.format("%s@%s:line %d", varName, access, line);
   }
 }
Index: src/org/sosy_lab/cpachecker/cpa/unsequenced/UnseqBehaviorAnalysisTransferRelation.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>// This file is part of CPAchecker,\n// a tool for configurable software verification:\n// https://cpachecker.sosy-lab.org\n//\n// SPDX-FileCopyrightText: 2025 Dirk Beyer <https://www.sosy-lab.org>\n//\n// SPDX-License-Identifier: Apache-2.0\n\npackage org.sosy_lab.cpachecker.cpa.unsequenced;\n\n\nimport java.util.Collection;\nimport java.util.Collections;\nimport java.util.List;\nimport java.util.Set;\nimport org.sosy_lab.common.log.LogManager;\nimport org.sosy_lab.cpachecker.cfa.ast.FileLocation;\nimport org.sosy_lab.cpachecker.cfa.ast.c.CBinaryExpression;\nimport org.sosy_lab.cpachecker.cfa.ast.c.CDeclaration;\nimport org.sosy_lab.cpachecker.cfa.ast.c.CExpression;\nimport org.sosy_lab.cpachecker.cfa.ast.c.CExpressionAssignmentStatement;\nimport org.sosy_lab.cpachecker.cfa.ast.c.CFunctionCallAssignmentStatement;\nimport org.sosy_lab.cpachecker.cfa.ast.c.CFunctionCallExpression;\nimport org.sosy_lab.cpachecker.cfa.ast.c.CIdExpression;\nimport org.sosy_lab.cpachecker.cfa.ast.c.CInitializerExpression;\nimport org.sosy_lab.cpachecker.cfa.ast.c.CParameterDeclaration;\nimport org.sosy_lab.cpachecker.cfa.ast.c.CPointerExpression;\nimport org.sosy_lab.cpachecker.cfa.ast.c.CSimpleDeclaration;\nimport org.sosy_lab.cpachecker.cfa.ast.c.CStatement;\nimport org.sosy_lab.cpachecker.cfa.ast.c.CVariableDeclaration;\nimport org.sosy_lab.cpachecker.cfa.model.c.CDeclarationEdge;\nimport org.sosy_lab.cpachecker.cfa.model.c.CFunctionCallEdge;\nimport org.sosy_lab.cpachecker.cfa.model.c.CStatementEdge;\nimport org.sosy_lab.cpachecker.core.defaults.ForwardingTransferRelation;\nimport org.sosy_lab.cpachecker.core.interfaces.Precision;\nimport org.sosy_lab.cpachecker.exceptions.UnrecognizedCodeException;\nimport org.sosy_lab.cpachecker.util.states.MemoryLocation;\n\n\npublic class UnseqBehaviorAnalysisTransferRelation\n    extends ForwardingTransferRelation<\n    Collection<UnseqBehaviorAnalysisState>, UnseqBehaviorAnalysisState, Precision> {\n\n  private final LogManager logger;\n\n  public UnseqBehaviorAnalysisTransferRelation(LogManager pLogger) {\n    logger = pLogger;\n  }\n\n  @Override\n  protected Collection<UnseqBehaviorAnalysisState> handleStatementEdge(CStatementEdge cfaEdge, CStatement stat)\n      throws UnrecognizedCodeException {\n    UnseqBehaviorAnalysisState newState = state;\n    SideEffectGatherVisitor visitor = new SideEffectGatherVisitor(newState, cfaEdge);\n\n    if (stat instanceof CExpressionAssignmentStatement exprAssign) {\n      CExpression lhs = exprAssign.getLeftHandSide();\n      CExpression rhs = exprAssign.getRightHandSide();\n      recordGlobalWrite(lhs,state);\n\n      //rhs: check if there exists unsequenced behavior and cause conflict\n      if (rhs instanceof CBinaryExpression binaryExpr){ // y = f() + g()\n        CBinaryExpression.BinaryOperator op = binaryExpr.getOperator();\n        if (isUnsequencedBinaryOperator(op)) {\n          rhs.accept(visitor);\n          detectUnsequencedConflicts(binaryExpr.getOperand1(), binaryExpr.getOperand2(), newState);\n        }\n      }\n    } else if (stat instanceof CFunctionCallAssignmentStatement funCallAssign){\n      CExpression lhs = funCallAssign.getLeftHandSide();\n      CFunctionCallExpression rhs = funCallAssign.getRightHandSide();\n\n      recordGlobalWrite(lhs,state);\n\n      if (lhs instanceof CPointerExpression pointerExpr){//*f() = g()\n        pointerExpr.accept(visitor);\n        rhs.accept(visitor);\n        detectUnsequencedConflicts(lhs,rhs,newState);\n      }\n    }\n\n    return soleSuccessor(newState);\n  }\n\n  @Override\n  protected Collection<UnseqBehaviorAnalysisState> handleDeclarationEdge(\n      CDeclarationEdge declarationEdge, CDeclaration declaration) throws UnrecognizedCodeException {\n\n    if (declarationEdge.getDeclaration() instanceof CVariableDeclaration varDecl) {\n      if (varDecl.getInitializer() instanceof CInitializerExpression init) {\n        if (init.getExpression() instanceof CBinaryExpression binaryExpr){ // int x = f() + g()\n\n        }\n      }\n    }\n\n    return\n  }\n\n  @Override\n  protected Collection<UnseqBehaviorAnalysisState> handleFunctionCallEdge(\n      CFunctionCallEdge callEdge, List<CExpression> arguments, List<CParameterDeclaration> parameters, String calledFunctionName)\n      throws UnrecognizedCodeException {\n\n\n  }\n\n  private void detectUnsequencedConflicts(CExpression expr1, CExpression expr2, UnseqBehaviorAnalysisState pState){\n    Set<SideEffectInfo> effects1 = pState.getSideEffectsPerExpr().getOrDefault(expr1, Set.of());\n    Set<SideEffectInfo> effects2 = pState.getSideEffectsPerExpr().getOrDefault(expr2, Set.of());\n\n    for (SideEffectInfo s1 : effects1) {\n      for (SideEffectInfo s2 : effects2) {\n        if (conflictOnSameLocation(s1, s2)) {\n          FileLocation loc = expr1.getFileLocation();\n          pState.addConflict(loc, expr1);\n          pState.addConflict(loc, expr2);\n        }\n      }\n    }\n\n  }\n\n  private boolean conflictOnSameLocation(SideEffectInfo sideEffectInfo1, SideEffectInfo sideEffectInfo2) {\n    return sideEffectInfo1.getMemoryLocation().equals(sideEffectInfo2.getMemoryLocation()) &&\n        (sideEffectInfo1.isWrite() || sideEffectInfo2.isWrite());\n  }\n\n  private boolean isUnsequencedBinaryOperator(CBinaryExpression.BinaryOperator op) {\n    return switch (op) {\n      case BINARY_AND, BINARY_OR -> false;\n      case MULTIPLY, DIVIDE, MODULO,\n           PLUS, MINUS,\n           SHIFT_LEFT, SHIFT_RIGHT, BINARY_XOR,\n           LESS_EQUAL, LESS_THAN, GREATER_EQUAL, GREATER_THAN,\n           EQUALS, NOT_EQUALS -> true;\n      default -> throw new AssertionError(\"Unhandled operator in isUnsequencedBinaryOperator: \" + op);\n    };\n  }\n\n  private void recordGlobalWrite(CExpression lhs, UnseqBehaviorAnalysisState pState) {\n    if (!(lhs instanceof CIdExpression idExpr)) {\n      return;\n    }\n\n    CSimpleDeclaration decl = idExpr.getDeclaration();\n    MemoryLocation loc = MemoryLocation.fromQualifiedName(decl.getQualifiedName());\n\n    if (!loc.isOnFunctionStack()) {\n      Set<SideEffectInfo> sideEffects = Set.of(\n          new SideEffectInfo(loc, lhs.getFileLocation(), SideEffectInfo.AccessType.WRITE)\n      );\n      pState.addSideEffectForExpr(idExpr, sideEffects);\n    }\n  }\n\n  private Collection<UnseqBehaviorAnalysisState> soleSuccessor(UnseqBehaviorAnalysisState successor) {\n    return Collections.singleton(successor);\n  }\n\n}\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/org/sosy_lab/cpachecker/cpa/unsequenced/UnseqBehaviorAnalysisTransferRelation.java b/src/org/sosy_lab/cpachecker/cpa/unsequenced/UnseqBehaviorAnalysisTransferRelation.java
--- a/src/org/sosy_lab/cpachecker/cpa/unsequenced/UnseqBehaviorAnalysisTransferRelation.java	(revision 994693c6616e755015ebf8f13b83d23d2f5cd593)
+++ b/src/org/sosy_lab/cpachecker/cpa/unsequenced/UnseqBehaviorAnalysisTransferRelation.java	(date 1744898324866)
@@ -8,38 +8,41 @@
 
 package org.sosy_lab.cpachecker.cpa.unsequenced;
 
-
-import java.util.Collection;
-import java.util.Collections;
+import java.util.HashSet;
 import java.util.List;
 import java.util.Set;
+import java.util.logging.Level;
 import org.sosy_lab.common.log.LogManager;
-import org.sosy_lab.cpachecker.cfa.ast.FileLocation;
 import org.sosy_lab.cpachecker.cfa.ast.c.CBinaryExpression;
 import org.sosy_lab.cpachecker.cfa.ast.c.CDeclaration;
 import org.sosy_lab.cpachecker.cfa.ast.c.CExpression;
 import org.sosy_lab.cpachecker.cfa.ast.c.CExpressionAssignmentStatement;
+import org.sosy_lab.cpachecker.cfa.ast.c.CExpressionStatement;
+import org.sosy_lab.cpachecker.cfa.ast.c.CFunctionCall;
 import org.sosy_lab.cpachecker.cfa.ast.c.CFunctionCallAssignmentStatement;
 import org.sosy_lab.cpachecker.cfa.ast.c.CFunctionCallExpression;
+import org.sosy_lab.cpachecker.cfa.ast.c.CFunctionDeclaration;
 import org.sosy_lab.cpachecker.cfa.ast.c.CIdExpression;
 import org.sosy_lab.cpachecker.cfa.ast.c.CInitializerExpression;
 import org.sosy_lab.cpachecker.cfa.ast.c.CParameterDeclaration;
-import org.sosy_lab.cpachecker.cfa.ast.c.CPointerExpression;
-import org.sosy_lab.cpachecker.cfa.ast.c.CSimpleDeclaration;
 import org.sosy_lab.cpachecker.cfa.ast.c.CStatement;
 import org.sosy_lab.cpachecker.cfa.ast.c.CVariableDeclaration;
+import org.sosy_lab.cpachecker.cfa.model.BlankEdge;
+import org.sosy_lab.cpachecker.cfa.model.CFAEdge;
+import org.sosy_lab.cpachecker.cfa.model.c.CAssumeEdge;
 import org.sosy_lab.cpachecker.cfa.model.c.CDeclarationEdge;
 import org.sosy_lab.cpachecker.cfa.model.c.CFunctionCallEdge;
+import org.sosy_lab.cpachecker.cfa.model.c.CFunctionReturnEdge;
+import org.sosy_lab.cpachecker.cfa.model.c.CReturnStatementEdge;
 import org.sosy_lab.cpachecker.cfa.model.c.CStatementEdge;
 import org.sosy_lab.cpachecker.core.defaults.ForwardingTransferRelation;
 import org.sosy_lab.cpachecker.core.interfaces.Precision;
+import org.sosy_lab.cpachecker.cpa.unsequenced.SideEffectInfo.AccessType;
 import org.sosy_lab.cpachecker.exceptions.UnrecognizedCodeException;
-import org.sosy_lab.cpachecker.util.states.MemoryLocation;
 
 
 public class UnseqBehaviorAnalysisTransferRelation
-    extends ForwardingTransferRelation<
-    Collection<UnseqBehaviorAnalysisState>, UnseqBehaviorAnalysisState, Precision> {
+    extends ForwardingTransferRelation<UnseqBehaviorAnalysisState, UnseqBehaviorAnalysisState, Precision> {
 
   private final LogManager logger;
 
@@ -48,77 +51,165 @@
   }
 
   @Override
-  protected Collection<UnseqBehaviorAnalysisState> handleStatementEdge(CStatementEdge cfaEdge, CStatement stat)
+  protected UnseqBehaviorAnalysisState handleStatementEdge(CStatementEdge statementEdge, CStatement stat)
       throws UnrecognizedCodeException {
     UnseqBehaviorAnalysisState newState = state;
-    SideEffectGatherVisitor visitor = new SideEffectGatherVisitor(newState, cfaEdge);
+    if (stat instanceof CExpressionAssignmentStatement exprAssign) {// to detect unseq behavior like y = (f() + g()) + x
+      CExpression lhsExpr = exprAssign.getLeftHandSide();
+      CExpression rhsExpr = exprAssign.getRightHandSide();
 
-    if (stat instanceof CExpressionAssignmentStatement exprAssign) {
-      CExpression lhs = exprAssign.getLeftHandSide();
-      CExpression rhs = exprAssign.getRightHandSide();
-      recordGlobalWrite(lhs,state);
+      //if functioncall true, then record side effects inside it
+      recordSideEffectsIfInFunctionCall(lhsExpr, statementEdge, AccessType.WRITE, newState);
+      recordSideEffectsIfInFunctionCall(rhsExpr, statementEdge, AccessType.READ, newState);
 
-      //rhs: check if there exists unsequenced behavior and cause conflict
-      if (rhs instanceof CBinaryExpression binaryExpr){ // y = f() + g()
-        CBinaryExpression.BinaryOperator op = binaryExpr.getOperator();
-        if (isUnsequencedBinaryOperator(op)) {
-          rhs.accept(visitor);
-          detectUnsequencedConflicts(binaryExpr.getOperand1(), binaryExpr.getOperand2(), newState);
-        }
+      //check if there exists unsequenced behavior and cause conflict
+      if (rhsExpr instanceof CBinaryExpression binaryExpr){
+        detectConflictsInUnsequencedBinaryExprs(binaryExpr, statementEdge, newState);
       }
-    } else if (stat instanceof CFunctionCallAssignmentStatement funCallAssign){
-      CExpression lhs = funCallAssign.getLeftHandSide();
-      CFunctionCallExpression rhs = funCallAssign.getRightHandSide();
+    }else if (stat instanceof CExpressionStatement exStat) {// to detect unseq behavior like (f() + g()) + x
+      CExpression expr = exStat.getExpression();
 
-      recordGlobalWrite(lhs,state);
+      recordSideEffectsIfInFunctionCall(expr, statementEdge, AccessType.READ, newState);
 
-      if (lhs instanceof CPointerExpression pointerExpr){//*f() = g()
-        pointerExpr.accept(visitor);
-        rhs.accept(visitor);
-        detectUnsequencedConflicts(lhs,rhs,newState);
+      if (expr instanceof CBinaryExpression binaryExpr) {
+        detectConflictsInUnsequencedBinaryExprs(binaryExpr, statementEdge, newState);
       }
+
+      //TODO: *f() = g()
     }
 
-    return soleSuccessor(newState);
+    return newState;
   }
 
   @Override
-  protected Collection<UnseqBehaviorAnalysisState> handleDeclarationEdge(
+  protected UnseqBehaviorAnalysisState handleDeclarationEdge(
       CDeclarationEdge declarationEdge, CDeclaration declaration) throws UnrecognizedCodeException {
-
-    if (declarationEdge.getDeclaration() instanceof CVariableDeclaration varDecl) {
+    UnseqBehaviorAnalysisState newState = state;
+    if (declaration instanceof CVariableDeclaration varDecl) {
       if (varDecl.getInitializer() instanceof CInitializerExpression init) {
-        if (init.getExpression() instanceof CBinaryExpression binaryExpr){ // int x = f() + g()
+        CExpression initExpr = init.getExpression();
+        //if functioncall true, then record side effects rhs
+        recordSideEffectsIfInFunctionCall(initExpr, declarationEdge, AccessType.READ, newState);
 
+        if (initExpr instanceof CBinaryExpression binaryExpr){ //to detect unseq behavior like int y = (f() + g()) + x
+          detectConflictsInUnsequencedBinaryExprs(binaryExpr, declarationEdge, newState);
         }
       }
     }
 
-    return
+    return newState;
   }
 
   @Override
-  protected Collection<UnseqBehaviorAnalysisState> handleFunctionCallEdge(
+  protected UnseqBehaviorAnalysisState handleFunctionCallEdge(
       CFunctionCallEdge callEdge, List<CExpression> arguments, List<CParameterDeclaration> parameters, String calledFunctionName)
       throws UnrecognizedCodeException {
+    UnseqBehaviorAnalysisState newState = state;
+    newState.setFunctionCalled(true);
+    newState.setCalledFunctionName(calledFunctionName);
+
+    //TODO: record side effects for parameters, if a function is called
+
+    //TODO: detect unseq behavior in function arguments like f(g(), a() + b())
+
+    return newState;
+  }
+
+  @Override
+  protected UnseqBehaviorAnalysisState handleFunctionReturnEdge(
+      CFunctionReturnEdge cfaEdge, CFunctionCall summaryExpr, String callerFunctionName)
+      throws UnrecognizedCodeException {
+    logger.log(Level.INFO, "[handleFunctionReturnEdge] edge: " + summaryExpr);
+
+    //map tmp name and function name
+    if (summaryExpr instanceof CFunctionCallAssignmentStatement assignStmt) {
+      CExpression lhs = assignStmt.getLeftHandSide();
+      CFunctionCallExpression rhs = assignStmt.getRightHandSide();
+
+      if (lhs instanceof CIdExpression tmpVar) {
+        String tmpName = tmpVar.getName();
+        String funName = rhs.getDeclaration().getName();
+
+        state.mapTmpToFunction(tmpName, funName);
+        logger.log(Level.INFO, String.format("[handleFunctionReturnEdge] Mapped TMP: %s → Function: %s", tmpName,funName));
+      }
+    }
+
+    return state;
+  }
+
+  @Override
+  protected UnseqBehaviorAnalysisState handleReturnStatementEdge(CReturnStatementEdge returnEdge)
+      throws UnrecognizedCodeException {
+    UnseqBehaviorAnalysisState newState = state;
+    newState.setFunctionCalled(false);
+    // TODO: detect unseq behavior in return statement
+    return newState;
+  }
+
+  @Override
+  protected UnseqBehaviorAnalysisState handleAssumption(
+      CAssumeEdge cfaEdge, CExpression expression, boolean truthValue)
+      throws UnrecognizedCodeException {
+    UnseqBehaviorAnalysisState newState = state;
+    // TODO: detect unseq behavior in condition
+    return newState;
+  }
 
+  @Override
+  protected UnseqBehaviorAnalysisState handleBlankEdge(BlankEdge cfaEdge) {
+    return state;
+  }
 
+  private void recordSideEffectsIfInFunctionCall(
+      CExpression expr,
+      CFAEdge edge,
+      AccessType accessType,
+      UnseqBehaviorAnalysisState pstate
+  ) throws UnrecognizedCodeException {
+    String funName = pstate.getCalledFunctionName();
+    if (funName != null && !pstate.getSideEffectsInFun().containsKey(funName)) {
+      SideEffectGatherVisitor visitor = new SideEffectGatherVisitor(pstate, edge, accessType, logger);
+      Set<SideEffectInfo> effects = expr.accept(visitor);
+      pstate.addSideEffectsToFunction(funName, effects);
+    }
   }
+
+  private void detectConflictsInUnsequencedBinaryExprs(
+      CExpression binaryExprs,
+      CFAEdge pCFAEdge,
+      UnseqBehaviorAnalysisState pState) throws UnrecognizedCodeException {
+
+    BinaryExpressionGatherVisitor binaryVisitor = new BinaryExpressionGatherVisitor(logger);
+    Set<CBinaryExpression> unseqBinExprs = binaryExprs.accept(binaryVisitor);
+
+    for (CBinaryExpression unseqExpr : unseqBinExprs) {
+      CExpression left = unseqExpr.getOperand1();
+      CExpression right = unseqExpr.getOperand2();
 
-  private void detectUnsequencedConflicts(CExpression expr1, CExpression expr2, UnseqBehaviorAnalysisState pState){
-    Set<SideEffectInfo> effects1 = pState.getSideEffectsPerExpr().getOrDefault(expr1, Set.of());
-    Set<SideEffectInfo> effects2 = pState.getSideEffectsPerExpr().getOrDefault(expr2, Set.of());
+      Set<SideEffectInfo> leftEffects = resolveSideEffectsFromExpr(left, pState, pCFAEdge);
+      Set<SideEffectInfo> rightEffects = resolveSideEffectsFromExpr(right, pState, pCFAEdge);
 
-    for (SideEffectInfo s1 : effects1) {
-      for (SideEffectInfo s2 : effects2) {
+      Set<ConflictPair> conflicts = getUnsequencedConflicts(leftEffects, rightEffects, pCFAEdge);
+      if (!conflicts.isEmpty()) {
+        pState.addConflicts(conflicts);
+      }
+    }
+  }
+
+  private Set<ConflictPair> getUnsequencedConflicts(
+      Set<SideEffectInfo> op1Effects,
+      Set<SideEffectInfo> op2Effects,
+      CFAEdge location) {
+    Set<ConflictPair> result = new HashSet<>();
+    for (SideEffectInfo s1 : op1Effects) {
+      for (SideEffectInfo s2 : op2Effects) {
         if (conflictOnSameLocation(s1, s2)) {
-          FileLocation loc = expr1.getFileLocation();
-          pState.addConflict(loc, expr1);
-          pState.addConflict(loc, expr2);
+          result.add(new ConflictPair(s1, s2, location));
         }
       }
     }
-
+    return result;
   }
 
   private boolean conflictOnSameLocation(SideEffectInfo sideEffectInfo1, SideEffectInfo sideEffectInfo2) {
@@ -126,36 +217,33 @@
         (sideEffectInfo1.isWrite() || sideEffectInfo2.isWrite());
   }
 
-  private boolean isUnsequencedBinaryOperator(CBinaryExpression.BinaryOperator op) {
-    return switch (op) {
-      case BINARY_AND, BINARY_OR -> false;
-      case MULTIPLY, DIVIDE, MODULO,
-           PLUS, MINUS,
-           SHIFT_LEFT, SHIFT_RIGHT, BINARY_XOR,
-           LESS_EQUAL, LESS_THAN, GREATER_EQUAL, GREATER_THAN,
-           EQUALS, NOT_EQUALS -> true;
-      default -> throw new AssertionError("Unhandled operator in isUnsequencedBinaryOperator: " + op);
-    };
-  }
+  private Set<SideEffectInfo> resolveSideEffectsFromExpr(CExpression expr, UnseqBehaviorAnalysisState pState, CFAEdge pCFAEdge) {
+    if (expr instanceof CIdExpression idExpr) {
+      String tmp = idExpr.getName();
+      String fun = pState.getFunctionForTmp(tmp);
 
-  private void recordGlobalWrite(CExpression lhs, UnseqBehaviorAnalysisState pState) {
-    if (!(lhs instanceof CIdExpression idExpr)) {
-      return;
-    }
+      if (fun != null) {
+        Set<SideEffectInfo> effects = pState.getSideEffectsInFun().getOrDefault(fun, Set.of());
 
-    CSimpleDeclaration decl = idExpr.getDeclaration();
-    MemoryLocation loc = MemoryLocation.fromQualifiedName(decl.getQualifiedName());
+        logger.log(
+            Level.INFO,
+            String.format(
+                "[resolveSideEffects] TMP: %s → Function: %s → SideEffects: %d → %s",
+                tmp, fun, effects.size(), effects
+            )
+        );
 
-    if (!loc.isOnFunctionStack()) {
-      Set<SideEffectInfo> sideEffects = Set.of(
-          new SideEffectInfo(loc, lhs.getFileLocation(), SideEffectInfo.AccessType.WRITE)
-      );
-      pState.addSideEffectForExpr(idExpr, sideEffects);
-    }
-  }
+        pState.removeTmpMapping(tmp);
+        return effects;
+      }
+    }
 
-  private Collection<UnseqBehaviorAnalysisState> soleSuccessor(UnseqBehaviorAnalysisState successor) {
-    return Collections.singleton(successor);
+    try {
+      SideEffectGatherVisitor visitor = new SideEffectGatherVisitor(pState, pCFAEdge, SideEffectInfo.AccessType.READ, logger);
+      return expr.accept(visitor);
+    } catch (Exception e) {
+      return Set.of();
+    }
   }
 
 }
Index: src/org/sosy_lab/cpachecker/cpa/unsequenced/UnseqBehaviorAnalysisState.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>// This file is part of CPAchecker,\n// a tool for configurable software verification:\n// https://cpachecker.sosy-lab.org\n//\n// SPDX-FileCopyrightText: 2025 Dirk Beyer <https://www.sosy-lab.org>\n//\n// SPDX-License-Identifier: Apache-2.0\n\npackage org.sosy_lab.cpachecker.cpa.unsequenced;\n\nimport java.util.HashMap;\nimport java.util.HashSet;\nimport java.util.Map;\nimport java.util.Objects;\nimport java.util.Set;\nimport org.sosy_lab.cpachecker.cfa.model.CFAEdge;\nimport org.sosy_lab.cpachecker.core.interfaces.AbstractState;\nimport org.sosy_lab.cpachecker.core.interfaces.Graphable;\n\n\n\npublic class UnseqBehaviorAnalysisState implements AbstractState, Graphable {\n\n  private final Map<CFAEdge, Set<SideEffectInfo>> sideEffectsByEdge;\n  private final Map<String, Set<SideEffectInfo>> sideEffectsInFun;\n  private boolean isFunctionCalled;\n  private final Map<CFAEdge, Set<SideEffectInfo>>  detectedConflictLocations;\n\n  public UnseqBehaviorAnalysisState(\n      Map<CFAEdge, Set<SideEffectInfo>> pSideEffectsByEdge,\n      Map<String, Set<SideEffectInfo>> pSideEffectsInFun,\n      boolean pIsFunctionCalled,\n      Map<CFAEdge, Set<SideEffectInfo>> pDetectedConflictLocations) {\n    sideEffectsByEdge = pSideEffectsByEdge;\n    sideEffectsInFun = pSideEffectsInFun;\n    isFunctionCalled = pIsFunctionCalled;\n    detectedConflictLocations = pDetectedConflictLocations;\n  }\n\n  public UnseqBehaviorAnalysisState() {\n    sideEffectsByEdge = new HashMap<>();\n    sideEffectsInFun = new HashMap<>();\n    isFunctionCalled = false;\n    detectedConflictLocations = new HashMap<>();\n  }\n\n  public Map<CFAEdge, Set<SideEffectInfo>> getSideEffectsByEdge() {\n    return sideEffectsByEdge;\n  }\n\n  public Map<String, Set<SideEffectInfo>> getSideEffectsInFun() {\n    return sideEffectsInFun;\n  }\n\n  public boolean hasFunctionCallOccurred() {\n    return isFunctionCalled;\n  }\n\n  public Map<CFAEdge, Set<SideEffectInfo>> getDetectedConflictLocations() {\n    return detectedConflictLocations;\n  }\n\n  @Override\n  public boolean equals(Object o) {\n    if (this == o) return true;\n    if (!(o instanceof UnseqBehaviorAnalysisState)) return false;\n    UnseqBehaviorAnalysisState that = (UnseqBehaviorAnalysisState) o;\n    return isFunctionCalled == that.isFunctionCalled\n        && Objects.equals(sideEffectsByEdge, that.sideEffectsByEdge)\n        && Objects.equals(sideEffectsInFun, that.sideEffectsInFun)\n        && Objects.equals(detectedConflictLocations, that.detectedConflictLocations);\n  }\n\n  @Override\n  public int hashCode() {\n    return Objects.hash(sideEffectsByEdge, sideEffectsInFun, isFunctionCalled, detectedConflictLocations);\n  }\n\n\n  public void addSideEffectForEdge(CFAEdge edge, Set<SideEffectInfo> sideEffects) {\n    sideEffectsByEdge.computeIfAbsent(edge, __ -> new HashSet<>())\n        .addAll(sideEffects);\n  }\n\n  public void addConflict(CFAEdge edge, Set<SideEffectInfo> sideEffects) {\n    detectedConflictLocations\n        .computeIfAbsent(edge, __ -> new HashSet<>())\n        .addAll(sideEffects);\n  }\n\n\n  public String printConflict() {\n\n    if (detectedConflictLocations.isEmpty()) {\n      return \"No conflicts detected.\";\n    }\n\n    StringBuilder sb = new StringBuilder();\n    sb.append(\"Detected Conflicts:\\n\");\n\n    for (Map.Entry<CFAEdge, Set<SideEffectInfo>> entry : detectedConflictLocations.entrySet()) {\n      CFAEdge edge = entry.getKey();\n      Set<SideEffectInfo> effects = entry.getValue();\n\n      sb.append(\"  Conflict at: \\\"\")\n          .append(edge.getRawStatement())\n          .append(\"\\\" (\")\n          .append(edge.getFileLocation().getNiceFileName())\n          .append(\":\")\n          .append(edge.getLineNumber())\n          .append(\")\\n\");\n\n      for (SideEffectInfo info : effects) {\n        sb.append(\"    → \").append(info.toStringSimple()).append(\"\\n\");\n      }\n    }\n\n\n    return sb.toString();\n  }\n\n  @Override\n  public String toDOTLabel() {\n    return printConflict();\n\n  }\n\n  @Override\n  public boolean shouldBeHighlighted() {\n    return false;\n  }\n}\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/org/sosy_lab/cpachecker/cpa/unsequenced/UnseqBehaviorAnalysisState.java b/src/org/sosy_lab/cpachecker/cpa/unsequenced/UnseqBehaviorAnalysisState.java
--- a/src/org/sosy_lab/cpachecker/cpa/unsequenced/UnseqBehaviorAnalysisState.java	(revision 994693c6616e755015ebf8f13b83d23d2f5cd593)
+++ b/src/org/sosy_lab/cpachecker/cpa/unsequenced/UnseqBehaviorAnalysisState.java	(date 1744889445571)
@@ -17,116 +17,171 @@
 import org.sosy_lab.cpachecker.core.interfaces.AbstractState;
 import org.sosy_lab.cpachecker.core.interfaces.Graphable;
 
-
-
 public class UnseqBehaviorAnalysisState implements AbstractState, Graphable {
 
-  private final Map<CFAEdge, Set<SideEffectInfo>> sideEffectsByEdge;
   private final Map<String, Set<SideEffectInfo>> sideEffectsInFun;
   private boolean isFunctionCalled;
-  private final Map<CFAEdge, Set<SideEffectInfo>>  detectedConflictLocations;
+  private String calledFunctionName;
+  private final Set<ConflictPair> detectedConflicts;
+  private final Map<String, String> tmpNameFunNameMap;
 
   public UnseqBehaviorAnalysisState(
-      Map<CFAEdge, Set<SideEffectInfo>> pSideEffectsByEdge,
       Map<String, Set<SideEffectInfo>> pSideEffectsInFun,
       boolean pIsFunctionCalled,
-      Map<CFAEdge, Set<SideEffectInfo>> pDetectedConflictLocations) {
-    sideEffectsByEdge = pSideEffectsByEdge;
+      String pCalledFunctionName,
+      Set<ConflictPair> pDetectedConflicts,
+      Map<String, String> pTmpNameFunNameMap) {
     sideEffectsInFun = pSideEffectsInFun;
     isFunctionCalled = pIsFunctionCalled;
-    detectedConflictLocations = pDetectedConflictLocations;
+    calledFunctionName = pCalledFunctionName;
+    detectedConflicts = pDetectedConflicts;
+    tmpNameFunNameMap = pTmpNameFunNameMap;
   }
 
   public UnseqBehaviorAnalysisState() {
-    sideEffectsByEdge = new HashMap<>();
     sideEffectsInFun = new HashMap<>();
     isFunctionCalled = false;
-    detectedConflictLocations = new HashMap<>();
-  }
-
-  public Map<CFAEdge, Set<SideEffectInfo>> getSideEffectsByEdge() {
-    return sideEffectsByEdge;
+    calledFunctionName = null;
+    detectedConflicts = new HashSet<>();
+    tmpNameFunNameMap = new HashMap<>();
   }
 
   public Map<String, Set<SideEffectInfo>> getSideEffectsInFun() {
     return sideEffectsInFun;
   }
 
+  public void addSideEffectsToFunction(String functionName, Set<SideEffectInfo> newEffects) {
+    sideEffectsInFun
+        .computeIfAbsent(functionName, k -> new HashSet<>())
+        .addAll(newEffects);
+  }
+
+  public void addConflicts(Set<ConflictPair> conflicts) {
+    detectedConflicts.addAll(conflicts);
+  }
+
+  public Set<ConflictPair> getDetectedConflicts() {
+    return detectedConflicts;
+  }
+
   public boolean hasFunctionCallOccurred() {
     return isFunctionCalled;
   }
 
-  public Map<CFAEdge, Set<SideEffectInfo>> getDetectedConflictLocations() {
-    return detectedConflictLocations;
+  public String getCalledFunctionName() {
+    return calledFunctionName;
+  }
+
+  public void setCalledFunctionName(String pCalledFunctionName) {
+    calledFunctionName = pCalledFunctionName;
+  }
+
+  public void setFunctionCalled(boolean pFunctionCalled) {
+    isFunctionCalled = pFunctionCalled;
+  }
+
+  public void mapTmpToFunction(String tmpVar, String functionName) {
+    tmpNameFunNameMap.put(tmpVar, functionName);
+  }
+
+  public String getFunctionForTmp(String tmpVar) {
+    return tmpNameFunNameMap.get(tmpVar);
+  }
+
+  public void removeTmpMapping(String tmpVar) {
+    tmpNameFunNameMap.remove(tmpVar);
   }
 
   @Override
   public boolean equals(Object o) {
     if (this == o) return true;
-    if (!(o instanceof UnseqBehaviorAnalysisState)) return false;
-    UnseqBehaviorAnalysisState that = (UnseqBehaviorAnalysisState) o;
-    return isFunctionCalled == that.isFunctionCalled
-        && Objects.equals(sideEffectsByEdge, that.sideEffectsByEdge)
-        && Objects.equals(sideEffectsInFun, that.sideEffectsInFun)
-        && Objects.equals(detectedConflictLocations, that.detectedConflictLocations);
+    if (!(o instanceof UnseqBehaviorAnalysisState other)) return false;
+    return isFunctionCalled == other.isFunctionCalled
+        && Objects.equals(calledFunctionName, other.calledFunctionName)
+        && Objects.equals(sideEffectsInFun, other.sideEffectsInFun)
+        && Objects.equals(detectedConflicts, other.detectedConflicts)
+        && Objects.equals(tmpNameFunNameMap, other.tmpNameFunNameMap);
   }
 
   @Override
   public int hashCode() {
-    return Objects.hash(sideEffectsByEdge, sideEffectsInFun, isFunctionCalled, detectedConflictLocations);
-  }
+    return Objects.hash(
+        sideEffectsInFun,
+        isFunctionCalled,
+        calledFunctionName,
+        detectedConflicts,
+        tmpNameFunNameMap
+    );
 
-
-  public void addSideEffectForEdge(CFAEdge edge, Set<SideEffectInfo> sideEffects) {
-    sideEffectsByEdge.computeIfAbsent(edge, __ -> new HashSet<>())
-        .addAll(sideEffects);
   }
-
-  public void addConflict(CFAEdge edge, Set<SideEffectInfo> sideEffects) {
-    detectedConflictLocations
-        .computeIfAbsent(edge, __ -> new HashSet<>())
-        .addAll(sideEffects);
-  }
-
 
   public String printConflict() {
+    if (detectedConflicts.isEmpty()) {
+      return "conflicts[]";
+    }
+
+    StringBuilder sb = new StringBuilder("conflicts[");
+
+    boolean first = true;
+    for (ConflictPair conflict : detectedConflicts) {
+      CFAEdge edge = conflict.getLocation();
+      String stmt = edge.getRawStatement();
+      String file = edge.getFileLocation().getNiceFileName();
+      int line = edge.getLineNumber();
+
+      String accessA = conflict.getAccessA().toStringSimple();
+      String accessB = conflict.getAccessB().toStringSimple();
+
+      if (!first) {
+        sb.append(", ");
+      } else {
+        first = false;
+      }
 
-    if (detectedConflictLocations.isEmpty()) {
-      return "No conflicts detected.";
+      sb.append(String.format(
+          "[%s, %s:%d, %s, %s]",
+          stmt, file, line, accessA, accessB));
+    }
+
+    sb.append("]");
+    return sb.toString();
+  }
+
+  public String printSideEffectsInFun() {
+    if (sideEffectsInFun.isEmpty()) {
+      return "SideEffectsInFun[]";
     }
 
     StringBuilder sb = new StringBuilder();
-    sb.append("Detected Conflicts:\n");
-
-    for (Map.Entry<CFAEdge, Set<SideEffectInfo>> entry : detectedConflictLocations.entrySet()) {
-      CFAEdge edge = entry.getKey();
-      Set<SideEffectInfo> effects = entry.getValue();
+    sb.append("SideEffectsInFun[");
 
-      sb.append("  Conflict at: \"")
-          .append(edge.getRawStatement())
-          .append("\" (")
-          .append(edge.getFileLocation().getNiceFileName())
-          .append(":")
-          .append(edge.getLineNumber())
-          .append(")\n");
+    boolean firstEffect = true;
+    for (Map.Entry<String, Set<SideEffectInfo>> entry : sideEffectsInFun.entrySet()) {
+      String functionName = entry.getKey();
+      for (SideEffectInfo effect : entry.getValue()) {
+        if (!firstEffect) {
+          sb.append(", ");
+        } else {
+          firstEffect = false;
+        }
 
-      for (SideEffectInfo info : effects) {
-        sb.append("    → ").append(info.toStringSimple()).append("\n");
+        sb.append("[").append(functionName).append(": ").append(effect.toStringSimple()).append("]");
       }
     }
 
-
+    sb.append("]");
     return sb.toString();
   }
 
+
   @Override
   public String toDOTLabel() {
-    return printConflict();
-
+    return printConflict() +
+        printSideEffectsInFun();
   }
 
   @Override
   public boolean shouldBeHighlighted() {
-    return false;
+    return !detectedConflicts.isEmpty();
   }
 }
Index: src/org/sosy_lab/cpachecker/cpa/unsequenced/SideEffectGatherVisitor.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>// This file is part of CPAchecker,\n// a tool for configurable software verification:\n// https://cpachecker.sosy-lab.org\n//\n// SPDX-FileCopyrightText: 2025 Dirk Beyer <https://www.sosy-lab.org>\n//\n// SPDX-License-Identifier: Apache-2.0\n\npackage org.sosy_lab.cpachecker.cpa.unsequenced;\n\nimport java.util.logging.Level;\nimport org.sosy_lab.common.log.LogManager;\nimport java.util.Collections;\nimport java.util.HashMap;\nimport java.util.HashSet;\nimport java.util.Map;\nimport java.util.Set;\nimport org.sosy_lab.cpachecker.cfa.ast.c.CBinaryExpression;\nimport org.sosy_lab.cpachecker.cfa.ast.c.CCastExpression;\nimport org.sosy_lab.cpachecker.cfa.ast.c.CComplexCastExpression;\nimport org.sosy_lab.cpachecker.cfa.ast.c.CExpression;\nimport org.sosy_lab.cpachecker.cfa.ast.c.CFieldReference;\nimport org.sosy_lab.cpachecker.cfa.ast.c.CFunctionCallExpression;\nimport org.sosy_lab.cpachecker.cfa.ast.c.CIdExpression;\nimport org.sosy_lab.cpachecker.cfa.ast.c.CPointerExpression;\nimport org.sosy_lab.cpachecker.cfa.ast.c.CRightHandSideVisitor;\nimport org.sosy_lab.cpachecker.cfa.ast.c.CUnaryExpression;\nimport org.sosy_lab.cpachecker.cfa.ast.c.CVariableDeclaration;\nimport org.sosy_lab.cpachecker.cfa.ast.c.DefaultCExpressionVisitor;\nimport org.sosy_lab.cpachecker.cfa.model.CFAEdge;\nimport org.sosy_lab.cpachecker.cpa.unsequenced.SideEffectInfo.AccessType;\nimport org.sosy_lab.cpachecker.exceptions.UnrecognizedCodeException;\nimport org.sosy_lab.cpachecker.util.states.MemoryLocation;\n\npublic class SideEffectGatherVisitor extends DefaultCExpressionVisitor<Map<CFAEdge, Set<SideEffectInfo>>, UnrecognizedCodeException>\n    implements CRightHandSideVisitor<Map<CFAEdge, Set<SideEffectInfo>>, UnrecognizedCodeException> {\n\n  private final UnseqBehaviorAnalysisState state;\n  private final CFAEdge cfaEdge;\n  private final AccessType accessType;\n  private final LogManager logger;\n\n  public SideEffectGatherVisitor(\n      UnseqBehaviorAnalysisState pState,\n      CFAEdge pCfaEdge,\n      AccessType pAccessType,\n      LogManager pLogger) {\n    state = pState;\n    cfaEdge = pCfaEdge;\n    accessType = pAccessType;\n    logger = pLogger;\n  }\n\n  @Override\n  protected Map<CFAEdge, Set<SideEffectInfo>> visitDefault(CExpression exp) throws UnrecognizedCodeException {\n    return Collections.emptyMap();\n  }\n\n  @Override\n  public Map<CFAEdge, Set<SideEffectInfo>> visit(CIdExpression idExpr) {\n    Set<SideEffectInfo> sideEffects = new HashSet<>();\n    // Variable access: record as READ if global\n    if (idExpr.getDeclaration() instanceof CVariableDeclaration decl) {\n      String qualifiedName = decl.getQualifiedName();\n      MemoryLocation loc = MemoryLocation.fromQualifiedName(qualifiedName);\n      if (!loc.isOnFunctionStack()) {\n          SideEffectInfo sideEffectInfo =  new SideEffectInfo(loc, accessType, cfaEdge);\n          sideEffects.add(sideEffectInfo);\n\n        logger.log(\n            Level.INFO,\n            String.format(\"Detected global %s access at %s: %s\",\n                accessType,\n                cfaEdge.getFileLocation().toString(),\n                qualifiedName)\n        );\n      }\n    }\n\n    return record(sideEffects);\n  }\n\n  @Override\n  public Map<CFAEdge, Set<SideEffectInfo>> visit(CFunctionCallExpression funCallExpr) throws UnrecognizedCodeException {\n    Set<SideEffectInfo> sideEffects = new HashSet<>();\n\n    //gather side effects for each parameter\n    for(CExpression param: funCallExpr.getParameterExpressions()){\n      Map<CFAEdge, Set<SideEffectInfo>> paramEffects = param.accept(this);\n      paramEffects.values().forEach(sideEffects::addAll);\n    }\n\n    //gather side effects inside function\n    CExpression funcExpr = funCallExpr.getFunctionNameExpression();\n    if (funcExpr instanceof CIdExpression idExpr) { //side effects inside foo()\n      String functionName = idExpr.getName();\n      if (state.getSideEffectsInFun().containsKey(functionName)) {\n        sideEffects.addAll(state.getSideEffectsInFun().get(functionName));\n      }\n    }else {\n      // TODO: handle indirect call via function pointer\n      // e.g., (*fp)(), *get_ptr()()...\n    }\n\n    return record(sideEffects) ;\n  }\n\n  @Override\n  public Map<CFAEdge, Set<SideEffectInfo>> visit(CBinaryExpression binaryExpression) throws UnrecognizedCodeException {\n    Set<SideEffectInfo> sideEffects = new HashSet<>();\n\n    Map<CFAEdge, Set<SideEffectInfo>> leftSideEffects = binaryExpression.getOperand1().accept(this);\n    leftSideEffects.values().forEach(sideEffects::addAll);\n    Map<CFAEdge, Set<SideEffectInfo>> rightSideEffects = binaryExpression.getOperand2().accept(this);\n    rightSideEffects.values().forEach(sideEffects::addAll);\n\n    return record(sideEffects);\n  }\n\n\n  @Override\n  public Map<CFAEdge, Set<SideEffectInfo>> visit(CUnaryExpression unaryExpression) throws UnrecognizedCodeException {\n    Set<SideEffectInfo> effects = switch (unaryExpression.getOperator()) {\n      case SIZEOF, ALIGNOF -> Set.of();\n      case MINUS, TILDE, AMPER -> {\n        Map<CFAEdge, Set<SideEffectInfo>> operandEffects = unaryExpression.getOperand().accept(this);\n        Set<SideEffectInfo> collected = new HashSet<>();\n        operandEffects.values().forEach(collected::addAll);\n        yield collected;\n      }\n      default -> throw new UnrecognizedCodeException(\"unknown unary operator\", cfaEdge, unaryExpression);\n    };\n    return record(effects);\n  }\n\n  @Override\n  public Map<CFAEdge, Set<SideEffectInfo>> visit(CFieldReference fieldReference) throws UnrecognizedCodeException {\n    return collectAndRecord(fieldReference);\n  }\n\n  @Override\n  public Map<CFAEdge, Set<SideEffectInfo>> visit(CCastExpression castExpr) throws UnrecognizedCodeException {\n    return collectAndRecord(castExpr);\n  }\n\n  @Override\n  public Map<CFAEdge, Set<SideEffectInfo>> visit(CComplexCastExpression complexCastExpr) throws UnrecognizedCodeException {\n    return collectAndRecord(complexCastExpr);\n  }\n\n  @Override\n  public Map<CFAEdge, Set<SideEffectInfo>> visit(CPointerExpression pointExpr) throws UnrecognizedCodeException {\n    return collectAndRecord(pointExpr);\n  }\n\n  private Map<CFAEdge, Set<SideEffectInfo>> record(Set<SideEffectInfo> effects) {\n    if (effects.isEmpty()) {\n      return Collections.emptyMap();\n    }\n    Map<CFAEdge, Set<SideEffectInfo>> result = new HashMap<>();\n    result.put(cfaEdge, effects);\n    return result;\n  }\n\n  private Map<CFAEdge, Set<SideEffectInfo>> collectAndRecord(CExpression expr) throws UnrecognizedCodeException {\n    Set<SideEffectInfo> sideEffects = new HashSet<>();\n    Map<CFAEdge, Set<SideEffectInfo>> effects = expr.accept(this);\n    effects.values().forEach(sideEffects::addAll);\n    return record(sideEffects);\n  }\n}\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/org/sosy_lab/cpachecker/cpa/unsequenced/SideEffectGatherVisitor.java b/src/org/sosy_lab/cpachecker/cpa/unsequenced/SideEffectGatherVisitor.java
--- a/src/org/sosy_lab/cpachecker/cpa/unsequenced/SideEffectGatherVisitor.java	(revision 994693c6616e755015ebf8f13b83d23d2f5cd593)
+++ b/src/org/sosy_lab/cpachecker/cpa/unsequenced/SideEffectGatherVisitor.java	(date 1744703706014)
@@ -11,9 +11,7 @@
 import java.util.logging.Level;
 import org.sosy_lab.common.log.LogManager;
 import java.util.Collections;
-import java.util.HashMap;
 import java.util.HashSet;
-import java.util.Map;
 import java.util.Set;
 import org.sosy_lab.cpachecker.cfa.ast.c.CBinaryExpression;
 import org.sosy_lab.cpachecker.cfa.ast.c.CCastExpression;
@@ -32,8 +30,8 @@
 import org.sosy_lab.cpachecker.exceptions.UnrecognizedCodeException;
 import org.sosy_lab.cpachecker.util.states.MemoryLocation;
 
-public class SideEffectGatherVisitor extends DefaultCExpressionVisitor<Map<CFAEdge, Set<SideEffectInfo>>, UnrecognizedCodeException>
-    implements CRightHandSideVisitor<Map<CFAEdge, Set<SideEffectInfo>>, UnrecognizedCodeException> {
+public class SideEffectGatherVisitor extends DefaultCExpressionVisitor<Set<SideEffectInfo>, UnrecognizedCodeException>
+    implements CRightHandSideVisitor<Set<SideEffectInfo>, UnrecognizedCodeException> {
 
   private final UnseqBehaviorAnalysisState state;
   private final CFAEdge cfaEdge;
@@ -52,14 +50,14 @@
   }
 
   @Override
-  protected Map<CFAEdge, Set<SideEffectInfo>> visitDefault(CExpression exp) throws UnrecognizedCodeException {
-    return Collections.emptyMap();
+  protected Set<SideEffectInfo> visitDefault(CExpression exp) throws UnrecognizedCodeException {
+    return Collections.emptySet();
   }
 
   @Override
-  public Map<CFAEdge, Set<SideEffectInfo>> visit(CIdExpression idExpr) {
+  public Set<SideEffectInfo> visit(CIdExpression idExpr) {
     Set<SideEffectInfo> sideEffects = new HashSet<>();
-    // Variable access: record as READ if global
+    // Variable access: record as READ/WRITE if global
     if (idExpr.getDeclaration() instanceof CVariableDeclaration decl) {
       String qualifiedName = decl.getQualifiedName();
       MemoryLocation loc = MemoryLocation.fromQualifiedName(qualifiedName);
@@ -77,17 +75,17 @@
       }
     }
 
-    return record(sideEffects);
+    return sideEffects;
   }
 
   @Override
-  public Map<CFAEdge, Set<SideEffectInfo>> visit(CFunctionCallExpression funCallExpr) throws UnrecognizedCodeException {
+  public Set<SideEffectInfo> visit(CFunctionCallExpression funCallExpr) throws UnrecognizedCodeException {
     Set<SideEffectInfo> sideEffects = new HashSet<>();
 
     //gather side effects for each parameter
     for(CExpression param: funCallExpr.getParameterExpressions()){
-      Map<CFAEdge, Set<SideEffectInfo>> paramEffects = param.accept(this);
-      paramEffects.values().forEach(sideEffects::addAll);
+      Set<SideEffectInfo> paramEffects = param.accept(this);
+      sideEffects.addAll(paramEffects);
     }
 
     //gather side effects inside function
@@ -102,70 +100,49 @@
       // e.g., (*fp)(), *get_ptr()()...
     }
 
-    return record(sideEffects) ;
+    return sideEffects;
   }
 
   @Override
-  public Map<CFAEdge, Set<SideEffectInfo>> visit(CBinaryExpression binaryExpression) throws UnrecognizedCodeException {
+  public  Set<SideEffectInfo> visit(CBinaryExpression binaryExpression) throws UnrecognizedCodeException {
     Set<SideEffectInfo> sideEffects = new HashSet<>();
 
-    Map<CFAEdge, Set<SideEffectInfo>> leftSideEffects = binaryExpression.getOperand1().accept(this);
-    leftSideEffects.values().forEach(sideEffects::addAll);
-    Map<CFAEdge, Set<SideEffectInfo>> rightSideEffects = binaryExpression.getOperand2().accept(this);
-    rightSideEffects.values().forEach(sideEffects::addAll);
+    Set<SideEffectInfo> leftSideEffects = binaryExpression.getOperand1().accept(this);
+    sideEffects.addAll(leftSideEffects);
+    Set<SideEffectInfo> rightSideEffects = binaryExpression.getOperand2().accept(this);
+    sideEffects.addAll(rightSideEffects);;
 
-    return record(sideEffects);
+    return sideEffects;
   }
 
 
   @Override
-  public Map<CFAEdge, Set<SideEffectInfo>> visit(CUnaryExpression unaryExpression) throws UnrecognizedCodeException {
-    Set<SideEffectInfo> effects = switch (unaryExpression.getOperator()) {
-      case SIZEOF, ALIGNOF -> Set.of();
-      case MINUS, TILDE, AMPER -> {
-        Map<CFAEdge, Set<SideEffectInfo>> operandEffects = unaryExpression.getOperand().accept(this);
-        Set<SideEffectInfo> collected = new HashSet<>();
-        operandEffects.values().forEach(collected::addAll);
-        yield collected;
-      }
-      default -> throw new UnrecognizedCodeException("unknown unary operator", cfaEdge, unaryExpression);
+  public Set<SideEffectInfo> visit(CUnaryExpression unaryExpression) throws UnrecognizedCodeException {
+    return switch (unaryExpression.getOperator()) {
+      case SIZEOF, ALIGNOF -> Collections.emptySet();
+      case MINUS, TILDE, AMPER -> unaryExpression.getOperand().accept(this);
+      default -> throw new UnrecognizedCodeException("Unknown unary operator", cfaEdge, unaryExpression);
     };
-    return record(effects);
   }
 
   @Override
-  public Map<CFAEdge, Set<SideEffectInfo>> visit(CFieldReference fieldReference) throws UnrecognizedCodeException {
-    return collectAndRecord(fieldReference);
+  public Set<SideEffectInfo> visit(CFieldReference fieldReference) throws UnrecognizedCodeException {
+    return fieldReference.getFieldOwner().accept(this);
   }
 
   @Override
-  public Map<CFAEdge, Set<SideEffectInfo>> visit(CCastExpression castExpr) throws UnrecognizedCodeException {
-    return collectAndRecord(castExpr);
+  public Set<SideEffectInfo> visit(CCastExpression castExpr) throws UnrecognizedCodeException {
+    return castExpr.getOperand().accept(this);
   }
 
   @Override
-  public Map<CFAEdge, Set<SideEffectInfo>> visit(CComplexCastExpression complexCastExpr) throws UnrecognizedCodeException {
-    return collectAndRecord(complexCastExpr);
+  public Set<SideEffectInfo> visit(CComplexCastExpression complexCastExpr) throws UnrecognizedCodeException {
+    return complexCastExpr.getOperand().accept(this);
   }
 
   @Override
-  public Map<CFAEdge, Set<SideEffectInfo>> visit(CPointerExpression pointExpr) throws UnrecognizedCodeException {
-    return collectAndRecord(pointExpr);
-  }
-
-  private Map<CFAEdge, Set<SideEffectInfo>> record(Set<SideEffectInfo> effects) {
-    if (effects.isEmpty()) {
-      return Collections.emptyMap();
-    }
-    Map<CFAEdge, Set<SideEffectInfo>> result = new HashMap<>();
-    result.put(cfaEdge, effects);
-    return result;
+  public Set<SideEffectInfo> visit(CPointerExpression pointExpr) throws UnrecognizedCodeException {
+    return pointExpr.getOperand().accept(this);
   }
 
-  private Map<CFAEdge, Set<SideEffectInfo>> collectAndRecord(CExpression expr) throws UnrecognizedCodeException {
-    Set<SideEffectInfo> sideEffects = new HashSet<>();
-    Map<CFAEdge, Set<SideEffectInfo>> effects = expr.accept(this);
-    effects.values().forEach(sideEffects::addAll);
-    return record(sideEffects);
-  }
 }
Index: src/org/sosy_lab/cpachecker/cpa/unsequenced/testcases/detected_subexpression_global_ww.c
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>#include <stdio.h>\n\n//6.5\nint r = 0;\n\nint g(int x){\n  return r = x;\n}\n\nint f(int x){\n  int result = g(1)+g(2);\n  return(r = x);\n}\n\nint main(){\n  int result = f(1)*(f(2)+f(3)) - f(4);\n  //possible r is 1,2,3,4\n  printf(\"r = %d\\n\", r);\n  printf(\"result = %d\\n\", result);\n\n  return 0;\n}
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/org/sosy_lab/cpachecker/cpa/unsequenced/testcases/detected_subexpression_global_ww.c b/src/org/sosy_lab/cpachecker/cpa/unsequenced/testcases/detected_subexpression_global_ww.c
--- a/src/org/sosy_lab/cpachecker/cpa/unsequenced/testcases/detected_subexpression_global_ww.c	(revision 994693c6616e755015ebf8f13b83d23d2f5cd593)
+++ b/src/org/sosy_lab/cpachecker/cpa/unsequenced/testcases/detected_subexpression_global_ww.c	(date 1744780137682)
@@ -1,22 +1,18 @@
 #include <stdio.h>
 
-//6.5
-int r = 0;
+int x = 0;
 
-int g(int x){
-  return r = x;
+int f() {
+  x = 1;
+  return 0;
 }
 
-int f(int x){
-  int result = g(1)+g(2);
-  return(r = x);
+int g() {
+  x = 2;
+  return 0;
 }
 
-int main(){
-  int result = f(1)*(f(2)+f(3)) - f(4);
-  //possible r is 1,2,3,4
-  printf("r = %d\n", r);
-  printf("result = %d\n", result);
-
+int main() {
+  int y = f() + g(); // Potential unsequenced write-write conflict on 'x'
   return 0;
 }
\ No newline at end of file
Index: src/org/sosy_lab/cpachecker/cpa/unsequenced/test/undeteced_one_global_var.c
===================================================================
diff --git a/src/org/sosy_lab/cpachecker/cpa/unsequenced/test/undeteced_one_global_var.c b/src/org/sosy_lab/cpachecker/cpa/unsequenced/test/undeteced_one_global_var.c
deleted file mode 100644
--- a/src/org/sosy_lab/cpachecker/cpa/unsequenced/test/undeteced_one_global_var.c	(revision 994693c6616e755015ebf8f13b83d23d2f5cd593)
+++ /dev/null	(revision 994693c6616e755015ebf8f13b83d23d2f5cd593)
@@ -1,11 +0,0 @@
-#include <stdio.h>
-
-int x = 5;
-
-int main(){
-    int y = 5;
-    int z = x + y;
-    printf("z = %d\n", z);
-
-    return 0;
-}
\ No newline at end of file
Index: src/org/sosy_lab/cpachecker/cpa/unsequenced/GlobalVarAnalysisState.java
===================================================================
diff --git a/src/org/sosy_lab/cpachecker/cpa/unsequenced/GlobalVarAnalysisState.java b/src/org/sosy_lab/cpachecker/cpa/unsequenced/GlobalVarAnalysisState.java
deleted file mode 100644
--- a/src/org/sosy_lab/cpachecker/cpa/unsequenced/GlobalVarAnalysisState.java	(revision 994693c6616e755015ebf8f13b83d23d2f5cd593)
+++ /dev/null	(revision 994693c6616e755015ebf8f13b83d23d2f5cd593)
@@ -1,62 +0,0 @@
-// This file is part of CPAchecker,
-// a tool for configurable software verification:
-// https://cpachecker.sosy-lab.org
-//
-// SPDX-FileCopyrightText: 2025 Dirk Beyer <https://www.sosy-lab.org>
-//
-// SPDX-License-Identifier: Apache-2.0
-
-package org.sosy_lab.cpachecker.cpa.unsequenced;
-
-import java.util.ArrayList;
-import java.util.HashSet;
-import java.util.List;
-import java.util.Set;
-import org.sosy_lab.cpachecker.core.interfaces.AbstractState;
-import org.sosy_lab.cpachecker.core.interfaces.Graphable;
-
-public class GlobalVarAnalysisState implements AbstractState, Graphable {
-  private final Set<String> globalVars;
-  private final boolean validReturn;
-  private final List<String> detectedAssignedVars;
-
-  public GlobalVarAnalysisState(
-      Set<String> pGlobalVars, boolean pValidReturn, List<String> pDetectedAssignedVars) {
-    globalVars = pGlobalVars;
-    validReturn = pValidReturn;
-    detectedAssignedVars = pDetectedAssignedVars;
-  }
-
-  public GlobalVarAnalysisState() {
-    globalVars = new HashSet<>();
-    validReturn = false;
-    detectedAssignedVars = new ArrayList<>();
-  }
-
-  public Set<String> getGlobalVars() {
-    return globalVars;
-  }
-
-  public boolean isValidReturn() {
-    return validReturn;
-  }
-
-  public List<String> getDetectedAssignedVars() {
-    return detectedAssignedVars;
-  }
-
-  @Override
-  public String toDOTLabel() {
-    return "global vars = "
-        + globalVars.toString()
-        + ", validReturn = "
-        + validReturn
-        + ", detectedAssignedVars = "
-        + detectedAssignedVars.toString();
-  }
-
-  @Override
-  public boolean shouldBeHighlighted() {
-    return false;
-  }
-}
Index: src/org/sosy_lab/cpachecker/cpa/unsequenced/test/detected_assign_to_itself.c
===================================================================
diff --git a/src/org/sosy_lab/cpachecker/cpa/unsequenced/test/detected_assign_to_itself.c b/src/org/sosy_lab/cpachecker/cpa/unsequenced/test/detected_assign_to_itself.c
deleted file mode 100644
--- a/src/org/sosy_lab/cpachecker/cpa/unsequenced/test/detected_assign_to_itself.c	(revision 994693c6616e755015ebf8f13b83d23d2f5cd593)
+++ /dev/null	(revision 994693c6616e755015ebf8f13b83d23d2f5cd593)
@@ -1,10 +0,0 @@
-#include <stdio.h>
-
-int x = 5;
-int y = 10;
-
-int main(){
-    x = x + y;
-    printf("x = %d\n", x);
-    return 0;
-}
\ No newline at end of file
Index: src/org/sosy_lab/cpachecker/cpa/unsequenced/test/undetected_computation_in_function.c
===================================================================
diff --git a/src/org/sosy_lab/cpachecker/cpa/unsequenced/test/undetected_computation_in_function.c b/src/org/sosy_lab/cpachecker/cpa/unsequenced/test/undetected_computation_in_function.c
deleted file mode 100644
--- a/src/org/sosy_lab/cpachecker/cpa/unsequenced/test/undetected_computation_in_function.c	(revision 994693c6616e755015ebf8f13b83d23d2f5cd593)
+++ /dev/null	(revision 994693c6616e755015ebf8f13b83d23d2f5cd593)
@@ -1,12 +0,0 @@
-#include <stdio.h>
-
-int minus(int a, int b){
-    return a-b;
-}
-
-int main(){
-    int y = 10;
-    int result = minus(5,y);
-    printf("result = %d\n", result);
-    return 0;
-}
\ No newline at end of file
Index: src/org/sosy_lab/cpachecker/cpa/unsequenced/GlobalVarAnalysisCPA.java
===================================================================
diff --git a/src/org/sosy_lab/cpachecker/cpa/unsequenced/GlobalVarAnalysisCPA.java b/src/org/sosy_lab/cpachecker/cpa/unsequenced/GlobalVarAnalysisCPA.java
deleted file mode 100644
--- a/src/org/sosy_lab/cpachecker/cpa/unsequenced/GlobalVarAnalysisCPA.java	(revision 994693c6616e755015ebf8f13b83d23d2f5cd593)
+++ /dev/null	(revision 994693c6616e755015ebf8f13b83d23d2f5cd593)
@@ -1,94 +0,0 @@
-// This file is part of CPAchecker,
-// a tool for configurable software verification:
-// https://cpachecker.sosy-lab.org
-//
-// SPDX-FileCopyrightText: 2025 Dirk Beyer <https://www.sosy-lab.org>
-//
-// SPDX-License-Identifier: Apache-2.0
-
-package org.sosy_lab.cpachecker.cpa.unsequenced;
-
-import java.util.Collection;
-import org.sosy_lab.common.ShutdownNotifier;
-import org.sosy_lab.common.configuration.Configuration;
-import org.sosy_lab.common.configuration.InvalidConfigurationException;
-import org.sosy_lab.common.configuration.Option;
-import org.sosy_lab.common.configuration.Options;
-import org.sosy_lab.common.log.LogManager;
-import org.sosy_lab.cpachecker.cfa.CFA;
-import org.sosy_lab.cpachecker.cfa.model.CFANode;
-import org.sosy_lab.cpachecker.core.defaults.AbstractCPA;
-import org.sosy_lab.cpachecker.core.defaults.AutomaticCPAFactory;
-import org.sosy_lab.cpachecker.core.defaults.DelegateAbstractDomain;
-import org.sosy_lab.cpachecker.core.interfaces.AbstractState;
-import org.sosy_lab.cpachecker.core.interfaces.CPAFactory;
-import org.sosy_lab.cpachecker.core.interfaces.MergeOperator;
-import org.sosy_lab.cpachecker.core.interfaces.StateSpacePartition;
-import org.sosy_lab.cpachecker.core.interfaces.Statistics;
-import org.sosy_lab.cpachecker.core.interfaces.StatisticsProvider;
-import org.sosy_lab.cpachecker.core.interfaces.StopOperator;
-import org.sosy_lab.cpachecker.core.interfaces.TransferRelation;
-import org.sosy_lab.cpachecker.cpa.interval.IntervalAnalysisState;
-import org.sosy_lab.cpachecker.util.StateToFormulaWriter;
-
-@Options(prefix = "cpa.globalvar")
-public class GlobalVarAnalysisCPA extends AbstractCPA implements StatisticsProvider {
-
-  @Option(
-      secure = true,
-      name = "merge",
-      toUppercase = true,
-      values = {"SEP", "JOIN"},
-      description = "which merge operator to use for GlobalVarAnalysisCPA")
-  private String mergeType = "SEP";
-
-  @Option(
-      secure = true,
-      name = "stop",
-      toUppercase = true,
-      values = {"SEP", "JOIN", "NEVER"},
-      description = "which stop operator to use for GlobalVarAnalysisCPA")
-  private String stopType = "SEP";
-
-  private final StateToFormulaWriter writer;
-  private final LogManager logger;
-
-  private GlobalVarAnalysisCPA(
-      Configuration config, LogManager pLogger, ShutdownNotifier shutdownNotifier, CFA cfa)
-      throws InvalidConfigurationException {
-    super("sep", "sep", DelegateAbstractDomain.<IntervalAnalysisState>getInstance(), null);
-    config.inject(this);
-    writer = new StateToFormulaWriter(config, pLogger, shutdownNotifier, cfa);
-    logger = pLogger;
-  }
-
-  public static CPAFactory factory() {
-    return AutomaticCPAFactory.forType(GlobalVarAnalysisCPA.class);
-  }
-
-  @Override
-  public MergeOperator getMergeOperator() {
-    return buildMergeOperator(mergeType);
-  }
-
-  @Override
-  public StopOperator getStopOperator() {
-    return buildStopOperator(stopType);
-  }
-
-  @Override
-  public TransferRelation getTransferRelation() {
-    return new GlobalVarAnalysisTransferRelation(logger);
-  }
-
-  @Override
-  public AbstractState getInitialState(CFANode node, StateSpacePartition partition)
-      throws InterruptedException {
-    return new GlobalVarAnalysisState();
-  }
-
-  @Override
-  public void collectStatistics(Collection<Statistics> pStatsCollection) {
-    writer.collectStatistics(pStatsCollection);
-  }
-}
Index: src/org/sosy_lab/cpachecker/cpa/unsequenced/test/undetected_non_global_var.c
===================================================================
diff --git a/src/org/sosy_lab/cpachecker/cpa/unsequenced/test/undetected_non_global_var.c b/src/org/sosy_lab/cpachecker/cpa/unsequenced/test/undetected_non_global_var.c
deleted file mode 100644
--- a/src/org/sosy_lab/cpachecker/cpa/unsequenced/test/undetected_non_global_var.c	(revision 994693c6616e755015ebf8f13b83d23d2f5cd593)
+++ /dev/null	(revision 994693c6616e755015ebf8f13b83d23d2f5cd593)
@@ -1,10 +0,0 @@
-#include <stdio.h>
-
-int main(){
-    int x = 10;
-    int y = 5;
-    int z = x + y;
-    printf("z = %d\n", z);
-
-    return 0;
-}
\ No newline at end of file
Index: src/org/sosy_lab/cpachecker/cpa/unsequenced/test/detected_global_parameters.c
===================================================================
diff --git a/src/org/sosy_lab/cpachecker/cpa/unsequenced/test/detected_global_parameters.c b/src/org/sosy_lab/cpachecker/cpa/unsequenced/test/detected_global_parameters.c
deleted file mode 100644
--- a/src/org/sosy_lab/cpachecker/cpa/unsequenced/test/detected_global_parameters.c	(revision 994693c6616e755015ebf8f13b83d23d2f5cd593)
+++ /dev/null	(revision 994693c6616e755015ebf8f13b83d23d2f5cd593)
@@ -1,16 +0,0 @@
-#include <stdio.h>
-
-int x = 5;
-int y = 10;
-
-
-int minus(int a, int b){
-  return a - b;
-}
-
-int main(){
-    int result;
-    result = minus(x,y);
-    printf("result = %d\n", result);
-    return 0;
-}
\ No newline at end of file
Index: src/org/sosy_lab/cpachecker/cpa/unsequenced/test/detected_assign_to_third_var.c
===================================================================
diff --git a/src/org/sosy_lab/cpachecker/cpa/unsequenced/test/detected_assign_to_third_var.c b/src/org/sosy_lab/cpachecker/cpa/unsequenced/test/detected_assign_to_third_var.c
deleted file mode 100644
--- a/src/org/sosy_lab/cpachecker/cpa/unsequenced/test/detected_assign_to_third_var.c	(revision 994693c6616e755015ebf8f13b83d23d2f5cd593)
+++ /dev/null	(revision 994693c6616e755015ebf8f13b83d23d2f5cd593)
@@ -1,10 +0,0 @@
-#include <stdio.h>
-
-int x = 5;
-int y = 10;
-
-int main(){
-    int z = x + y;
-    printf("z = %d\n", z);
-    return 0;
-}
\ No newline at end of file
Index: src/org/sosy_lab/cpachecker/cpa/unsequenced/GlobalVarAnalysisTransferRelation.java
===================================================================
diff --git a/src/org/sosy_lab/cpachecker/cpa/unsequenced/GlobalVarAnalysisTransferRelation.java b/src/org/sosy_lab/cpachecker/cpa/unsequenced/GlobalVarAnalysisTransferRelation.java
deleted file mode 100644
--- a/src/org/sosy_lab/cpachecker/cpa/unsequenced/GlobalVarAnalysisTransferRelation.java	(revision 994693c6616e755015ebf8f13b83d23d2f5cd593)
+++ /dev/null	(revision 994693c6616e755015ebf8f13b83d23d2f5cd593)
@@ -1,196 +0,0 @@
-// This file is part of CPAchecker,
-// a tool for configurable software verification:
-// https://cpachecker.sosy-lab.org
-//
-// SPDX-FileCopyrightText: 2025 Dirk Beyer <https://www.sosy-lab.org>
-//
-// SPDX-License-Identifier: Apache-2.0
-
-package org.sosy_lab.cpachecker.cpa.unsequenced;
-
-import java.util.ArrayList;
-import java.util.HashSet;
-import java.util.List;
-import java.util.Optional;
-import java.util.Set;
-import java.util.logging.Level;
-import org.sosy_lab.common.log.LogManager;
-import org.sosy_lab.cpachecker.cfa.ast.c.CBinaryExpression;
-import org.sosy_lab.cpachecker.cfa.ast.c.CBinaryExpression.BinaryOperator;
-import org.sosy_lab.cpachecker.cfa.ast.c.CDeclaration;
-import org.sosy_lab.cpachecker.cfa.ast.c.CExpression;
-import org.sosy_lab.cpachecker.cfa.ast.c.CExpressionAssignmentStatement;
-import org.sosy_lab.cpachecker.cfa.ast.c.CFunctionCall;
-import org.sosy_lab.cpachecker.cfa.ast.c.CFunctionCallAssignmentStatement;
-import org.sosy_lab.cpachecker.cfa.ast.c.CIdExpression;
-import org.sosy_lab.cpachecker.cfa.ast.c.CInitializerExpression;
-import org.sosy_lab.cpachecker.cfa.ast.c.CLeftHandSide;
-import org.sosy_lab.cpachecker.cfa.ast.c.CParameterDeclaration;
-import org.sosy_lab.cpachecker.cfa.ast.c.CStatement;
-import org.sosy_lab.cpachecker.cfa.ast.c.CVariableDeclaration;
-import org.sosy_lab.cpachecker.cfa.model.BlankEdge;
-import org.sosy_lab.cpachecker.cfa.model.c.CAssumeEdge;
-import org.sosy_lab.cpachecker.cfa.model.c.CDeclarationEdge;
-import org.sosy_lab.cpachecker.cfa.model.c.CFunctionCallEdge;
-import org.sosy_lab.cpachecker.cfa.model.c.CFunctionReturnEdge;
-import org.sosy_lab.cpachecker.cfa.model.c.CReturnStatementEdge;
-import org.sosy_lab.cpachecker.cfa.model.c.CStatementEdge;
-import org.sosy_lab.cpachecker.core.defaults.ForwardingTransferRelation;
-import org.sosy_lab.cpachecker.core.interfaces.Precision;
-import org.sosy_lab.cpachecker.exceptions.UnrecognizedCodeException;
-
-public class GlobalVarAnalysisTransferRelation
-    extends ForwardingTransferRelation<GlobalVarAnalysisState, GlobalVarAnalysisState, Precision> {
-
-  private final LogManager logger;
-  private Set<String> formalParameters; // remember formal parameters used when we call a function
-
-  public GlobalVarAnalysisTransferRelation(LogManager pLogger) {
-    formalParameters = new HashSet<>();
-    logger = pLogger;
-  }
-
-  @Override
-  protected GlobalVarAnalysisState handleDeclarationEdge(
-      CDeclarationEdge declarationEdge, CDeclaration declaration) throws UnrecognizedCodeException {
-    Set<String> newGlobalVars = state.getGlobalVars();
-    List<String> newDetectedAssignedVars = new ArrayList<>(state.getDetectedAssignedVars());
-
-    if (declarationEdge.getDeclaration() instanceof CVariableDeclaration decl) {
-      boolean isGlobal = decl.isGlobal();
-      if (isGlobal) {
-        newGlobalVars.add(decl.getQualifiedName());
-      }
-
-      if (decl.getInitializer() instanceof CInitializerExpression init) {
-        if (init.getExpression() instanceof CBinaryExpression binaryExpr
-            && isGlobalPair(binaryExpr)) { // int x = y + z
-          newDetectedAssignedVars.add(decl.getQualifiedName());
-        }
-      }
-    }
-
-    return new GlobalVarAnalysisState(
-        newGlobalVars, state.isValidReturn(), newDetectedAssignedVars);
-  }
-
-  @Override
-  protected GlobalVarAnalysisState handleFunctionReturnEdge(
-      CFunctionReturnEdge cfaEdge, CFunctionCall summaryExpr, String callerFunctionName)
-      throws UnrecognizedCodeException {
-    logger.log(
-        Level.INFO,
-        "valid return:" + state.isValidReturn() + " summaryExpr:" + summaryExpr.toASTString());
-    List<String> newDetectedAssignedVars = new ArrayList<>(state.getDetectedAssignedVars());
-
-    if (state.isValidReturn()) {
-      if (summaryExpr
-          instanceof CFunctionCallAssignmentStatement fCallAssign) { // y = add() or int y = add()
-        CLeftHandSide lhs = fCallAssign.getLeftHandSide();
-        if (lhs instanceof CIdExpression idExpr) {
-          String assignedVar = idExpr.getDeclaration().getQualifiedName();
-          newDetectedAssignedVars.add(assignedVar);
-        }
-      }
-    }
-
-    return new GlobalVarAnalysisState(
-        state.getGlobalVars(), state.isValidReturn(), newDetectedAssignedVars);
-  }
-
-  @Override
-  protected GlobalVarAnalysisState handleStatementEdge(CStatementEdge cfaEdge, CStatement stat)
-      throws UnrecognizedCodeException {
-    List<String> newDetectedAssignedVars = new ArrayList<>(state.getDetectedAssignedVars());
-
-    if (stat instanceof CExpressionAssignmentStatement exprAssign) { // y = y + z
-      if (exprAssign.getRightHandSide() instanceof CBinaryExpression binaryExpr
-          && isGlobalPair(binaryExpr)) {
-        if (exprAssign.getLeftHandSide() instanceof CIdExpression idExpr) {
-          newDetectedAssignedVars.add(idExpr.getDeclaration().getQualifiedName());
-        }
-      }
-    }
-
-    return new GlobalVarAnalysisState(state.getGlobalVars(), false, newDetectedAssignedVars);
-  }
-
-  @Override
-  protected GlobalVarAnalysisState handleReturnStatementEdge(CReturnStatementEdge returnEdge)
-      throws UnrecognizedCodeException {
-
-    boolean newValidReturn = state.isValidReturn();
-    Optional<CExpression> expressionOptional = returnEdge.getExpression();
-
-    if (expressionOptional.isPresent()) {
-      CExpression returnExpression = expressionOptional.get();
-      if (returnExpression instanceof CBinaryExpression returnExpr) {
-        newValidReturn = isGlobalPair(returnExpr);
-      }
-    }
-
-    // delete formal vars from global var set
-    Set<String> newGlobalVars = new HashSet<>(state.getGlobalVars());
-    newGlobalVars.removeAll(formalParameters);
-    formalParameters.clear();
-
-    return new GlobalVarAnalysisState(
-        newGlobalVars, newValidReturn, state.getDetectedAssignedVars());
-  }
-
-  @Override
-  protected GlobalVarAnalysisState handleFunctionCallEdge(
-      CFunctionCallEdge callEdge,
-      List<CExpression> arguments,
-      List<CParameterDeclaration> parameters,
-      String calledFunctionName)
-      throws UnrecognizedCodeException {
-
-    Set<String> newGlobalVars = new HashSet<>(state.getGlobalVars());
-
-    // add related formal vars in global var set
-    for (int i = 0; i < parameters.size(); i++) {
-      CParameterDeclaration parameter = parameters.get(i);
-      CExpression argument = arguments.get(i);
-
-      if (argument instanceof CIdExpression idExpr) {
-        if (state.getGlobalVars().contains(idExpr.getDeclaration().getQualifiedName())) {
-          newGlobalVars.add(parameter.getQualifiedName());
-          formalParameters.add(parameter.getQualifiedName());
-        }
-      }
-    }
-
-    return new GlobalVarAnalysisState(
-        newGlobalVars, state.isValidReturn(), state.getDetectedAssignedVars());
-  }
-
-  private boolean isGlobalPair(CBinaryExpression binaryExpr) {
-    if (binaryExpr.getOperator() == BinaryOperator.PLUS
-        || binaryExpr.getOperator() == BinaryOperator.MINUS) {
-      CExpression operand1 = binaryExpr.getOperand1();
-      CExpression operand2 = binaryExpr.getOperand2();
-
-      if (operand1 instanceof CIdExpression var1 && operand2 instanceof CIdExpression var2) {
-        if (!var1.equals(var2)
-            && state.getGlobalVars().contains(var1.getDeclaration().getQualifiedName())
-            && state.getGlobalVars().contains(var2.getDeclaration().getQualifiedName())) {
-          return true;
-        }
-      }
-    }
-    return false;
-  }
-
-  @Override
-  protected GlobalVarAnalysisState handleAssumption(
-      CAssumeEdge cfaEdge, CExpression expression, boolean truthValue)
-      throws UnrecognizedCodeException {
-    return state;
-  }
-
-  @Override
-  protected GlobalVarAnalysisState handleBlankEdge(BlankEdge cfaEdge) {
-    return state;
-  }
-}
Index: src/org/sosy_lab/cpachecker/cpa/unsequenced/test/detected_multi.c
===================================================================
diff --git a/src/org/sosy_lab/cpachecker/cpa/unsequenced/test/detected_multi.c b/src/org/sosy_lab/cpachecker/cpa/unsequenced/test/detected_multi.c
deleted file mode 100644
--- a/src/org/sosy_lab/cpachecker/cpa/unsequenced/test/detected_multi.c	(revision 994693c6616e755015ebf8f13b83d23d2f5cd593)
+++ /dev/null	(revision 994693c6616e755015ebf8f13b83d23d2f5cd593)
@@ -1,19 +0,0 @@
-#include <stdio.h>
-
-int x = 5;
-int y = 10;
-int a = 1;
-int b = 2;
-
-int add(){
-  int c = a + b;
-  return x + y;
-}
-
-int main(){
-    int result;
-    result = add();
-    int c = a + b;
-    printf("result = %d\n", result);
-    return 0;
-}
\ No newline at end of file
Index: src/org/sosy_lab/cpachecker/cpa/unsequenced/test/undetected_multiplication.c
===================================================================
diff --git a/src/org/sosy_lab/cpachecker/cpa/unsequenced/test/undetected_multiplication.c b/src/org/sosy_lab/cpachecker/cpa/unsequenced/test/undetected_multiplication.c
deleted file mode 100644
--- a/src/org/sosy_lab/cpachecker/cpa/unsequenced/test/undetected_multiplication.c	(revision 994693c6616e755015ebf8f13b83d23d2f5cd593)
+++ /dev/null	(revision 994693c6616e755015ebf8f13b83d23d2f5cd593)
@@ -1,10 +0,0 @@
-#include <stdio.h>
-
-int x = 5;
-int y = 10;
-
-int main(){
-    int z = x * y;
-    printf("z = %d\n", z);
-    return 0;
-}
\ No newline at end of file
Index: src/org/sosy_lab/cpachecker/cpa/unsequenced/test/undetected_one_global_parameter.c
===================================================================
diff --git a/src/org/sosy_lab/cpachecker/cpa/unsequenced/test/undetected_one_global_parameter.c b/src/org/sosy_lab/cpachecker/cpa/unsequenced/test/undetected_one_global_parameter.c
deleted file mode 100644
--- a/src/org/sosy_lab/cpachecker/cpa/unsequenced/test/undetected_one_global_parameter.c	(revision 994693c6616e755015ebf8f13b83d23d2f5cd593)
+++ /dev/null	(revision 994693c6616e755015ebf8f13b83d23d2f5cd593)
@@ -1,15 +0,0 @@
-#include <stdio.h>
-
-int x = 5;
-
-
-int minus(int a, int b){
-  return a - b;
-}
-
-int main(){
-    int result;
-    result = minus(x,10);
-    printf("result = %d\n", result);
-    return 0;
-}
\ No newline at end of file
Index: src/org/sosy_lab/cpachecker/cpa/unsequenced/test/detected_computation_in_function.c
===================================================================
diff --git a/src/org/sosy_lab/cpachecker/cpa/unsequenced/test/detected_computation_in_function.c b/src/org/sosy_lab/cpachecker/cpa/unsequenced/test/detected_computation_in_function.c
deleted file mode 100644
--- a/src/org/sosy_lab/cpachecker/cpa/unsequenced/test/detected_computation_in_function.c	(revision 994693c6616e755015ebf8f13b83d23d2f5cd593)
+++ /dev/null	(revision 994693c6616e755015ebf8f13b83d23d2f5cd593)
@@ -1,14 +0,0 @@
-#include <stdio.h>
-
-int x = 5;
-int y = 10;
-
-int minus(){
-    return x-y;
-}
-
-int main(){
-    int result = minus();
-    printf("result = %d\n", result);
-    return 0;
-}
\ No newline at end of file
Index: .idea/codeStyles/Project.xml
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+><component name=\"ProjectCodeStyleConfiguration\">\n  <code_scheme name=\"Project\" version=\"173\">\n    <option name=\"OTHER_INDENT_OPTIONS\">\n      <value>\n        <option name=\"INDENT_SIZE\" value=\"2\" />\n        <option name=\"CONTINUATION_INDENT_SIZE\" value=\"4\" />\n        <option name=\"TAB_SIZE\" value=\"8\" />\n      </value>\n    </option>\n    <option name=\"LINE_SEPARATOR\" value=\"&#10;\" />\n    <option name=\"RIGHT_MARGIN\" value=\"100\" />\n    <JavaCodeStyleSettings>\n      <option name=\"PARAMETER_NAME_PREFIX\" value=\"p\" />\n      <option name=\"INSERT_INNER_CLASS_IMPORTS\" value=\"true\" />\n      <option name=\"CLASS_COUNT_TO_USE_IMPORT_ON_DEMAND\" value=\"99\" />\n      <option name=\"NAMES_COUNT_TO_USE_IMPORT_ON_DEMAND\" value=\"99\" />\n      <option name=\"PACKAGES_TO_USE_IMPORT_ON_DEMAND\">\n        <value />\n      </option>\n      <option name=\"IMPORT_LAYOUT_TABLE\">\n        <value>\n          <package name=\"\" withSubpackages=\"true\" static=\"true\" />\n          <emptyLine />\n          <package name=\"\" withSubpackages=\"true\" static=\"false\" />\n        </value>\n      </option>\n      <option name=\"JD_P_AT_EMPTY_LINES\" value=\"false\" />\n      <option name=\"JD_KEEP_EMPTY_PARAMETER\" value=\"false\" />\n      <option name=\"JD_KEEP_EMPTY_EXCEPTION\" value=\"false\" />\n      <option name=\"JD_KEEP_EMPTY_RETURN\" value=\"false\" />\n    </JavaCodeStyleSettings>\n    <ADDITIONAL_INDENT_OPTIONS fileType=\"haml\">\n      <option name=\"INDENT_SIZE\" value=\"2\" />\n    </ADDITIONAL_INDENT_OPTIONS>\n    <ADDITIONAL_INDENT_OPTIONS fileType=\"java\">\n      <option name=\"INDENT_SIZE\" value=\"2\" />\n      <option name=\"CONTINUATION_INDENT_SIZE\" value=\"4\" />\n      <option name=\"TAB_SIZE\" value=\"8\" />\n    </ADDITIONAL_INDENT_OPTIONS>\n    <ADDITIONAL_INDENT_OPTIONS fileType=\"js\">\n      <option name=\"CONTINUATION_INDENT_SIZE\" value=\"4\" />\n    </ADDITIONAL_INDENT_OPTIONS>\n    <ADDITIONAL_INDENT_OPTIONS fileType=\"sass\">\n      <option name=\"INDENT_SIZE\" value=\"2\" />\n    </ADDITIONAL_INDENT_OPTIONS>\n    <ADDITIONAL_INDENT_OPTIONS fileType=\"yml\">\n      <option name=\"INDENT_SIZE\" value=\"2\" />\n    </ADDITIONAL_INDENT_OPTIONS>\n    <codeStyleSettings language=\"ECMA Script Level 4\">\n      <option name=\"KEEP_BLANK_LINES_IN_CODE\" value=\"1\" />\n      <option name=\"ALIGN_MULTILINE_PARAMETERS_IN_CALLS\" value=\"true\" />\n      <option name=\"ALIGN_MULTILINE_BINARY_OPERATION\" value=\"true\" />\n      <option name=\"ALIGN_MULTILINE_TERNARY_OPERATION\" value=\"true\" />\n      <option name=\"ALIGN_MULTILINE_EXTENDS_LIST\" value=\"true\" />\n      <option name=\"ALIGN_MULTILINE_ARRAY_INITIALIZER_EXPRESSION\" value=\"true\" />\n      <option name=\"CALL_PARAMETERS_WRAP\" value=\"1\" />\n      <option name=\"METHOD_PARAMETERS_WRAP\" value=\"1\" />\n      <option name=\"EXTENDS_LIST_WRAP\" value=\"1\" />\n      <option name=\"EXTENDS_KEYWORD_WRAP\" value=\"1\" />\n      <option name=\"METHOD_CALL_CHAIN_WRAP\" value=\"1\" />\n      <option name=\"BINARY_OPERATION_WRAP\" value=\"1\" />\n      <option name=\"BINARY_OPERATION_SIGN_ON_NEXT_LINE\" value=\"true\" />\n      <option name=\"TERNARY_OPERATION_WRAP\" value=\"1\" />\n      <option name=\"TERNARY_OPERATION_SIGNS_ON_NEXT_LINE\" value=\"true\" />\n      <option name=\"FOR_STATEMENT_WRAP\" value=\"1\" />\n      <option name=\"ARRAY_INITIALIZER_WRAP\" value=\"1\" />\n      <option name=\"ASSIGNMENT_WRAP\" value=\"5\" />\n      <option name=\"WRAP_COMMENTS\" value=\"true\" />\n      <option name=\"IF_BRACE_FORCE\" value=\"3\" />\n      <option name=\"DOWHILE_BRACE_FORCE\" value=\"3\" />\n      <option name=\"WHILE_BRACE_FORCE\" value=\"3\" />\n      <option name=\"FOR_BRACE_FORCE\" value=\"3\" />\n    </codeStyleSettings>\n    <codeStyleSettings language=\"JAVA\">\n      <option name=\"ALIGN_MULTILINE_TERNARY_OPERATION\" value=\"true\" />\n      <option name=\"ALIGN_MULTILINE_THROWS_LIST\" value=\"true\" />\n      <option name=\"ALIGN_MULTILINE_EXTENDS_LIST\" value=\"true\" />\n      <option name=\"CALL_PARAMETERS_WRAP\" value=\"1\" />\n      <option name=\"METHOD_PARAMETERS_WRAP\" value=\"5\" />\n      <option name=\"METHOD_PARAMETERS_LPAREN_ON_NEXT_LINE\" value=\"true\" />\n      <option name=\"EXTENDS_LIST_WRAP\" value=\"1\" />\n      <option name=\"THROWS_LIST_WRAP\" value=\"1\" />\n      <option name=\"EXTENDS_KEYWORD_WRAP\" value=\"1\" />\n      <option name=\"THROWS_KEYWORD_WRAP\" value=\"1\" />\n      <option name=\"METHOD_CALL_CHAIN_WRAP\" value=\"1\" />\n      <option name=\"BINARY_OPERATION_WRAP\" value=\"1\" />\n      <option name=\"BINARY_OPERATION_SIGN_ON_NEXT_LINE\" value=\"true\" />\n      <option name=\"TERNARY_OPERATION_WRAP\" value=\"1\" />\n      <option name=\"TERNARY_OPERATION_SIGNS_ON_NEXT_LINE\" value=\"true\" />\n      <option name=\"FOR_STATEMENT_WRAP\" value=\"1\" />\n      <option name=\"ASSIGNMENT_WRAP\" value=\"1\" />\n      <option name=\"ASSERT_STATEMENT_WRAP\" value=\"1\" />\n      <option name=\"ASSERT_STATEMENT_COLON_ON_NEXT_LINE\" value=\"true\" />\n      <option name=\"IF_BRACE_FORCE\" value=\"3\" />\n      <option name=\"DOWHILE_BRACE_FORCE\" value=\"3\" />\n      <option name=\"WHILE_BRACE_FORCE\" value=\"3\" />\n      <option name=\"FOR_BRACE_FORCE\" value=\"3\" />\n      <option name=\"VARIABLE_ANNOTATION_WRAP\" value=\"2\" />\n      <option name=\"ENUM_CONSTANTS_WRAP\" value=\"2\" />\n      <indentOptions>\n        <option name=\"INDENT_SIZE\" value=\"2\" />\n        <option name=\"CONTINUATION_INDENT_SIZE\" value=\"4\" />\n        <option name=\"TAB_SIZE\" value=\"8\" />\n      </indentOptions>\n    </codeStyleSettings>\n    <codeStyleSettings language=\"JavaScript\">\n      <option name=\"KEEP_BLANK_LINES_IN_CODE\" value=\"1\" />\n      <option name=\"ALIGN_MULTILINE_PARAMETERS_IN_CALLS\" value=\"true\" />\n      <option name=\"ALIGN_MULTILINE_BINARY_OPERATION\" value=\"true\" />\n      <option name=\"ALIGN_MULTILINE_TERNARY_OPERATION\" value=\"true\" />\n      <option name=\"ALIGN_MULTILINE_ARRAY_INITIALIZER_EXPRESSION\" value=\"true\" />\n      <option name=\"CALL_PARAMETERS_WRAP\" value=\"1\" />\n      <option name=\"METHOD_PARAMETERS_WRAP\" value=\"1\" />\n      <option name=\"METHOD_CALL_CHAIN_WRAP\" value=\"1\" />\n      <option name=\"BINARY_OPERATION_WRAP\" value=\"1\" />\n      <option name=\"BINARY_OPERATION_SIGN_ON_NEXT_LINE\" value=\"true\" />\n      <option name=\"TERNARY_OPERATION_WRAP\" value=\"1\" />\n      <option name=\"TERNARY_OPERATION_SIGNS_ON_NEXT_LINE\" value=\"true\" />\n      <option name=\"FOR_STATEMENT_WRAP\" value=\"1\" />\n      <option name=\"ARRAY_INITIALIZER_WRAP\" value=\"1\" />\n      <option name=\"ASSIGNMENT_WRAP\" value=\"5\" />\n      <option name=\"WRAP_COMMENTS\" value=\"true\" />\n      <option name=\"IF_BRACE_FORCE\" value=\"3\" />\n      <option name=\"DOWHILE_BRACE_FORCE\" value=\"3\" />\n      <option name=\"WHILE_BRACE_FORCE\" value=\"3\" />\n      <option name=\"FOR_BRACE_FORCE\" value=\"3\" />\n    </codeStyleSettings>\n  </code_scheme>\n</component>
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/.idea/codeStyles/Project.xml b/.idea/codeStyles/Project.xml
--- a/.idea/codeStyles/Project.xml	(revision 994693c6616e755015ebf8f13b83d23d2f5cd593)
+++ b/.idea/codeStyles/Project.xml	(date 1742860244087)
@@ -19,6 +19,7 @@
       </option>
       <option name="IMPORT_LAYOUT_TABLE">
         <value>
+          <package name="" withSubpackages="true" static="false" module="true" />
           <package name="" withSubpackages="true" static="true" />
           <emptyLine />
           <package name="" withSubpackages="true" static="false" />
Index: doc/ConfigurationOptions.txt
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+># This is an auto-generated file, DO NOT EDIT!\n# Run ant to generate it.\n\n# This file is part of CPAchecker,\n# a tool for configurable software verification:\n# https://cpachecker.sosy-lab.org\n#\n# SPDX-FileCopyrightText: 2007-2020 Dirk Beyer <https://www.sosy-lab.org>\n#\n# SPDX-License-Identifier: Apache-2.0\n\n# Possible log levels in descending order \n# (lower levels include higher ones):\n# OFF:      no logs published\n# SEVERE:   error messages\n# WARNING:  warnings\n# INFO:     messages\n# FINE:     logs on main application level\n# FINER:    logs on central CPA algorithm level\n# FINEST:   logs published by specific CPAs\n# ALL:      debugging information\n# Care must be taken with levels of FINER or lower, as output files may\n# become quite large and memory usage might become an issue.\n\n# single levels to be excluded from being logged\nlog.consoleExclude = []\n\n# log level of console output\nlog.consoleLevel = Level.INFO\n\n# name of the log file\nlog.file = \"CPALog.txt\"\n\n# single levels to be excluded from being logged\nlog.fileExclude = []\n\n# log level of file output\nlog.level = Level.OFF\n\n# Maximum size of log output strings before they will be truncated. Note that\n# truncation is not precise and truncation to small values has no effect. Use\n# 0 for disabling truncation completely.\nlog.truncateSize = 10000\n\n# use colors for log messages on console\nlog.useColors = true\n\n# disable all default output files\n# (any explicitly given file will still be written)\noutput.disable = false\n\n# directory to put all output files in\noutput.path = \"output/\"\n\n# base directory for all paths in default values\nrootDirectory = \".\"\n\n# SPDX-FileCopyrightText: 2020 Dirk Beyer <https://www.sosy-lab.org>\n# SPDX-FileCopyrightText: 2022 Dirk Beyer <https://www.sosy-lab.org>\n# SPDX-FileCopyrightText: 2023 Dirk Beyer <https://www.sosy-lab.org>\n# SPDX-FileCopyrightText: 2024 Dirk Beyer <https://www.sosy-lab.org>\n#\n# SPDX-License-Identifier: Apache-2.0\n\n# Further options for Bitwuzla in addition to the default options. Format: \n# \"option_name=value\" with ’,’ to separate options. Option names and values\n# can be found in the Bitwuzla documentation\n# online:https://bitwuzla.github.io/docs/cpp/enums/option.html#_CPPv4N8bitwuzla6OptionEExample:\n# \"PRODUCE_MODELS=2,SAT_SOLVER=kissat\".\nsolver.bitwuzla.furtherOptions = \"\"\n\n# The SAT solver used by Bitwuzla.\nsolver.bitwuzla.satSolver = CADICAL\n  enum:     [LINGELING, CMS, CADICAL, KISSAT]\n\n# Further options for Boolector in addition to the default options. Format: \n# \"Optionname=value\" with ’,’ to seperate options. Optionname and value can\n# be found in BtorOption or Boolector C Api.Example:\n# \"BTOR_OPT_MODEL_GEN=2,BTOR_OPT_INCREMENTAL=1\".\nsolver.boolector.furtherOptions = \"\"\n\n# The SAT solver used by Boolector.\nsolver.boolector.satSolver = CADICAL\n  enum:     [LINGELING, PICOSAT, MINISAT, CMS, CADICAL]\n\n# Counts all operations and interactions towards the SMT solver.\nsolver.collectStatistics = false\n\n# apply additional validation checks for interpolation results\nsolver.cvc5.validateInterpolants = false\n\n# Enable assertions that make sure that functions are only used in the\n# context that declared them.\nsolver.debugMode.noSharedDeclarations = false\n\n# Enable assertions that make sure formula terms are only used in the context\n# that created them.\nsolver.debugMode.noSharedFormulas = false\n\n# Enable assertions that make sure that solver instances are only used on the\n# thread that created them.\nsolver.debugMode.threadLocal = false\n\n# Default rounding mode for floating point operations.\nsolver.floatingPointRoundingMode = NEAREST_TIES_TO_EVEN\n  enum:     [NEAREST_TIES_TO_EVEN, NEAREST_TIES_AWAY, TOWARD_POSITIVE, TOWARD_NEGATIVE,\n             TOWARD_ZERO]\n\n# Export solver queries in SmtLib format into a file.\nsolver.logAllQueries = false\nsolver.logfile = no default value\n\n# Further options that will be passed to Mathsat in addition to the default\n# options. Format is 'key1=value1,key2=value2'\nsolver.mathsat5.furtherOptions = \"\"\n\n# Load less stable optimizing version of mathsat5 solver.\nsolver.mathsat5.loadOptimathsat5 = false\n\n# Use non-linear arithmetic of the solver if supported and throw exception\n# otherwise, approximate non-linear arithmetic with UFs if unsupported, or\n# always approximate non-linear arithmetic. This affects only the theories of\n# integer and rational arithmetic.\nsolver.nonLinearArithmetic = USE\n  enum:     [USE, APPROXIMATE_FALLBACK, APPROXIMATE_ALWAYS]\n\n# Algorithm for boolean interpolation\nsolver.opensmt.algBool = 0\n\n# Algorithm for LRA interpolation\nsolver.opensmt.algLra = 0\n\n# Algorithm for UF interpolation\nsolver.opensmt.algUf = 0\n\n# SMT-LIB2 name of the logic to be used by the solver.\nsolver.opensmt.logic = QF_AUFLIRA\n  enum:     [CORE, QF_AX, QF_UF, QF_IDL, QF_RDL, QF_LIA, QF_LRA, QF_ALIA, QF_ALRA,\n             QF_UFLIA, QF_UFLRA, QF_AUFLIA, QF_AUFLRA, QF_AUFLIRA]\n\n# Enable additional assertion checks within Princess. The main usage is\n# debugging. This option can cause a performance overhead.\nsolver.princess.enableAssertions = false\n\n# log all queries as Princess-specific Scala code\nsolver.princess.logAllQueriesAsScala = false\n\n# file for Princess-specific dump of queries as Scala code\nsolver.princess.logAllQueriesAsScalaFile = \"princess-query-%03d-\"\n\n# The number of atoms a term has to have before it gets abbreviated if there\n# are more identical terms.\nsolver.princess.minAtomsForAbbreviation = 100\n\n# Random seed for SMT solver.\nsolver.randomSeed = 42\n\n# If logging from the same application, avoid conflicting logfile names.\nsolver.renameLogfileToAvoidConflicts = true\n\n# Double check generated results like interpolants and models whether they\n# are correct\nsolver.smtinterpol.checkResults = false\n\n# Further options that will be set to true for SMTInterpol in addition to the\n# default options. Format is 'option1,option2,option3'\nsolver.smtinterpol.furtherOptions = []\n\n# Which SMT solver to use.\nsolver.solver = SMTINTERPOL\n  enum:     [OPENSMT, MATHSAT5, SMTINTERPOL, Z3, PRINCESS, BOOLECTOR, CVC4, CVC5,\n             YICES2, BITWUZLA]\n\n# Sequentialize all solver actions to allow concurrent access!\nsolver.synchronize = false\n\n# Use provers from a seperate context to solve queries. This allows more\n# parallelity when solving larger queries.\nsolver.synchronized.useSeperateProvers = false\n\n# Apply additional checks to catch common user errors.\nsolver.useDebugMode = false\n\n# Log solver actions, this may be slow!\nsolver.useLogger = false\n\n# Activate replayable logging in Z3. The log can be given as an input to the\n# solver and replayed.\nsolver.z3.log = no default value\n\n# Ordering for objectives in the optimization context\nsolver.z3.objectivePrioritizationMode = \"box\"\n  allowed values: [lex, pareto, box]\n\n# Engine to use for the optimization\nsolver.z3.optimizationEngine = \"basic\"\n  allowed values: [basic, farkas, symba]\n\n# Require proofs from SMT solver\nsolver.z3.requireProofs = false\n\n# Whether to use PhantomReferences for discarding Z3 AST\nsolver.z3.usePhantomReferences = false\n\n# SPDX-FileCopyrightText: 2007-2020 Dirk Beyer <https://www.sosy-lab.org>\n# SPDX-FileCopyrightText: 2007-2021 Dirk Beyer <https://www.sosy-lab.org>\n# SPDX-FileCopyrightText: 2007-2022 Dirk Beyer <https://www.sosy-lab.org>\n# SPDX-FileCopyrightText: 2007-2023 Dirk Beyer <https://www.sosy-lab.org>\n# SPDX-FileCopyrightText: 2014-2017 Université Grenoble Alpes\n# SPDX-FileCopyrightText: 2020 Dirk Beyer <https://www.sosy-lab.org>\n# SPDX-FileCopyrightText: 2021 Dirk Beyer <https://www.sosy-lab.org>\n# SPDX-FileCopyrightText: 2022 Dirk Beyer <https://www.sosy-lab.org>\n# SPDX-FileCopyrightText: 2023 Dirk Beyer <https://www.sosy-lab.org>\n# SPDX-FileCopyrightText: 2024 Dirk Beyer <https://www.sosy-lab.org>\n# SPDX-FileCopyrightText: 2025 Dirk Beyer <https://www.sosy-lab.org>\n#\n# SPDX-License-Identifier: Apache-2.0\n\n# Refiner that SlicingDelegatingRefiner should delegate to\nSlicingDelegatingRefiner.refiner = no default value\n\n# maximum number of condition adjustments (-1 for infinite)\nadjustableconditions.adjustmentLimit = -1\n\n# number of threads, positive values match exactly, with -1 we use the number\n# of available cores or the machine automatically.\nalgorithm.parallelBam.numberOfThreads = -1\n\n# export number of running RSE instances as CSV\nalgorithm.parallelBam.runningRSESeriesFile = \"RSESeries.csv\"\n\n# use a BMC like algorithm that checks for satisfiability after the analysis\n# has finished, works only with PredicateCPA\nanalysis.algorithm.BMC = false\n\n# use CEGAR algorithm for lazy counter-example guided analysis\n# You need to specify a refiner with the cegar.refiner option.\n# Currently all refiner require the use of the ARGCPA.\nanalysis.algorithm.CEGAR = false\n\n# use dual approximated reachability model checking algorithm, works only\n# with PredicateCPA and large-block encoding\nanalysis.algorithm.DAR = false\n\n# use McMillan's interpolation-based model checking algorithm, works only\n# with PredicateCPA and large-block encoding\nanalysis.algorithm.IMC = false\n\n# Use MPI for running analyses in new subprocesses. The resulting reachedset\n# is the one of the first analysis returning in time. All other mpi-processes\n# will get aborted.\nanalysis.algorithm.MPI = false\n\n# use MPV algorithm for checking multiple properties\nanalysis.algorithm.MPV = false\n\n# use a analysis which proves if the program satisfies a specified property\n# with the help of an enabler CPA to separate differnt program paths\nanalysis.algorithm.analysisWithEnabler = false\n\n# use adjustable conditions algorithm\nanalysis.algorithm.conditionAdjustment = false\n\n# Use distributed summary synthesis. This decomposes the input program into\n# smaller units that are analyzed concurrently. See\n# https://doi.org/10.1145/3660766 for details.\nanalysis.algorithm.distributedSummarySynthesis = false\n\n# for found property violation, perform fault localization with coverage\nanalysis.algorithm.faultLocalization.by_coverage = false\n\n# Use fault localization with distance metrics\nanalysis.algorithm.faultLocalization.by_distance = false\n\n# for found property violation, perform fault localization with trace\n# formulas\nanalysis.algorithm.faultLocalization.by_traceformula = false\n\n# Use McMillan's Impact algorithm for lazy interpolation\nanalysis.algorithm.impact = false\n\n# Import faults stored in a JSON format.\nanalysis.algorithm.importFaults = false\n\n# use nontermination witness validator to check a violation witness for\n# termination\nanalysis.algorithm.nonterminationWitnessCheck = false\n\n# use PDR algorithm\nanalysis.algorithm.pdr = false\n\n# use a proof check algorithm to validate a previously generated proof\nanalysis.algorithm.proofCheck = false\n\n# use a proof check algorithm to validate a previously generated proofand\n# extract requirements on a (reconfigurable) HW from the proof\nanalysis.algorithm.proofCheckAndGetHWRequirements = false\n\n# use a proof check algorithm to validate a previously generated proofand\n# read the configuration for checking from the proof\nanalysis.algorithm.proofCheckReadConfig = false\n\n# use a proof check algorithm that using pcc.strategy=arg.ARG_CMCStrategy to\n# validate a previously generated proof\nanalysis.algorithm.proofCheckWithARGCMCStrategy = false\n\n# do analysis and then check if reached set fulfills property specified by\n# ConfigurableProgramAnalysisWithPropertyChecker\nanalysis.algorithm.propertyCheck = false\n\n# Use termination algorithm to prove (non-)termination. This needs the\n# TerminationCPA as root CPA and an automaton CPA with\n# termination_as_reach.spc in the tree of CPAs.\nanalysis.algorithm.termination = false\n\n# collect undefined functions\nanalysis.algorithm.undefinedFunctionCollector = false\n\n# run the parallel BAM algortihm.\nanalysis.algorithm.useParallelBAM = false\n\n# If not already done by the analysis, store a found counterexample in the\n# ARG for later re-use. Does nothing if no ARGCPA is used\nanalysis.alwaysStoreCounterexamples = false\n\n# Construct a residual program from condition and verify residual program\nanalysis.asConditionalVerifier = false\n\n# use a second model checking run (e.g., with CBMC or a different CPAchecker\n# configuration) to double-check counter-examples\nanalysis.checkCounterexamples = false\n\n# use counterexample check and the BDDCPA Restriction option\nanalysis.checkCounterexamplesWithBDDCPARestriction = false\n\n# do analysis and then check analysis result\nanalysis.checkProof = false\n\n# use assumption collecting algorithm\nanalysis.collectAssumptions = false\n\n# Construct the program slice for the given configuration.\nanalysis.constructProgramSlice = false\n\n# Solely construct the residual program for a given condition/assumption.\nanalysis.constructResidualProgram = false\n\n# continue analysis after a unsupported code was found on one path\nanalysis.continueAfterUnsupportedCode = false\n\n# Maximum number of counterexamples to be created.\nanalysis.counterexampleLimit = 0\n\n# stop CPAchecker after startup (internal option, not intended for users)\nanalysis.disable = false\n\n# entry function\nanalysis.entryFunction = \"main\"\n\n# do analysis and then extract pre- and post conditions for custom\n# instruction from analysis result\nanalysis.extractRequirements.customInstruction = false\n\n# create all potential function pointer call edges\nanalysis.functionPointerCalls = true\n\n# Create edge for skipping a function pointer call if its value is unknown.\nanalysis.functionPointerEdgesForUnknownPointer = true\n\n# potential targets for call edges created for function pointer parameter\n# calls\nanalysis.functionPointerParameterTargets = {\n          FunctionSet.USED_IN_CODE, FunctionSet.RETURN_VALUE, FunctionSet.EQ_PARAM_TYPES}\n\n# potential targets for call edges created for function pointer calls\nanalysis.functionPointerTargets = {\n          FunctionSet.USED_IN_CODE,\n          FunctionSet.RETURN_VALUE,\n          FunctionSet.EQ_PARAM_TYPES,\n          FunctionSet.EQ_PARAM_SIZES,\n          FunctionSet.EQ_PARAM_COUNT}\n\n# What CFA nodes should be the starting point of the analysis?\nanalysis.initialStatesFor = {InitialStatesFor.ENTRY}\n\n# run interprocedural analysis\nanalysis.interprocedural = true\n\n# the machine model, which determines the sizes of types like int:\n# - LINUX32: ILP32 for Linux on 32-bit x86\n# - LINUX64: LP64 for Linux on 64-bit x86\n# - ARM: ILP32 for Linux on 32-bit ARM\n# - ARM64: LP64 for Linux on 64-bit ARM\nanalysis.machineModel = LINUX32\n  enum:     [LINUX32, LINUX64, ARM, ARM64]\n\n# Use as targets for call edges only those shich are assigned to the\n# particular expression (structure field).\nanalysis.matchAssignedFunctionPointers = false\n\n# If a no target function was assigned to a function pointer, use the origin\n# heuristic instead of replacing with empty calls\nanalysis.matchAssignedFunctionPointers.ignoreUnknownAssignments = false\n\n# memorize previously used (incomplete) reached sets after a restart of the\n# analysis\nanalysis.memorizeReachedAfterRestart = false\n\n# Name of the used analysis, defaults to the name of the used configuration\nanalysis.name = no default value\n\n# Partition the initial states based on the type of location they were\n# created for (see 'initialStatesFor')\nanalysis.partitionInitialStates = false\n\n# A String, denoting the programs to be analyzed\nanalysis.programNames = []\n\n# which reached set implementation to use?\n# NORMAL: just a simple set\n# LOCATIONMAPPED: a different set per location (faster, states with different\n# locations cannot be merged)\n# PARTITIONED: partitioning depending on CPAs (e.g Location, Callstack etc.)\n# PSEUDOPARTITIONED: based on PARTITIONED, uses additional info about the\n# states' lattice (maybe faster for some special analyses which use merge_sep\n# and stop_sep\nanalysis.reachedSet = PARTITIONED\n  enum:     [NORMAL, LOCATIONMAPPED, PARTITIONED, PSEUDOPARTITIONED, USAGE]\n\n# track more statistics about the reachedset\nanalysis.reachedSet.withStatistics = false\n\n# Use if you are going to change function with function pionter parameter\nanalysis.replaceFunctionWithParameterPointer = false\n\n# Functions with function pointer parameter which will be instrumented\nanalysis.replacedFunctionsWithParameters = {\"pthread_create\"}\n\n# restart the analysis using a different configuration after unknown result\nanalysis.restartAfterUnknown = false\n\n# Use heuristics to select the analysis\nanalysis.selectAnalysisHeuristically = false\n\n# Split program in subprograms which can be analyzed separately afterwards\nanalysis.split.program = false\n\n# stop after the first error has been found\nanalysis.stopAfterError = true\n\n# create summary call statement edges\nanalysis.summaryEdges = false\n\n# Enable converting test goals to conditions.\nanalysis.testGoalConverter = no default value\n\n# Replace thread creation operations with a special function callsso, any\n# analysis can go through the function\nanalysis.threadOperationsTransform = false\n\n# Patterns for detecting block starts (ldv_ like functions)\nanalysis.traversal.blockFunctionPatterns = {\"ldv_%_instance_%\"}\n\n# resource limit for the block\nanalysis.traversal.blockResourceLimit = 1000\n\n# save resources for the block if it is empty\nanalysis.traversal.blockSaveResources = true\n\n# traverse in the order defined by the values of an automaton variable\nanalysis.traversal.byAutomatonVariable = no default value\n\n# resource limit for the entry block\nanalysis.traversal.entryResourceLimit = 100000\n\n# which strategy to adopt for visiting states?\nanalysis.traversal.order = DFS\n  enum:     [DFS, BFS, RAND, RANDOM_PATH, ROUND_ROBIN]\n\n# Exponent of random function.This value influences the probability\n# distribution over the waitlist elementswhen choosing the next element.Has\n# to be a double in the range [0, INF)\nanalysis.traversal.random.exponent = 1\n\n# Seed for random values.\nanalysis.traversal.random.seed = 0\n\n# handle abstract states with more automaton matches first? (only if\n# AutomatonCPA enabled)\nanalysis.traversal.useAutomatonInformation = false\n\n# use blocks and set resource limits for its traversal, blocks are handled in\n# DFS order\nanalysis.traversal.useBlocks = false\n\n# handle states with a deeper callstack first\n# This needs the CallstackCPA instance to have any effect.\nanalysis.traversal.useCallstack = false\n\n# handle more abstract states (with less information) first? (only for\n# ExplicitCPA)\nanalysis.traversal.useExplicitInformation = false\n\n# handle states with more loop iterations first.\nanalysis.traversal.useLoopIterationCount = false\n\n# handle states with a deeper loopstack first.\nanalysis.traversal.useLoopstack = false\n\n# handle abstract states with fewer heap objects first? (needs SMGCPA)\nanalysis.traversal.useNumberOfHeapObjects = false\n\n# handle abstract states with fewer running threads first? (needs\n# ThreadingCPA)\nanalysis.traversal.useNumberOfThreads = false\n\n# Use an implementation of postorder strategy that allows to select a\n# secondary strategy that is used if there are two states with the same\n# postorder id. The secondary strategy is selected with\n# 'analysis.traversal.order'.\nanalysis.traversal.usePostorder = false\n\n# handle states with fewer loop iterations first.\nanalysis.traversal.useReverseLoopIterationCount = false\n\n# handle states with a more shallow loopstack first.\nanalysis.traversal.useReverseLoopstack = false\n\n# Use an implementation of reverse postorder strategy that allows to select a\n# secondary strategy that is used if there are two states with the same\n# reverse postorder id. The secondary strategy is selected with\n# 'analysis.traversal.order'.\nanalysis.traversal.useReversePostorder = false\n\n# perform a weighted random selection based on the branching depth\nanalysis.traversal.weightedBranches = false\n\n# perform a weighted random selection based on the depth in the ARG\nanalysis.traversal.weightedDepth = false\n\n# After an incomplete analysis constructs a residual program which contains\n# all program paths which are not fully explored\nanalysis.unexploredPathsAsProgram = false\n\n# Do not report unknown if analysis terminated, report true (UNSOUND!).\nanalysis.unknownAsTrue = false\n\n# stop the analysis with the result unknown if the program does not satisfies\n# certain restrictions.\nanalysis.unknownIfUnrestrictedProgram = false\n\n# Use array abstraction by program transformation.\nanalysis.useArrayAbstraction = false\n\n# select an analysis from a set of analyses after unknown result\nanalysis.useCompositionAnalysis = false\n\n# add declarations for global variables before entry function\nanalysis.useGlobalVars = true\n\n# add loop-structure information to CFA.\nanalysis.useLoopStructure = true\n\n# Use analyses parallely. The resulting reachedset is the one of the first\n# analysis finishing in time. All other analyses are terminated.\nanalysis.useParallelAnalyses = false\n\n# generate random test cases\nanalysis.useRandomTestCaseGeneratorAlgorithm = false\n\n# generate test cases for covered test targets\nanalysis.useTestCaseGeneratorAlgorithm = false\n\n# converts a witness to an ACSL annotated program\nanalysis.useWitnessToACSLAlgorithm = false\n\n# Whether to allow imprecise array abstraction that may lead to false alarms.\narrayAbstraction.allowImprecision = false\n\n# Whether to export the CFA with abstracted arrays as C source file.\narrayAbstraction.cfa.c.export = true\n\n# C source file path for CFA with abstracted arrays.\narrayAbstraction.cfa.c.file = \"abstracted-arrays.c\"\n\n# Whether to export the CFA with abstracted arrays as DOT file.\narrayAbstraction.cfa.dot.export = true\n\n# DOT file path for CFA with abstracted arrays.\narrayAbstraction.cfa.dot.file = \"cfa-abstracted-arrays.dot\"\n\n# Use a second delegate analysis run to check counterexamples on the original\n# program that contains (non-abstracted) arrays for imprecise array\n# abstractions.\narrayAbstraction.checkCounterexamples = false\n\n# Configuration file path of the delegate analysis running on the transformed\n# program.\narrayAbstraction.delegateAnalysis = no default value\n\n# Add a threshold to the automaton, after so many branches on a path the\n# automaton will be ignored (0 to disable)\nassumptions.automatonBranchingThreshold = 0\n\n# write collected assumptions as automaton to file\nassumptions.automatonFile = \"AssumptionAutomaton.txt\"\n\n# If it is enabled, automaton does not add assumption which is considered to\n# continue path with corresponding this edge.\nassumptions.automatonIgnoreAssumptions = false\n\n# If it is enabled, automaton adds transitions to later ARG states first\nassumptions.automatonOrderedTransitions = false\n\n# compress the produced assumption automaton using GZIP compression.\nassumptions.compressAutomaton = false\n\n# export assumptions as automaton to dot file\nassumptions.dotExport = false\n\n# write collected assumptions as automaton to dot file\nassumptions.dotFile = \"AssumptionAutomaton.dot\"\n\n# write collected assumptions to file\nassumptions.export = true\n\n# export assumptions collected per location\nassumptions.export.location = true\n\n# write collected assumptions to file\nassumptions.file = \"assumptions.txt\"\n\n# If it is enabled, check if a state that should lead to false state indeed\n# has successors.\nassumptions.removeNonExploredWithoutSuccessors = false\n\n# comma-separated list of files with specifications that should be used \n# in a backwards analysis; used if the analysis starts at the target states!\n# (see config/specification/ for examples)\nbackwardSpecification = []\n\n# Count accesses for the BDD library. Counting works for concurrent accesses.\nbdd.countLibraryAccess = false\n\n# Size of the BDD cache in relation to the node table size (set to 0 to use\n# fixed BDD cache size).\nbdd.javabdd.cacheRatio = 0.1\n\n# Initial size of the BDD cache, use 0 for cacheRatio*initTableSize.\nbdd.javabdd.cacheSize = 0\n\n# Initial size of the BDD node table in percentage of available Java heap\n# memory (only used if initTableSize is 0).\nbdd.javabdd.initTableRatio = 0.001\n\n# Initial size of the BDD node table, use 0 for size based on initTableRatio.\nbdd.javabdd.initTableSize = 0\n\n# Measure the time spent in the BDD library. The behaviour in case of\n# concurrent accesses is undefined!\nbdd.measureLibraryAccess = false\n\n# Which BDD package should be used?\n# - java:   JavaBDD (default, no dependencies, many features)\n# - sylvan: Sylvan (only 64bit Linux, uses multiple threads)\n# - cudd:   CUDD (native library required, reordering not supported)\n# - micro:  MicroFactory (maximum number of BDD variables is 1024, slow, but\n# less memory-comsumption)\n# - buddy:  Buddy (native library required)\n# - cal:    CAL (native library required)\n# - jdd:    JDD\n# - pjbdd:  A java native parallel bdd framework\nbdd.package = \"JAVA\"\n  allowed values: [JAVA, SYLVAN, CUDD, MICRO, BUDDY, CAL, JDD, PJBDD]\n\n# Size of the BDD cache in relation to the node table size (set to 0 to use\n# fixed BDD cache size).\nbdd.pjbdd.cacheRatio = 0.1\n\n# size of the BDD cache.\nbdd.pjbdd.cacheSize = 0\n\n# Disable thread safe bdd operations.\nbdd.pjbdd.disableThreadSafety = false\n\n# increase factor for resizing tables\nbdd.pjbdd.increaseFactor = 1\n\n# Initial size of the BDD node table in percentage of available Java heap\n# memory (only used if initTableSize is 0).\nbdd.pjbdd.initTableRatio = 0.001\n\n# Initial size of the BDD node table, use 0 for size based on initTableRatio.\nbdd.pjbdd.initTableSize = 0\n\n# unique table's concurrency factor\nbdd.pjbdd.tableParallelism = 10000\n\n# Number of worker threads, Runtime.getRuntime().availableProcessors()\n# default\nbdd.pjbdd.threads = Runtime.getRuntime().availableProcessors()\n\n# Type of BDD used in PJBDD.\nbdd.pjbdd.useBDDType = \"BDD\"\n  allowed values: [BDD, ChainedBDD]\n\n# Use internal a int based bdd representation.\nbdd.pjbdd.useInts = false\n\n# initial variable count\nbdd.pjbdd.varCount = 100\n\n# Granularity of the Sylvan BDD operations cache (recommended values 4-8).\nbdd.sylvan.cacheGranularity = 4\n\n# Log2 size of the BDD cache.\nbdd.sylvan.cacheSize = 24\n\n# Log2 size of the BDD node table.\nbdd.sylvan.tableSize = 26\n\n# Number of worker threads, 0 for automatic.\nbdd.sylvan.threads = 0\n\n# sequentialize all accesses to the BDD library.\nbdd.synchronizeLibraryAccess = false\n\n# output file for visualizing the block graph\nblockCFAFile = \"block_analysis/blocks.json\"\n\n# Allow reduction of function entries; calculate abstractions always at\n# function entries?\nblockreducer.allowReduceFunctionEntries = true\n\n# Allow reduction of function exits; calculate abstractions always at\n# function exits?\nblockreducer.allowReduceFunctionExits = true\n\n# Allow reduction of loop heads; calculate abstractions always at loop heads?\nblockreducer.allowReduceLoopHeads = false\n\n# write the reduced cfa to the specified file.\nblockreducer.reducedCfaFile = \"ReducedCfa.rsf\"\n\n# Do at most n summarizations on a node.\nblockreducer.reductionThreshold = 100\n\n# If BMC did not find a bug, check whether the bounding did actually remove\n# parts of the state space (this is similar to CBMC's unwinding assertions).\nbmc.boundingAssertions = true\n\n# If BMC did not find a bug, check which parts of the boundary actually\n# reachableand prevent them from being unrolled any further.\nbmc.boundingAssertionsSlicing = false\n\n# Check reachability of target states after analysis (classical BMC). The\n# alternative is to check the reachability as soon as the target states are\n# discovered, which is done if cpa.predicate.targetStateSatCheck=true.\nbmc.checkTargetStates = true\n\n# try using induction to verify programs with loops\nbmc.induction = false\n\n# Strategy for generating auxiliary invariants\nbmc.invariantGenerationStrategy = REACHED_SET\n  enum:     [INDUCTION, REACHED_SET, DO_NOTHING]\n\n# k-induction configuration to be used as an invariant generator for\n# k-induction (ki-ki(-ai)).\nbmc.invariantGeneratorConfig = no default value\n\n# Controls how long the invariant generator is allowed to run before the\n# k-induction procedure starts.\nbmc.invariantGeneratorHeadStartStrategy = NONE\n  enum:     [NONE, AWAIT_TERMINATION, WAIT_UNTIL_EXPENSIVE_ADJUSTMENT]\n\n# Export auxiliary invariants used for induction.\nbmc.invariantsExport = no default value\n\n# get candidate invariants from a predicate precision file\nbmc.kinduction.predicatePrecisionFile = no default value\n\n# which strategy to use to convert predicate precision to k-induction\n# invariant\nbmc.kinduction.reuse.pred.strategy = GLOBAL\n  enum:     [ALL, GLOBAL, FUNCTION, LOCAL, GLOBAL_AND_FUNCTION, GLOBAL_AND_LOCAL,\n             FUNCTION_AND_LOCAL]\n\n# Propagates the interrupts of the invariant generator.\nbmc.propagateInvGenInterrupts = false\n\n# Try to simplify the structure of formulas for the sat check of BMC. The\n# improvement depends on the underlying SMT solver.\nbmc.simplifyBooleanFormula = false\n\n# Use generalized counterexamples to induction as candidate invariants.\nbmc.usePropertyDirection = false\n\n# File name where to put the path program that is generated as input for\n# CBMC. A temporary file is used if this is unspecified. If specified, the\n# file name should end with '.i' because otherwise CBMC runs the\n# pre-processor on the file.\ncbmc.dumpCBMCfile = no default value\n\n# maximum time limit for CBMC (use milliseconds or specify a unit; 0 for\n# infinite)\ncbmc.timelimit = 0ms\n\n# continue analysis after a failed refinement (e.g. due to interpolation)\n# other paths may still contain errors that could be found\ncegar.continueAfterFailedRefinement = false\n\n# if this score is exceeded by the first analysis, the auxilliary analysis\n# will be refined\ncegar.domainScoreThreshold = 1024\n\n# Whether to do refinement immediately after finding an error state, or\n# globally after the ARG has been unrolled completely.\n# whether or not global refinement is performed\ncegar.globalRefinement = false\n\n# Max number of refinement iterations, -1 for no limit\ncegar.maxIterations = -1\n\n# Which refinement algorithm to use? (give class name, required for CEGAR) If\n# the package name starts with 'org.sosy_lab.cpachecker.', this prefix can be\n# omitted.\ncegar.refiner = no default value\n\n# whether or not to use refinement selection to decide which domain to refine\ncegar.useRefinementSelection = false\n\n# Which functions should be interpreted as encoding assumptions\ncfa.assumeFunctions = {\"__VERIFIER_assume\"}\n\n# dump a simple call graph\ncfa.callgraph.export = true\n\n# file name for call graph as .dot file\ncfa.callgraph.file = \"functionCalls.dot\"\ncfa.callgraph.fileUsed = \"functionCallsUsed.dot\"\n\n# how often do we clone a function?\ncfa.cfaCloner.numberOfCopies = 5\n\n# while this option is activated, before each use of a PointerExpression, or\n# a dereferenced field access the expression is checked if it is 0\ncfa.checkNullPointers = false\n\n# Whether to have a single target node per function for all invalid null\n# pointer dereferences or to have separate nodes for each dereference\ncfa.checkNullPointers.singleTargetPerFunction = true\n\n# When a function pointer array element is written with a variable as index,\n# create a series of if-else edges with explicit indizes instead.\ncfa.expandFunctionPointerArrayAssignments = false\n\n# export CFA as .dot file\ncfa.export = true\n\n# export individual CFAs for function as .dot files\ncfa.exportPerFunction = true\n\n# export CFA as C file\ncfa.exportToC = false\ncfa.exportToC.file = \"cfa.c\"\n\n# produce C programs more similar to the input program\n# (only possible for a single input file)\ncfa.exportToC.stayCloserToInput = false\n\n# export CFA as .dot file\ncfa.file = \"cfa.dot\"\n\n# By enabling this option the variables that are live are computed for each\n# edge of the cfa. Live means that their value is read later on.\ncfa.findLiveVariables = false\n\n# how often can a function appear in the callstack as a clone of the original\n# function?\ncfa.functionCalls.recursionDepth = 5\n\n# Also initialize local variables with default values, or leave them\n# uninitialized.\ncfa.initializeAllVariables = false\n\n# With this option, all declarations in each function will be movedto the\n# beginning of each function. Do only use this option if you arenot able to\n# handle initializer lists and designated initializers (like they can be used\n# for arrays and structs) in your analysis anyway. this option will otherwise\n# create c code which is not the same as the original one\ncfa.moveDeclarationsToFunctionStart = false\n\n# Which functions should be interpreted as never returning to their call site\ncfa.nonReturningFunctions = {\"abort\", \"exit\"}\n\n# Export CFA as pixel graphic to the given file name. The suffix is added\n# corresponding to the value of option pixelgraphic.export.formatIf set to\n# 'null', no pixel graphic is exported.\ncfa.pixelGraphicFile = no default value\n\n# Show messages when dead code is encountered during parsing.\ncfa.showDeadCode = true\n\n# Remove all edges which don't have any effect on the program\ncfa.simplifyCfa = true\n\n# simplify simple const expressions like 1+2\ncfa.simplifyConstExpressions = true\n\n# simplify pointer expressions like s->f to (*s).f with this option the cfa\n# is simplified until at maximum one pointer is allowed for left- and\n# rightHandSide\ncfa.simplifyPointerExpressions = false\n\n# A name of thread_create function\ncfa.threads.threadCreate = \"pthread_create\"\n\n# A name of thread_join function\ncfa.threads.threadJoin = \"pthread_join\"\n\n# A name of thread_create_N function\ncfa.threads.threadSelfCreate = \"pthread_create_N\"\n\n# A name of thread_join_N function\ncfa.threads.threadSelfJoin = \"pthread_join_N\"\n\n# clone functions of the CFA, such that there are several identical CFAs for\n# each function, only with different names.\ncfa.useCFACloningForMultiThreadedPrograms = false\n\n# unwind recursive functioncalls (bounded to max call stack size)\ncfa.useFunctionCallUnwinding = false\n\n# Dump domain type statistics to a CSV file.\ncfa.variableClassification.domainTypeStatisticsFile = no default value\n\n# Dump variable classification to a file.\ncfa.variableClassification.logfile = \"VariableClassification.log\"\n\n# Print some information about the variable classification.\ncfa.variableClassification.printStatsOnStartup = false\n\n# Dump variable type mapping to a file.\ncfa.variableClassification.typeMapFile = \"VariableTypeMapping.txt\"\n\n# Output an input file, with invariants embedded as assume constraints.\ncinvariants.export = false\n\n# File name for exporting invariants. Only supported if invariant export for\n# specified lines is enabled.\ncinvariants.external.file = no default value\n\n# Specify lines for which an invariant should be written. Lines are specified\n# as comma separated list of individual lines x and line ranges x-y.\ncinvariants.forLines = \"\"\n\n# If enabled only export invariants for specified lines.\ncinvariants.onlyForSpecifiedLines = false\n\n# Prefix to add to an output file, which would contain assumed invariants.\ncinvariants.prefix = no default value\n\n# Attempt to simplify the invariant before exporting [may be very expensive].\ncinvariants.simplify = false\n\n# If adaptTimeLimits is set and all configurations support progress reports,\n# in each cycle the time limits per configuration are newly calculated based\n# on the progress\ncompositionAlgorithm.circular.adaptTimeLimits = false\n\n# where to store initial condition, when generated\ncompositionAlgorithm.condition.file = \"AssumptionAutomaton.txt\"\n\n# list of files with configurations to use, which are optionally suffixed\n# according to one of the followig schemes:either ::MODE or ::MODE_LIMIT,\n# where MODE and LIMIT are place holders.MODE may take one of the following\n# values continue (i.e., continue analysis with same CPA and reached set),\n# reuse-precision (i.e., reuse the aggregation of the precisions from the\n# previous analysis run), noreuse (i.e., start from scratch).LIMIT is a\n# positive integer number specifying the time limit of the analysis in each\n# round.If no (correct) limit is given a default limit is used.\ncompositionAlgorithm.configFiles = no default value\n\n# Whether or not to create an initial condition, that excludes no paths,\n# before first analysis is run.Required when first analysis uses condition\n# from conditional model checking\ncompositionAlgorithm.initCondition = false\n\n# print the statistics of each component of the composition algorithm\n# directly after the component's computation is finished\ncompositionAlgorithm.intermediateStatistics = NONE\n  enum:     [EXECUTE, NONE, PRINT]\n\n# Enable when composition algorithm is used to check a specification\ncompositionAlgorithm.propertyChecked = true\n\n# Qualified name for class which implements strategy that decides how to\n# compose given analyses\ncompositionAlgorithm.strategy = no default value\n\n# let each analysis part of the composition algorithm write output files and\n# not only the last one that is executed\ncompositionAlgorithm.writeIntermediateOutputFiles = true\n\n# configuration of the residual program generator\nconditional.verifier.generatorConfig = no default value\n\n# configuration for the verification of the residual program which is\n# constructed from another verifier's condition\nconditional.verifier.verifierConfig = no default value\n\n# The input file with all goals that were previously reached\nconditional_testing.inputfile = no default value\n\n# The strategy to use\nconditional_testing.strategy = no default value\n  enum:     [NAIVE, PROPAGATION]\n\n# Dump the complete configuration to a file.\nconfiguration.dumpFile = \"UsedConfiguration.properties\"\n\n# True if the path to the error state can not always be uniquely determined\n# from the ARG.\n# This is the case e.g. for Slicing Abstractions, where the abstraction\n# states in the ARG\n# do not form a tree!\ncounterexample.ambigiousARG = false\n\n# Which model checker to use for verifying counterexamples as a second check.\n# Currently CBMC or CPAchecker with a different config or the concrete\n# execution \n# checker can be used.\ncounterexample.checker = CBMC\n  enum:     [CBMC, CPACHECKER, CONCRETE_EXECUTION]\n\n# counterexample information should provide more precise information from\n# counterexample check, if available\ncounterexample.checker.changeCEXInfo = false\n\n# counterexample check checks MemSafety sub-properties (valid-deref,\n# valid-free, valid-memtrack) additionally to the path.\ncounterexample.checker.checkMemorySafetySubproperty = false\n\n# configuration file for counterexample checks with CPAchecker\ncounterexample.checker.config = no default value\n\n# counterexample check should fully replace existing counterexamples with own\n# ones, if available\ncounterexample.checker.forceCEXChange = false\n\n# File name where to put the path specification that is generated as input\n# for the counterexample check. A temporary file is used if this is\n# unspecified.\ncounterexample.checker.path.file = no default value\n\n# The file in which the generated C code is saved.\ncounterexample.concrete.dumpFile = no default value\n\n# Path to the compiler. Can be absolute or only the name of the program if it\n# is in the PATH\ncounterexample.concrete.pathToCompiler = \"/usr/bin/gcc\"\n\n# Maximum time limit for the concrete execution checker.\n# This limit is used for compilation as well as execution so overall, twice\n# the time of this limit may be consumed.\n# (use milliseconds or specify a unit; 0 for infinite)\ncounterexample.concrete.timelimit = 0ms\n\n# continue analysis after an counterexample was found that was denied by the\n# second check\ncounterexample.continueAfterInfeasibleError = true\n\n# An imprecise counterexample of the Predicate CPA is usually a bug, but\n# expected in some configurations. Should it be treated as a bug or accepted?\ncounterexample.export.allowImpreciseCounterexamples = false\n\n# Always use imprecise counterexamples of the predicate analysis. If this\n# option is set to true, counterexamples generated by the predicate analysis\n# will be exported as-is. This means that no information like variable\n# assignments will be added and imprecise or potentially wrong program paths\n# will be exported as counterexample.\ncounterexample.export.alwaysUseImpreciseCounterexamples = false\n\n# If the option assumeLinearArithmetics is set, this option can be used to\n# allow division and modulo by constants.\ncounterexample.export.assumptions.allowDivisionAndModuloByConstants = false\n\n# If the option assumeLinearArithmetics is set, this option can be used to\n# allow multiplication between operands with at least one constant.\ncounterexample.export.assumptions.allowMultiplicationWithConstants = false\n\n# Try to avoid using operations that exceed the capabilities of linear\n# arithmetics when extracting assumptions from the model. This option aims to\n# prevent witnesses that are inconsistent with  models that are, due to an\n# analysis limited to linear arithmetics, actually incorrect.\n#  This option does not magically produce a correct witness from an incorrect\n# model, and since the difference between an incorrect witness consistent\n# with the model and an incorrect witness that is inconsistent with the model\n# is academic, you usually want this option to be off.\ncounterexample.export.assumptions.assumeLinearArithmetics = false\n\n# export counterexample as automaton\ncounterexample.export.automaton = \"Counterexample.%d.spc\"\n\n# exports either CMBC format or a concrete path program\ncounterexample.export.codeStyle = CBMC\n  enum:     [CBMC, CONCRETE_EXECUTION]\n\n# compress the produced error-witness automata using GZIP compression.\ncounterexample.export.compressWitness = true\n\n# export counterexample core as text file\ncounterexample.export.core = \"Counterexample.%d.core.txt\"\n\n# export counterexample to file, if one is found\ncounterexample.export.enabled = true\n\n# export error paths to files immediately after they were found, including\n# spurious error-paths before executing a refinement. Note that we do not\n# track already exported error-paths and export them at every refinement as\n# long as they are not removed from the reached-set. Most helpful for\n# debugging refinements.\ncounterexample.export.exportAllFoundErrorPaths = false\n\n# export counterexample as source file\ncounterexample.export.exportAsSource = true\n\n# export coverage information for every witness: requires using an Assumption\n# Automaton as part of the specification. Lines are considered to be covered\n# only when the path reaching the statement does not reach the __FALSE state\n# in the Assumption Automaton.\ncounterexample.export.exportCounterexampleCoverage = false\n\n# Export extended witness in addition to regular witness\ncounterexample.export.exportExtendedWitness = false\n\n# exports a JSON file describing found faults, if fault localization is\n# activated\ncounterexample.export.exportFaults = true\n\n# export test harness\ncounterexample.export.exportHarness = true\n\n# export error paths to files immediately after they were found\ncounterexample.export.exportImmediately = false\n\n# export test case that represents the counterexample. Further options can be\n# set with options 'testcase.*'\ncounterexample.export.exportTestCase = false\n\n# export counterexample as witness/graphml file\ncounterexample.export.exportWitness = true\n\n# Extended witness with specific analysis information file\ncounterexample.export.extendedWitnessFile = \"extendedWitness.%d.graphml\"\n\n# export counterexample as text file\ncounterexample.export.file = \"Counterexample.%d.txt\"\n\n# Filter for irrelevant counterexamples to reduce the number of similar\n# counterexamples reported. Only relevant with analysis.stopAfterError=false\n# and counterexample.export.exportImmediately=true. Put the weakest and\n# cheapest filter first, e.g., PathEqualityCounterexampleFilter.\ncounterexample.export.filters = no default value\n\n# where to dump the counterexample formula in case a specification violation\n# is found\ncounterexample.export.formula = \"Counterexample.%d.smt2\"\n\n# export counterexample as Dot/Graphviz visualization\ncounterexample.export.graph = \"Counterexample.%d.dot\"\n\n# export counterexample witness as GraphML automaton\ncounterexample.export.graphml = \"Counterexample.%d.graphml\"\n\n# export test harness to file as code\ncounterexample.export.harness = \"Counterexample.%d.harness.c\"\n\n# where to dump the counterexample model in case a specification violation is\n# found\ncounterexample.export.model = \"Counterexample.%d.assignment.txt\"\n\n# export counterexample coverage information, considering only spec prefix as\n# covered (up until reaching __FALSE state in Assumption Automaton).\ncounterexample.export.prefixCoverageFile = \"Counterexample.%d.aa-prefix.coverage-info\"\n\n# The files where the BDDCPARestrictionAlgorithm should write the presence\n# conditions for the counterexamples to.\ncounterexample.export.presenceCondition = \"Counterexample.%d.presenceCondition.txt\"\n\n# File name for analysis report in case a counterexample was found.\ncounterexample.export.report = \"Counterexample.%d.html\"\n\n# export counterexample as source file\ncounterexample.export.source = \"Counterexample.%d.c\"\n\n# export counterexample witness as Dot/Graphviz visualization\ncounterexample.export.witnessGraph = \"Counterexample.%d.witness.dot\"\n\n# The template from which the different versions of the violation witnesses\n# will be exported. Each version replaces the string '%s' with its version\n# number. The string %d is replace with the number of the counterexample.\ncounterexample.export.yaml = \"Counterexample.%d.witness-%s.yml\"\n\n# deprecated name for counterexample.export.presenceCondition\ncounterexample.presenceConditionFile = \"Counterexample.%d.presenceCondition.txt\"\n\n# If continueAfterInfeasibleError is true, remove the error state that is\n# proven to be unreachable before continuing. Set this to false if\n# analyis.collectAssumptions=true is also set.\ncounterexample.removeInfeasibleErrorState = true\n\n# If continueAfterInfeasibleError is true, attempt to remove the whole path\n# of the infeasible counterexample before continuing. Setting this to false\n# may prevent a lot of similar infeasible counterexamples to get discovered,\n# but is unsound\ncounterexample.removeInfeasibleErrors = false\n\n# If true, the counterexample checker will not assume a counterexample as\n# infeasible because of unsupported code. But will try different paths\n# anyway.\ncounterexample.skipCounterexampleForUnsupportedCode = false\n\n# Compute and export information about the verification coverage?\ncoverage.enabled = true\n\n# print coverage info to file\ncoverage.file = \"coverage.info\"\n\n# CPA to use (see doc/Configuration.md for more documentation on this)\ncpa = CompositeCPA.class.getCanonicalName()\n\n# Where to perform abstraction\ncpa.abe.abstractionLocations = LOOPHEAD\n  enum:     [ALL, LOOPHEAD, MERGE]\n\n# Check target states reachability\ncpa.abe.checkTargetStates = true\n\n# Cache formulas produced by path formula manager\ncpa.abe.useCachingPathFormulaManager = true\n\n# only store pure C expressions without ACSL-specific constructs\ncpa.acsl.usePureExpressionsOnly = true\n\n# Use this to change the underlying abstract domain in the APRON library\ncpa.apron.domain = OCTAGON\n  enum:     [BOX, OCTAGON, POLKA, POLKA_STRICT, POLKA_EQ]\n\n# get an initial precision from file\ncpa.apron.initialPrecisionFile = no default value\n\n# this option determines which initial precision should be used\ncpa.apron.initialPrecisionType = \"STATIC_FULL\"\n  allowed values: [STATIC_FULL, REFINEABLE_EMPTY]\n\n# with this option enabled the states are only merged at loop heads\ncpa.apron.mergeop.onlyMergeAtLoopHeads = false\n\n# of which type should the merge be?\ncpa.apron.mergeop.type = \"SEP\"\n  allowed values: [SEP, JOIN, WIDENING]\n\n# target file to hold the exported precision\ncpa.apron.precisionFile = no default value\n\n# Timelimit for the backup feasibility check with the apron analysis.(use\n# seconds or specify a unit; 0 for infinite)\ncpa.apron.refiner.timeForApronFeasibilityCheck = 0ns\n\n# split disequalities considering integer operands into two states or use\n# disequality provided by apron library \ncpa.apron.splitDisequalities = true\n\n# translate final ARG into this C file\ncpa.arg.CTranslation.file = \"ARG.c\"\n\n# minimum ratio of branch compared to whole program to be exported\ncpa.arg.automaton.branchRatio = 0.5\n\n# what data should be exported from the ARG nodes? A different strategy might\n# result in a smaller automaton.\ncpa.arg.automaton.dataStrategy = LOCATION\n  enum:     [LOCATION, CALLSTACK]\n\n# translate final ARG into an automaton\ncpa.arg.automaton.export = false\n\n# export as zip-files, depends on 'automaton.export=true'\ncpa.arg.automaton.exportCompressed = true\n\n# translate final ARG into an automaton, depends on 'automaton.export=true'\ncpa.arg.automaton.exportDotFile = \"ARG_parts/ARG.%06d.spc.dot\"\ncpa.arg.automaton.exportSpcFile = \"ARG_parts/ARG.%06d.spc\"\ncpa.arg.automaton.exportSpcZipFile = \"ARG_parts.zip\"\n\n# export all automata into one zip-file, depends on 'automaton.export=true'\ncpa.arg.automaton.exportZipped = true\n\n# after determining branches, which one of them should be exported?\ncpa.arg.automaton.selectionStrategy = LEAVES\n  enum:     [NONE, ALL, LEAVES, WEIGHTED, FIRST_BFS]\n\n# minimum ratio of siblings such that one of them will be exported\ncpa.arg.automaton.siblingRatio = 0.4\n\n# when using FIRST_BFS, how many nodes should be skipped? ZERO will only\n# export the root itself, MAX_INT will export only LEAFS.\ncpa.arg.automaton.skipFirstNum = 10\n\n# which coarse strategy should be applied when analyzing the ARG?\ncpa.arg.automaton.splitStrategy = TARGETS\n  enum:     [NONE, GLOBAL_CONDITIONS, LEAVES, TARGETS]\n\n# compress the produced correctness-witness automata using GZIP compression.\ncpa.arg.compressWitness = true\n\n# prevent the stop-operator from aborting the stop-check early when it\n# crosses a target state\ncpa.arg.coverTargetStates = false\n\n# inform merge operator in CPA enabled analysis that it should delete the\n# subgraph of the merged node which is required to get at most one successor\n# per CFA edge.\ncpa.arg.deleteInCPAEnabledAnalysis = false\n\n# Dump all ARG related statistics files after each iteration of the CPA\n# algorithm? (for debugging and demonstration)\ncpa.arg.dumpAfterIteration = false\n\n# Enable reduction for nested abstract states when entering or leaving a\n# block abstraction for BAM. The reduction can lead to a higher\n# cache-hit-rate for BAM and a faster sub-analysis for blocks.\ncpa.arg.enableStateReduction = true\n\n# deprecated name for counterexample.export.automaton\ncpa.arg.errorPath.automaton = \"Counterexample.%d.spc\"\n\n# deprecated name for counterexample.export.codeStyle\ncpa.arg.errorPath.codeStyle = CBMC\n  enum:     [CBMC, CONCRETE_EXECUTION]\n\n# deprecated name for counterexample.export.compressWitness\ncpa.arg.errorPath.compressWitness = true\n\n# deprecated name for counterexample.export.core\ncpa.arg.errorPath.core = \"Counterexample.%d.core.txt\"\n\n# deprecated name for counterexample.export.enabled\ncpa.arg.errorPath.export = true\n\n# deprecated name for counterexample.export.exportAllFoundErrorPaths\ncpa.arg.errorPath.exportAllFoundErrorPaths = false\n\n# deprecated name for counterexample.export.exportAsSource\ncpa.arg.errorPath.exportAsSource = true\n\n# deprecated name for counterexample.export.exportCounterexampleCoverage\ncpa.arg.errorPath.exportCounterexampleCoverage = false\n\n# deprecated name for counterexample.export.exportExtendedWitness\ncpa.arg.errorPath.exportExtendedWitness = false\n\n# deprecated name for counterexample.export.exportFaults\ncpa.arg.errorPath.exportFaults = true\n\n# deprecated name for counterexample.export.exportHarness\ncpa.arg.errorPath.exportHarness = true\n\n# deprecated name for counterexample.export.exportImmediately\ncpa.arg.errorPath.exportImmediately = false\n\n# deprecated name for counterexample.export.exportTestCase\ncpa.arg.errorPath.exportTestCase = false\n\n# deprecated name for counterexample.export.exportWitness\ncpa.arg.errorPath.exportWitness = true\n\n# deprecated name for counterexample.export.extendedWitnessFile\ncpa.arg.errorPath.extendedWitnessFile = \"extendedWitness.%d.graphml\"\n\n# deprecated name for counterexample.export.file\ncpa.arg.errorPath.file = \"Counterexample.%d.txt\"\n\n# deprecated name for counterexample.export.filters\ncpa.arg.errorPath.filters = no default value\n\n# deprecated name for counterexample.export.graph\ncpa.arg.errorPath.graph = \"Counterexample.%d.dot\"\n\n# deprecated name for counterexample.export.graphml\ncpa.arg.errorPath.graphml = \"Counterexample.%d.graphml\"\n\n# deprecated name for counterexample.export.harness\ncpa.arg.errorPath.harness = \"Counterexample.%d.harness.c\"\n\n# deprecated name for counterexample.export.prefixCoverageFile\ncpa.arg.errorPath.prefixCoverageFile = \"Counterexample.%d.aa-prefix.coverage-info\"\n\n# deprecated name for counterexample.export.source\ncpa.arg.errorPath.source = \"Counterexample.%d.c\"\n\n# deprecated name for counterexample.export.witnessGraph\ncpa.arg.errorPath.witnessGraph = \"Counterexample.%d.witness.dot\"\n\n# deprecated name for counterexample.export.yaml\ncpa.arg.errorPath.yaml = \"Counterexample.%d.witness-%s.yml\"\n\n# export final ARG as .dot file\ncpa.arg.export = true\n\n# Enable the integration of __VERIFIER_assume statements for non-true\n# assumption in states. Disable if you want to create residual programs.\ncpa.arg.export.code.addAssumptions = true\n\n# Only enable CLOSEFUNCTIONBLOCK if you are sure that the ARG merges\n# different flows through a function at the end of the function.\ncpa.arg.export.code.blockAtFunctionEnd = KEEPBLOCK\n  enum:     [CLOSEFUNCTIONBLOCK, ADDNEWBLOCK, KEEPBLOCK]\n\n# How to deal with target states during code generation\ncpa.arg.export.code.handleTargetStates = NONE\n  enum:     [NONE, RUNTIMEVERIFICATION, ASSERTFALSE, FRAMACPRAGMA, VERIFIERERROR,\n             REACHASMEMSAFETY, REACHASOVERFLOW, REACHASTERMINATION]\n\n# write include directives\ncpa.arg.export.code.header = true\n\n# If specified, metadata about the produced C program will be exported to\n# this file\ncpa.arg.export.code.metadataOutput = no default value\n\n# when enabled also write invariant true to correctness-witness automata\ncpa.arg.exportTrueInvariants = false\n\n# export correctness witness in YAML format\ncpa.arg.exportYamlCorrectnessWitness = true\n\n# export witnesses for unknown verdicts\ncpa.arg.exportYamlWitnessesForUnknownVerdict = true\n\n# export final ARG as .dot file\ncpa.arg.file = \"ARG.dot\"\n\n# inform ARG CPA if it is run in an analysis with enabler CPA because then it\n# must behave differently during merge.\ncpa.arg.inCPAEnabledAnalysis = false\n\n# whether to keep covered states in the reached set as addition to keeping\n# them in the ARG\ncpa.arg.keepCoveredStatesInReached = false\n\n# What do to on a late merge, i.e., if the second parameter of the merge\n# already has child states (cf. issue #991):\n# - ALLOW: Just merge as usual.\n# - ALLOW_WARN: Log a warning the first time this happens, then ALLOW.\n# - PREVENT: Do not merge, i.e., enforce merge-sep for such situations.\n# - PREVENT_WARN: Log a warning the first time this happens, then PREVENT.\n# - CRASH: Crash CPAchecker as soon as this happens\n#   (useful for cases where a late merge should never happen).\ncpa.arg.lateMerge = ALLOW\n  enum:     [ALLOW, ALLOW_WARN, PREVENT, PREVENT_WARN, CRASH]\n\n# write the ARG at various stages during execution into dot files whose name\n# is specified by this option. Only works if 'cpa.arg.logARGs=true'\ncpa.arg.log.fileTemplate = \"ARG_log/ARG_%04d.dot\"\n\n# Enable logging of ARGs at various positions\ncpa.arg.logARGs = false\n\n# If this option is enabled, ARG states will also be merged if the first\n# wrapped state is subsumed by the second wrapped state (and the parents are\n# not yet subsumed).\ncpa.arg.mergeOnWrappedSubsumption = false\n\n# Export final ARG as pixel graphic to the given file name. The suffix is\n# added  corresponding to the value of option pixelgraphic.export.formatIf\n# set to 'null', no pixel graphic is exported.\ncpa.arg.pixelGraphicFile = no default value\n\n# export a proof as .graphml file\ncpa.arg.proofWitness = no default value\n\n# export a proof as dot/graphviz file\ncpa.arg.proofWitness.dot = no default value\n\n# export simplified ARG that shows all refinements to .dot file\ncpa.arg.refinements.file = \"ARGRefinements.dot\"\n\n# export final ARG as .dot file, showing only loop heads and function\n# entries/exits\ncpa.arg.simplifiedARG.file = \"ARGSimplified.dot\"\n\n# translate final ARG into C program\ncpa.arg.translateToC = false\n\n# Verification witness: Include the considered case of an assume?\ncpa.arg.witness.exportAssumeCaseInfo = true\n\n# Verification witness: Include assumptions (C statements)?\ncpa.arg.witness.exportAssumptions = true\n\n# Verification witness: Include function calls and function returns?\ncpa.arg.witness.exportFunctionCallsAndReturns = true\n\n# Export invariants in correctness witness also if location was not explored\ncpa.arg.witness.exportInvariantsForNonExploredStates = true\n\n# Export witness that is a combination of multiple (partial) correctness\n# witnesses, do not export default invariants\ncpa.arg.witness.exportJointWitnesses = false\n\n# Verification witness: Include the (starting) line numbers of the operations\n# on the transitions?\ncpa.arg.witness.exportLineNumbers = true\n\n# Verification witness: Export labels for nodes in GraphML for easier visual\n# representation?\ncpa.arg.witness.exportNodeLabel = false\n\n# Verification witness: Include the offset within the file?\ncpa.arg.witness.exportOffset = true\n\n# Always export source file name, even default\ncpa.arg.witness.exportSourceFileName = false\n\n# Verification witness: Include the sourcecode of the operations?\ncpa.arg.witness.exportSourcecode = false\n\n# Verification witness: Include an thread-identifier within the file?\ncpa.arg.witness.exportThreadId = false\n\n# Verification witness: Include (not necessarily globally unique) thread\n# names for concurrent tasks for debugging?\ncpa.arg.witness.exportThreadName = false\n\n# Shrink ARG graph into a smaller witness graph by merging edges\ncpa.arg.witness.minimizeARG = true\n\n# Produce an invariant witness instead of a correctness witness. Constructing\n# an invariant witness makes use of a different merge for quasi-invariants:\n# Instead of computing the disjunction of two invariants present when merging\n# nodes, 'true' is ignored when constructing the disjunction. This may be\n# unsound in some situations, so be careful when using this option.\ncpa.arg.witness.produceInvariantWitnesses = false\n\n# Some redundant transitions will be removed\ncpa.arg.witness.removeInsufficientEdges = true\n\n# Verification witness: Revert escaping/renaming of functions for threads?\ncpa.arg.witness.revertThreadFunctionRenaming = false\n\n# The template from which the different versions of the correctness witnesses\n# will be exported. Each version replaces the string '%s' with its version\n# number.\ncpa.arg.yamlProofWitness = \"witness-%s.yml\"\n\n# signal the analysis to break in case the given number of error state is\n# reached. Use -1 to disable this limit.\ncpa.automaton.breakOnTargetState = 1\n\n# export automaton to file\ncpa.automaton.dotExport = false\n\n# file for saving the automaton in DOT format (%s will be replaced with\n# automaton name)\ncpa.automaton.dotExportFile = \"%s.dot\"\n\n# the maximum number of iterations performed after the initial error is\n# found, despite the limit given as cpa.automaton.breakOnTargetState is not\n# yet reached. Use -1 to disable this limit.\ncpa.automaton.extraIterationsLimit = -1\n\n# file with automaton specification for ObserverAutomatonCPA and\n# ControlAutomatonCPA\ncpa.automaton.inputFile = no default value\n\n# Merge two automata states if one of them is TOP.\ncpa.automaton.mergeOnTop = false\n\n# An implicit precision: consider states with a self-loop and no other\n# outgoing edges as TOP.\ncpa.automaton.prec.topOnFinalSelfLoopingState = false\n\n# file for saving the automaton in spc format (%s will be replaced with\n# automaton name)\ncpa.automaton.spcExportFile = \"%s.spc\"\n\n# Whether to treat automaton states with an internal error state as targets.\n# This should be the standard use case.\ncpa.automaton.treatErrorsAsTargets = true\n\n# If enabled, cache queries also consider blocks with non-matching precision\n# for reuse.\ncpa.bam.aggressiveCaching = true\n\n# export blocked ARG as .dot file\ncpa.bam.argFile = \"BlockedARG.dot\"\n\n# Type of partitioning (FunctionAndLoopPartitioning or\n# DelayedFunctionAndLoopPartitioning)\n# or any class that implements a PartitioningHeuristic\ncpa.bam.blockHeuristic = no default value\n\n# only consider functions with a matching name, i.e., select only some\n# functions directly.\ncpa.bam.blockHeuristic.functionPartitioning.matchFunctions = no default value\n\n# only consider function with a minimum number of calls. This approach is\n# similar to 'inlining' functions used only a few times. Info: If a function\n# is called several times in a loop, we only count 'one' call.\ncpa.bam.blockHeuristic.functionPartitioning.minFunctionCalls = 0\n\n# only consider function with a minimum number of CFA nodes. This approach is\n# similar to 'inlining' small functions, when using BAM.\ncpa.bam.blockHeuristic.functionPartitioning.minFunctionSize = 0\n\n# file for exporting detailed statistics about blocks\ncpa.bam.blockStatisticsFile = \"block_statistics.txt\"\n\n# abort current analysis when finding a missing block abstraction\ncpa.bam.breakForMissingBlock = true\n\n# This flag determines which precisions should be updated during refinement.\n# We can choose between the minimum number of states and all states that are\n# necessary to re-explore the program along the error-path.\ncpa.bam.doPrecisionRefinementForAllStates = false\n\n# Heuristic: This flag determines which precisions should be updated during\n# refinement. This flag also updates the precision of the most inner block.\ncpa.bam.doPrecisionRefinementForMostInnerBlock = true\n\n# export blocks\ncpa.bam.exportBlocksPath = \"block_cfa.dot\"\n\n# If enabled, the reached set cache is analysed for each cache miss to find\n# the cause of the miss.\ncpa.bam.gatherCacheMissStatistics = false\n\n# BAM allows to analyse recursive procedures. This strongly depends on the\n# underlying CPA. The current support includes only ValueAnalysis and\n# PredicateAnalysis (with tree interpolation enabled).\ncpa.bam.handleRecursiveProcedures = false\n\n# export single blocked ARG as .dot files, should contain '%d'\ncpa.bam.indexedArgFile = \"ARGs/ARG_%d.dot\"\n\n# if we cannot determine a repeating/covering call-state, we will run into\n# CallStackOverflowException. Thus we bound the stack size (unsound!). This\n# option only limits non-covered recursion, but not a recursion where we find\n# a coverage and re-use the cached block several times. The value '-1'\n# disables this option.\ncpa.bam.maximalDepthForExplicitRecursion = -1\n\n# By default, the CPA algorithm terminates when finding the first target\n# state, which makes it easy to identify this last state. For special\n# analyses, we need to search for more target states in the reached-set, when\n# reaching a block-exit. This flag is needed if the option\n# 'cpa.automaton.breakOnTargetState' is unequal to 1.\ncpa.bam.searchTargetStatesOnExit = false\n\n# export used parts of blocked ARG as .dot file\ncpa.bam.simplifiedArgFile = \"BlockedARGSimplified.dot\"\n\n# Should the nested CPA-algorithm be wrapped with CEGAR within BAM?\ncpa.bam.useCEGAR = false\n\n# This flag determines which refinement procedure we should use. We can\n# choose between an in-place refinement and a copy-on-write refinement.\ncpa.bam.useCopyOnWriteRefinement = false\n\n# In some cases BAM cache can not be easily applied. If the option is enabled\n# CPAs can inform BAM that the result states should not be used even if there\n# will a cache hit.\ncpa.bam.useDynamicAdjustment = false\n\n# max bitsize for values and vars, initial value\ncpa.bdd.bitsize = 64\n\n# use a smaller bitsize for all vars, that have only intEqual values\ncpa.bdd.compressIntEqual = true\n\n# add some additional variables (with prefix) for each variable that can be\n# used for more complex BDD operations later. In the ordering, we declare\n# them as narrow as possible to the original variable, such that the overhead\n# for using them stays small. A value 0 disables this feature.\ncpa.bdd.initAdditionalVariables = 0\n\n# declare the bits of a var from 0 to N or from N to 0\ncpa.bdd.initBitsIncreasing = true\n\n# declare first bit of all vars, then second bit,...\ncpa.bdd.initBitwise = true\n\n# declare vars partitionwise\ncpa.bdd.initPartitions = Ordered = true\n\n# declare partitions ordered\ncpa.bdd.initPartitionsOrdered = true\n\n# Dump tracked variables to a file.\ncpa.bdd.logfile = \"BDDCPA_tracked_variables.log\"\n\n# mergeType\ncpa.bdd.merge = \"join\"\n  allowed values: [sep, join]\n\n# reduce and expand BDD states for BAM, otherwise use plain identity\ncpa.bdd.useBlockAbstraction = false\n\n# Dump tracked variables to a file.\ncpa.bdd.variablesFile = \"BDDCPA_ordered_variables.txt\"\n\n# depth of recursion bound\ncpa.callstack.depth = 0\n\n# which abstract domain to use for callstack cpa, typically FLAT which is\n# faster since it uses only object equivalence\ncpa.callstack.domain = \"FLAT\"\n  allowed values: [FLAT, FLATPCC]\n\n# Skip recursion if it happens only by going via a function pointer (this is\n# unsound). Imprecise function pointer tracking often lead to false\n# recursions.\ncpa.callstack.skipFunctionPointerRecursion = false\n\n# Skip recursion (this is unsound). Treat function call as a statement (the\n# same as for functions without bodies)\ncpa.callstack.skipRecursion = false\n\n# Skip recursion if it happens only by going via a void function with no\n# pointers passed as parameters. This is unsound if the function modifies\n# global variables.\ncpa.callstack.skipVoidRecursion = false\n\n# analyse the CFA backwards\ncpa.callstack.traverseBackwards = false\n\n# Blacklist of extern functions that will make the analysis abort if called\ncpa.callstack.unsupportedFunctions = {\n          \"pthread_create\",\n          \"pthread_key_create\",\n          \"_longjmp\",\n          \"longjmp\",\n          \"siglongjmp\",\n          \"__builtin_va_arg\",\n          \"atexit\"}\n\n# By enabling this option the CompositeTransferRelation will compute abstract\n# successors for as many edges as possible in one call. For any chain of\n# edges in the CFA which does not have more than one outgoing or leaving edge\n# the components of the CompositeCPA are called for each of the edges in this\n# chain. Strengthening is still computed after every edge. The main\n# difference is that while this option is enabled not every ARGState may have\n# a single edge connecting to the child/parent ARGState but it may instead be\n# a list.\ncpa.composite.aggregateBasicBlocks = false\n\n# inform Composite CPA if it is run in a CPA enabled analysis because then it\n# must behave differently during merge.\ncpa.composite.inCPAEnabledAnalysis = false\n\n# which composite merge operator to use (plain or agree)\n# Both delegate to the component cpas, but agree only allows merging if all\n# cpas agree on this. This is probably what you want.\ncpa.composite.merge = \"AGREE\"\n  allowed values: [PLAIN, AGREE]\n\n# Limit for Java heap memory used by CPAchecker (in MB, not MiB!; -1 for\n# infinite)\ncpa.conditions.global.memory.heap = -1\n\n# Limit for process memory used by CPAchecker (in MB, not MiB!; -1 for\n# infinite)\ncpa.conditions.global.memory.process = -1\n\n# Limit for size of reached set (-1 for infinite)\ncpa.conditions.global.reached.size = -1\n\n# Limit for cpu time used by CPAchecker (use milliseconds or specify a unit;\n# -1 for infinite)\ncpa.conditions.global.time.cpu = -1\n\n# Hard limit for cpu time used by CPAchecker (use milliseconds or specify a\n# unit; -1 for infinite)\n# When using adjustable conditions, analysis will end after this threshold\ncpa.conditions.global.time.cpu.hardlimit = -1\n\n# Limit for wall time used by CPAchecker (use milliseconds or specify a unit;\n# -1 for infinite)\ncpa.conditions.global.time.wall = -1\n\n# Hard limit for wall time used by CPAchecker (use milliseconds or specify a\n# unit; -1 for infinite)\n# When using adjustable conditions, analysis will end after this threshold\ncpa.conditions.global.time.wall.hardlimit = -1\n\n# Number of times the path condition may be adjusted, i.e., the path\n# condition threshold may be increased (-1 to always adjust)\ncpa.conditions.path.adjustment.threshold = -1\n\n# determines if there should be one single assignment state per state, one\n# per path segment between assume edges, or a global one for the whole\n# program.\ncpa.conditions.path.assignments.scope = STATE\n  enum:     [STATE, PATH, PROGRAM]\n\n# sets the threshold for assignments (-1 for infinite), and it is upto, e.g.,\n# ValueAnalysisPrecisionAdjustment to act accordingly to this threshold\n# value.\ncpa.conditions.path.assignments.threshold = DISABLED\n\n# maximum number of assume edges length (-1 for infinite)\ncpa.conditions.path.assumeedges.limit = -1\n\n# The condition\ncpa.conditions.path.condition = no default value\n\n# maximum path length (-1 for infinite)\ncpa.conditions.path.length.limit = -1\n\n# maximum repetitions of any edge in a path (-1 for infinite)\ncpa.conditions.path.repetitions.limit = -1\n\n# Generate congruences for sums of variables (<=> x and y have same/different\n# evenness)\ncpa.congruence.trackCongruenceSum = false\n\n# Cache formulas produced by path formula manager\ncpa.congruence.useCachingPathFormulaManager = true\n\n# Whether to perform caching of constraint satisfiability results\ncpa.constraints.cache = true\n\n# Whether to use subset caching\ncpa.constraints.cacheSubsets = false\n\n# Whether to use superset caching\ncpa.constraints.cacheSupersets = false\n\n# Type of less-or-equal operator to use\ncpa.constraints.lessOrEqualType = SUBSET\n  enum:     [SUBSET]\n\n# Type of merge operator to use\ncpa.constraints.mergeType = SEP\n  enum:     [SEP, JOIN_FITTING_CONSTRAINT]\n\n# Whether to perform SAT checks only for the last added constraint\ncpa.constraints.minimalSatCheck = true\n\n# enable if variables from value precision should be considered in variable's\n# scope instead of scope specified in precision\ncpa.constraints.refinement.applyInScope = false\n\n# derive an initial constraint precision from value precision stored in this\n# file\ncpa.constraints.refinement.initialValuePrecisionFile = no default value\n\n# enable to track constraints based on value precision only if all variables\n# occurring in constraint are relevant in variable precision. If disabled it\n# is sufficient that one variable is relevant.\ncpa.constraints.refinement.mustTrackAll = false\n\n# Type of precision to use. Has to be LOCATION if PredicateExtractionRefiner\n# is used.\ncpa.constraints.refinement.precisionType = CONSTRAINTS\n  enum:     [CONSTRAINTS, LOCATION]\n\n# Whether to remove constraints that can't add any more information\n# toanalysis during simplification\ncpa.constraints.removeOutdated = true\n\n# Whether to remove trivial constraints from constraints states during\n# simplification\ncpa.constraints.removeTrivial = false\n\n# Resolve definite assignments\ncpa.constraints.resolveDefinites = true\n\n# When to check the satisfiability of constraints\ncpa.constraints.satCheckStrategy = AT_ASSUME\n  enum:     [AT_ASSUME, AT_TARGET]\n\n# Export the trace-abtraction automaton to a file in dot-format.\ncpa.dca.refiner.dotExport = false\n\n# Filename that the interpolation automaton will be written to. %s will get\n# replaced by the automaton name.\ncpa.dca.refiner.dotExportFile = \"%s.dot\"\n\n# The max amount of refinements for the trace abstraction algorithm. Setting\n# it to 0 leads to an analysis of the ARG without executing any refinements.\n# This is used for debugging purposes.\ncpa.dca.refiner.maxRefinementIterations = 10\n\n# Skip the analysis (including the refinement) entirely, so that the ARG is\n# left unmodified. This is used for debugging purposes.\ncpa.dca.refiner.skipAnalysis = false\n\n# which merge operator to use for DefUseCPA\ncpa.defuse.merge = \"sep\"\n  allowed values: [sep, join]\n\n# Which strategy to use for forced coverings (empty for none)\ncpa.forcedCovering = no default value\n\n# When an invalid function pointer is called, do not assume all functions as\n# possible targets and instead call no function.\ncpa.functionpointer.ignoreInvalidFunctionPointerCalls = false\n\n# When an unknown function pointer is called, do not assume all functions as\n# possible targets and instead call no function (this is unsound).\ncpa.functionpointer.ignoreUnknownFunctionPointerCalls = false\n\n# whether function pointers with invalid targets (e.g., 0) should be tracked\n# in order to find calls to such pointers\ncpa.functionpointer.trackInvalidFunctionPointers = false\n\n# which merge operator to use for GlobalVarAnalysisCPA\ncpa.globalvar.merge = \"SEP\"\n  allowed values: [SEP, JOIN]\n\n# which stop operator to use for GlobalVarAnalysisCPA\ncpa.globalvar.stop = \"SEP\"\n  allowed values: [SEP, JOIN, NEVER]\n\n# which type of merge operator to use for IntervalAnalysisCPA\ncpa.interval.merge = \"SEP\"\n  allowed values: [SEP, JOIN]\n\n# decides whether one (false) or two (true) successors should be created when\n# an inequality-check is encountered\ncpa.interval.splitIntervals = false\n\n# at most that many intervals will be tracked per variable, -1 if number not\n# restricted\ncpa.interval.threshold = -1\n\n# controls whether to use abstract evaluation always, never, or depending on\n# entering edges.\ncpa.invariants.abstractionStateFactory = ENTERING_EDGES\n  enum:     [ALWAYS, ENTERING_EDGES, NEVER]\n\n# enables the over-approximation of unsupported features instead of failing\n# fast; this is imprecise\ncpa.invariants.allowOverapproximationOfUnsupportedFeatures = true\n\n# determine variables relevant to the decision whether or not a target path\n# assume edge is taken and limit the analyis to those variables.\ncpa.invariants.analyzeRelevantVariablesOnly = true\n\n# determine target locations in advance and analyse paths to the target\n# locations only.\ncpa.invariants.analyzeTargetPathsOnly = true\n\n# controls the condition adjustment logic: STATIC means that condition\n# adjustment is a no-op, INTERESTING_VARIABLES increases the interesting\n# variable limit, MAXIMUM_FORMULA_DEPTH increases the maximum formula depth,\n# ABSTRACTION_STRATEGY tries to choose a more precise abstraction strategy,\n# COMPOUND combines the other strategies (minus STATIC).\ncpa.invariants.conditionAdjusterFactory = COMPOUND\n  enum:     [STATIC, INTERESTING_VARIABLES, MAXIMUM_FORMULA_DEPTH,\n             ABSTRACTION_STRATEGY, COMPOUND]\n\n# include type information for variables, such as x >= MIN_INT && x <=\n# MAX_INT\ncpa.invariants.includeTypeInformation = true\n\n# the maximum number of variables to consider as interesting. -1 one disables\n# the limit, but this is not recommended. 0 means that no variables are\n# considered to be interesting.\ncpa.invariants.interestingVariableLimit = 2\n\n# the maximum number of adjustments of the interestingVariableLimit. -1 one\n# disables the limit\ncpa.invariants.maxInterestingVariableAdjustments = -1\n\n# the maximum tree depth of a formula recorded in the environment.\ncpa.invariants.maximumFormulaDepth = 4\n\n# which merge operator to use for InvariantCPA\ncpa.invariants.merge = \"PRECISIONDEPENDENT\"\n  allowed values: [JOIN, SEP, PRECISIONDEPENDENT]\n\n# use modulo-2 template during widening if applicable.\ncpa.invariants.useMod2Template = false\n\n# use pointer-alias information in strengthening, if available.\ncpa.invariants.usePointerAliasStrengthening = true\n\n# With this option the handling of global variables during the analysis can\n# be fine-tuned. For example while doing a function-wise analysis it is\n# important to assume that all global variables are live. In contrast to\n# that, while doing a global analysis, we do not need to assume global\n# variables being live.\ncpa.liveVar.assumeGlobalVariablesAreAlwaysLive = true\n\n# functions, which allocate new free memory\ncpa.local.allocateFunctionPattern = {}\ncpa.local.allocatefunctions = {}\n\n# functions, which do not change sharedness of parameters\ncpa.local.conservativefunctions = {}\n\n# variables, which are always local\ncpa.local.localvariables = {}\n\n# With this option enabled, function calls that occur in the CFA are\n# followed. By disabling this option one can traverse a function without\n# following function calls (in this case FunctionSummaryEdges are used)\ncpa.location.followFunctionCalls = true\n\n# What are we searching for: race or deadlock\ncpa.lock.analysisMode = RACE\n  enum:     [RACE, DEADLOCK]\n\n#  annotated functions, which are known to works right\ncpa.lock.annotate = no default value\n\n# contains all lock names\ncpa.lock.lockinfo = {}\n\n# which merge operator to use for LockCPA\ncpa.lock.merge = \"SEP\"\n  allowed values: [SEP, JOIN]\n\n# reduce recursive locks to a single access\ncpa.lock.reduceLockCounters = BLOCK\n  enum:     [NONE, BLOCK, ALL]\n\n# reduce unused locks\ncpa.lock.reduceUselessLocks = false\n\n# Enable refinement procedure\ncpa.lock.refinement = false\n\n# stop path exploration if a lock limit is reached\ncpa.lock.stopAfterLockLimit = false\n\n# Consider or not special cases with empty lock sets\ncpa.lock.stopMode = DEFAULT\n  enum:     [DEFAULT, EMPTYLOCKSET]\n\n# Only checks for targets after loops were unrolled exactly a number of times\n# that is contained in this list. The default is an empty list, which means\n# targets are checked in every iteration\ncpa.loopbound.checkOnlyAtBounds = []\n\n# Use a stop operator that will identify loop states who's depth is congruent\n# regarding the modulus of this number. Values smaller or equal to zero will\n# deactivate this feature.\ncpa.loopbound.cyclicStopModulus = -1\n\n# Number of loop iterations before the loop counter is abstracted. Zero is\n# equivalent to no limit.\ncpa.loopbound.loopIterationsBeforeAbstraction = 0\n\n# This option controls how the maxLoopIterations condition is adjusted when a\n# condition adjustment is invoked.\ncpa.loopbound.maxLoopIterationAdjusterFactory = STATIC\n  enum:     [STATIC, INCREMENT, DOUBLE]\n\n# Bound for the number of complete loop unrollings\n# of the program (0 is used for no bound).\n# Works only if assumption storage CPA is enabled, because otherwise it would\n# be unsound.\ncpa.loopbound.maxLoopIterations = 0\n\n# Maximum for adjusting the bound for the number of complete loop unrollings\n# of the\n#  program (0 is used for no maximum).\n# Only relevant in combination with a non-static adjuster for the bound for\n# loop-head visits.\ncpa.loopbound.maxLoopIterationsUpperBound = 0\n\n# Only checks for error after loops were unrolled at least this amount of\n# times.\ncpa.loopbound.startAtBound = 0\n\n# enable stack-based tracking of loops\ncpa.loopbound.trackStack = false\n\n# Where to perform abstraction\ncpa.lpi.abstractionLocations = LOOPHEAD\n  enum:     [ALL, LOOPHEAD, MERGE]\n\n# deprecated name for precision.template.allowedCoefficients\ncpa.lpi.allowedCoefficients = {Rational.NEG_ONE, Rational.ONE}\n\n# Attach extra invariant from other CPAs during the value determination\n# computation\ncpa.lpi.attachExtraInvariantDuringValueDetermination = true\n\n# Check whether the policy depends on the initial value\ncpa.lpi.checkPolicyInitialCondition = true\n\n# Check target states reachability\ncpa.lpi.checkTargetStates = true\n\n# Compute abstraction for larger templates using decomposition\ncpa.lpi.computeAbstractionByDecomposition = false\n\n# Do not compute the abstraction until strengthen is called. This speeds up\n# the computation, but does not let other CPAs use the output of LPI.\ncpa.lpi.delayAbstractionUntilStrengthen = false\n\n# Value to substitute for the epsilon\ncpa.lpi.epsilon = Rational.ONE\n\n# deprecated name for precision.template.generateDifferences\ncpa.lpi.generateDifferences = false\n\n# deprecated name for precision.template.generateFromAsserts\ncpa.lpi.generateFromAsserts = true\n\n# deprecated name for precision.template.generateFromStatements\ncpa.lpi.generateFromStatements = false\n\n# Generate new templates using polyhedra convex hull\ncpa.lpi.generateTemplatesUsingConvexHull = false\n\n# deprecated name for precision.template.includeFunctionParameters\ncpa.lpi.includeFunctionParameters = false\n\n# Remove UFs and ITEs from policies.\ncpa.lpi.linearizePolicy = true\n\n# deprecated name for precision.template.maxExpressionSize\ncpa.lpi.maxExpressionSize = 1\n\n# deprecated name for precision.template.performEnumerativeRefinement\ncpa.lpi.performEnumerativeRefinement = true\n\n# Attempt to weaken interpolants in order to make them more general\ncpa.lpi.refinement.generalizeInterpolants = true\n\n# Run naive value determination first, switch to namespaced if it fails.\ncpa.lpi.runHopefulValueDetermination = true\n\n# Remove redundant items when abstract values.\ncpa.lpi.simplifyDotOutput = false\n\n# deprecated name for precision.template.templateConstantThreshold\ncpa.lpi.templateConstantThreshold = 100\n\n# Algorithm for converting a formula to a set of lemmas\ncpa.lpi.toLemmasAlgorithm = \"RCNF\"\n  allowed values: [CNF, RCNF, NONE]\n\n# Number of refinements after which the unrolling depth is increased.Set to\n# -1 to never increase the depth.\ncpa.lpi.unrollingRefinementThreshold = 2\n\n# Cache formulas produced by path formula manager\ncpa.lpi.useCachingPathFormulaManager = true\n\n# Syntactically pre-compute dependencies for value determination\ncpa.lpi.valDetSyntacticCheck = true\n\n# deprecated name for precision.template.varFiltering\ncpa.lpi.varFiltering = ALL_LIVE\n  enum:     [INTERPOLATION_BASED, ALL_LIVE, ONE_LIVE, ALL]\n\n# Number of value determination steps allowed before widening is run. Value\n# of '-1' runs value determination until convergence.\ncpa.lpi.wideningThreshold = -1\n\n# time limit for a single post computation (use milliseconds or specify a\n# unit; 0 for infinite)\ncpa.monitor.limit = 0\n\n# time limit for all computations on a path in milliseconds (use milliseconds\n# or specify a unit; 0 for infinite)\ncpa.monitor.pathcomputationlimit = 0\n\n# keep tracking nondeterministically-assigned variables even if they are used\n# in assumptions\ncpa.nondeterminism.acceptConstrained = true\n\n# this option determines which initial precision should be used\ncpa.octagon.initialPrecisionType = \"STATIC_FULL\"\n  allowed values: [STATIC_FULL, REFINEABLE_EMPTY]\n\n# with this option enabled the states are only merged at loop heads\ncpa.octagon.mergeop.onlyMergeAtLoopHeads = false\n\n# of which type should the merge be?\ncpa.octagon.mergeop.type = \"SEP\"\n  allowed values: [SEP, JOIN, WIDENING]\n\n# with this option the number representation in the library will be changed\n# between floats and ints.\ncpa.octagon.octagonLibrary = \"INT\"\n  allowed values: [INT, FLOAT]\n\n# Timelimit for the backup feasibility check with the octagon analysis.(use\n# seconds or specify a unit; 0 for infinite)\ncpa.octagon.refiner.timeForOctagonFeasibilityCheck = 0ns\n\n# which merge operator to use for PointerCPA\ncpa.pointer2.merge = \"JOIN\"\n  allowed values: [JOIN, SEP]\n\n# which merge operator to use for PointerACPA\ncpa.pointerA.merge = \"JOIN\"\n  allowed values: [SEP, JOIN]\n\n# which stop operator to use for PointerACPA\ncpa.pointerA.stop = \"SEP\"\n  allowed values: [SEP, JOIN, NEVER]\n\n# Whether to give up immediately if a very large array is encountered\n# (heuristic, often we would just waste time otherwise)\ncpa.predicate.abortOnLargeArrays = true\n\n# Predicate ordering\ncpa.predicate.abs.predicateOrdering.method = CHRONOLOGICAL\n  enum:     [CHRONOLOGICAL, FRAMEWORK_RANDOM, FRAMEWORK_SIFT, FRAMEWORK_SIFTITE,\n             FRAMEWORK_WIN2, FRAMEWORK_WIN2ITE, FRAMEWORK_WIN3, FRAMEWORK_WIN3ITE]\n\n# use caching of abstractions\n# use caching of region to formula conversions\ncpa.predicate.abs.useCache = true\n\n# DEPRECATED: whether to use Boolean (false) or Cartesian (true) abstraction\ncpa.predicate.abstraction.cartesian = false\n\n# whether to use Boolean or Cartesian abstraction or both\ncpa.predicate.abstraction.computation = BOOLEAN\n  enum:     [CARTESIAN, CARTESIAN_BY_WEAKENING, BOOLEAN, COMBINED, ELIMINATION]\n\n# dump the abstraction formulas if they took to long\ncpa.predicate.abstraction.dumpHardQueries = false\n\n# Identify those predicates where the result is trivially known before\n# abstraction computation and omit them.\ncpa.predicate.abstraction.identifyTrivialPredicates = false\n\n# get an initial map of predicates from a list of files (see source\n# doc/examples/predmap.txt for an example)\ncpa.predicate.abstraction.initialPredicates = []\n\n# Apply location-specific predicates to all locations in their function\ncpa.predicate.abstraction.initialPredicates.applyFunctionWide = false\n\n# Apply location- and function-specific predicates globally (to all locations\n# in the program)\ncpa.predicate.abstraction.initialPredicates.applyGlobally = false\n\n# when reading predicates from file, convert them from Integer- to BV-theory\n# or reverse.\ncpa.predicate.abstraction.initialPredicates.encodePredicates = DISABLE\n  enum:     [DISABLE, INT2BV, BV2INT]\n\n# when reading invariants from YML witness ignore the location context and\n# only consider the function context of the program\ncpa.predicate.abstraction.initialPredicates.ignoreLocationInfoInYMLWitness = false\n\n# initial predicates are added as atomic predicates\ncpa.predicate.abstraction.initialPredicates.splitIntoAtoms = false\n\n# An initial set of comptued abstractions that might be reusable\ncpa.predicate.abstraction.reuseAbstractionsFrom = no default value\n\n# Simplify the abstraction formula that is stored to represent the state\n# space. Helpful when debugging (formulas get smaller).\ncpa.predicate.abstraction.simplify = false\n\n# What to use for storing abstractions\ncpa.predicate.abstraction.type = \"BDD\"\n  allowed values: [BDD, FORMULA]\n\n# Export abstraction formulas as (way more readable) expressions.\ncpa.predicate.abstractions.asExpressions = false\n\n# Export one abstraction formula for each abstraction state into a file?\ncpa.predicate.abstractions.export = true\n\n# file that consists of one abstraction formula for each abstraction state\ncpa.predicate.abstractions.file = \"abstractions.txt\"\n\n# Add constraints for the range of the return-value of a nondet-method. For\n# example the assignment 'X=nondet_int()' produces the constraint\n# 'MIN<=X<=MAX', where MIN and MAX are computed from the type of the method\n# (signature, not name!).\ncpa.predicate.addRangeConstraintsForNondet = false\n\n# deprecated name for cpa.predicate.invariants.addToPrecision\ncpa.predicate.addToPrecision = false\n\n# deprecated name for counterexample.export.allowImpreciseCounterexamples\ncpa.predicate.allowImpreciseCounterexamples = false\n\n# Allow the given extern functions and interpret them as pure functions\n# although the predicate analysis does not support their semantics and this\n# can produce wrong results.\ncpa.predicate.allowedUnsupportedFunctions = {}\n\n# deprecated name for counterexample.export.alwaysUseImpreciseCounterexamples\ncpa.predicate.alwaysUseImpreciseCounterexamples = false\n\n# deprecated name for cpa.predicate.invariants.appendToAbstractionFormula\ncpa.predicate.appendToAbstractionFormula = false\n\n# Check satisfiability for plain conjunction of edge and assumptions.\ncpa.predicate.assumptionStrengtheningSatCheck = false\n\n# Enable/disable abstraction reduction at the BAM block entry\ncpa.predicate.bam.useAbstractionReduction = true\n\n# Enable/disable precision reduction at the BAM block entry\ncpa.predicate.bam.usePrecisionReduction = true\n\n# The bitsize is used to encode integers as bitvectors.\ncpa.predicate.bitsize = 32\n\n# force abstractions immediately after threshold is reached (no effect if\n# threshold = 0)\ncpa.predicate.blk.alwaysAfterThreshold = true\n\n# abstraction always and only on explicitly computed abstraction nodes.\ncpa.predicate.blk.alwaysAndOnlyAtExplicitNodes = false\n\n# force abstractions at each branch node, regardless of threshold\ncpa.predicate.blk.alwaysAtBranch = false\n\n# force abstractions at the head of the analysis-entry function (first node\n# in the body), regardless of threshold\ncpa.predicate.blk.alwaysAtEntryFunctionHead = false\n\n# abstraction always at explicitly computed abstraction nodes.\ncpa.predicate.blk.alwaysAtExplicitNodes = false\n\n# force abstractions at each function call (node before entering the body),\n# regardless of threshold\ncpa.predicate.blk.alwaysAtFunctionCallNodes = false\n\n# abstraction always at function exit nodes.\ncpa.predicate.blk.alwaysAtFunctionExit = false\n\n# force abstractions at each function head (first node in the body),\n# regardless of threshold\ncpa.predicate.blk.alwaysAtFunctionHeads = false\n\n# force abstractions at each function calls/returns, regardless of threshold\ncpa.predicate.blk.alwaysAtFunctions = true\n\n# Abstract at predefined locations given as a list of CFANode ids.\ncpa.predicate.blk.alwaysAtGivenNodes = {}\n\n# force abstractions at each join node, regardless of threshold\ncpa.predicate.blk.alwaysAtJoin = false\n\n# force abstractions at loop heads, regardless of threshold\ncpa.predicate.blk.alwaysAtLoops = true\n\n# force abstractions at program exit (program end, abort, etc.), regardless\n# of threshold\ncpa.predicate.blk.alwaysAtProgramExit = false\n\n# abstractions at function calls/returns if threshold has been reached (no\n# effect if threshold = 0)\ncpa.predicate.blk.functions = false\n\n# abstractions at CFA nodes with more than one incoming edge if threshold has\n# been reached (no effect if threshold = 0)\ncpa.predicate.blk.join = false\n\n# abstractions at loop heads if threshold has been reached (no effect if\n# threshold = 0)\ncpa.predicate.blk.loops = false\n\n# maximum blocksize before abstraction is forced\n# (non-negative number, special values: 0 = don't check threshold, 1 = SBE)\ncpa.predicate.blk.threshold = 0\n\n# use caching of path formulas\ncpa.predicate.blk.useCache = true\n\n# always check satisfiability at end of block, even if precision is empty\ncpa.predicate.checkBlockFeasibility = false\n\n# The default size in bytes for memory allocations when the value cannot be\n# determined.\ncpa.predicate.defaultAllocationSize = 4\n\n# The length for arrays we assume for variably-sized arrays.\ncpa.predicate.defaultArrayLength = 20\n\n# Use deferred allocation heuristic that tracks void * variables until the\n# actual type of the allocation is figured out.\ncpa.predicate.deferUntypedAllocations = true\n\n# Direction of the analysis?\ncpa.predicate.direction = FORWARD\n  enum:     [FORWARD, BACKWARD]\n\n# deprecated name for counterexample.export.formula\ncpa.predicate.dumpCounterexampleFormula = \"Counterexample.%d.smt2\"\n\n# deprecated name for counterexample.export.model\ncpa.predicate.dumpCounterexampleModel = \"Counterexample.%d.assignment.txt\"\n\n# deprecated name for\n# cpa.predicate.invariants.dumpInvariantGenerationAutomata\ncpa.predicate.dumpInvariantGenerationAutomata = false\n\n# deprecated name for\n# cpa.predicate.invariants.dumpInvariantGenerationAutomataFile\ncpa.predicate.dumpInvariantGenerationAutomataFile = \"invgen.%d.spc\"\n\n# Enable the possibility to precompute explicit abstraction locations.\ncpa.predicate.enableBlockreducer = false\n\n# Enable handling of functions memset, memcopy, memmove. If disabled, using\n# these functions will result in an error.\ncpa.predicate.enableMemoryAssignmentFunctions = false\n\n# Enable to share the information via serialization storage.\ncpa.predicate.enableSharedInformation = false\n\n# Theory to use as backend for bitvectors. If different from BITVECTOR, the\n# specified theory is used to approximate bitvectors. This can be used for\n# solvers that do not support bitvectors, or for increased performance. If\n# UNSUPPORTED, solvers can be used that support none of the possible\n# alternatives, but CPAchecker will crash if bitvectors are required by the\n# analysis.\ncpa.predicate.encodeBitvectorAs = BITVECTOR\n  enum:     [UNSUPPORTED, INTEGER, RATIONAL, BITVECTOR, FLOAT]\n\n# Theory to use as backend for floats. If different from FLOAT, the specified\n# theory is used to approximate floats. This can be used for solvers that do\n# not support floating-point arithmetic, or for increased performance. If\n# UNSUPPORTED, solvers can be used that support none of the possible\n# alternatives, but CPAchecker will crash if floats are required by the\n# analysis.\ncpa.predicate.encodeFloatAs = FLOAT\n  enum:     [UNSUPPORTED, INTEGER, RATIONAL, BITVECTOR, FLOAT]\n\n# Theory to use as backend for integers. If different from INTEGER, the\n# specified theory is used to approximate integers. This can be used for\n# solvers that do not support integers, or for increased performance. If\n# UNSUPPORTED, solvers can be used that support none of the possible\n# alternatives, but CPAchecker will crash if integers are required by the\n# analysis.\ncpa.predicate.encodeIntegerAs = INTEGER\n  enum:     [UNSUPPORTED, INTEGER, RATIONAL, BITVECTOR, FLOAT]\n\n# Replace possible overflows with an ITE-structure, which returns either the\n# normal value or an UF representing the overflow.\ncpa.predicate.encodeOverflowsWithUFs = false\n\n# Name of an external function that will be interpreted as if the function\n# call would be replaced by an externally defined expression over the program\n# variables. This will only work when all variables referenced by the dimacs\n# file are global and declared before this function is called.\ncpa.predicate.externModelFunctionName = \"__VERIFIER_externModelSatisfied\"\n\n# where to dump interpolation and abstraction problems (format string)\ncpa.predicate.formulaDumpFilePattern = \"%s%04d-%s%03d.smt2\"\n\n# deprecated name for cpa.predicate.invariants.generationStrategy\ncpa.predicate.generationStrategy = []\n\n# Handle field access via extract and concat instead of new variables.\ncpa.predicate.handleFieldAccess = false\n\n# If disabled, all implicitly initialized fields and elements are treated as\n# non-dets\ncpa.predicate.handleImplicitInitialization = true\n\n# Handle aliasing of pointers. This adds disjunctions to the formulas, so be\n# careful when using cartesian abstraction.\ncpa.predicate.handlePointerAliasing = true\n\n# When a string literal initializer is encountered, initialize the contents\n# of the char array with the contents of the string literal instead of just\n# assigning a fresh non-det address to it\ncpa.predicate.handleStringLiteralInitializers = false\n\n# Ignore Extract and Extend operations instead of encoding them with a UF\n# when Bitvector theory is replaced with Integer or Rational. This is unsound\n# but sometimes more practical in order to not make casts return\n# nondeterministic values.\ncpa.predicate.ignoreExtractExtend = true\n\n# Ignore fields that are not relevant for reachability properties. This is\n# unsound in case fields are accessed by pointer arithmetic with hard-coded\n# field offsets. Only relvant if ignoreIrrelevantVariables is enabled.\ncpa.predicate.ignoreIrrelevantFields = true\n\n# Ignore variables that are not relevant for reachability properties.\ncpa.predicate.ignoreIrrelevantVariables = true\n\n# do not include assumptions of states into path formula during strengthening\ncpa.predicate.ignoreStateAssumptions = false\n\n# Prevent functions memset, memcopy, memmove from stopping verification if\n# there is unrecognized code. Instead, they will just be skipped (unsound).\n# Only relevant if enableMemoryAssignmentFunctions is set to true.\ncpa.predicate.ignoreUnrecognizedCodeInMemoryAssignmentFunctions = false\n\n# Add computed invariants to the precision. Invariants do not need to be\n# generated with the PredicateCPA they can also be given from outside.\ncpa.predicate.invariants.addToPrecision = false\n\n# Strengthen the abstraction formula during abstraction with invariants if\n# some are generated. Invariants do not need to be generated with the\n# PredicateCPA they can also be given from outside.\ncpa.predicate.invariants.appendToAbstractionFormula = false\n\n# Strengthen the pathformula during abstraction with invariants if some are\n# generated. Invariants do not need to be generated with the PredicateCPA\n# they can also be given from outside.\ncpa.predicate.invariants.appendToPathFormula = false\n\n# Should the automata used for invariant generation be dumped to files?\ncpa.predicate.invariants.dumpInvariantGenerationAutomata = false\n\n# Where to dump the automata that are used to narrow the analysis used for\n# invariant generation.\ncpa.predicate.invariants.dumpInvariantGenerationAutomataFile = \"invgen.%d.spc\"\n\n# export final loop invariants\ncpa.predicate.invariants.export = true\n\n# export invariants as precision file?\ncpa.predicate.invariants.exportAsPrecision = true\n\n# file for exporting final loop invariants\ncpa.predicate.invariants.file = \"invariants.txt\"\n\n# Which strategy should be used for generating invariants, a comma separated\n# list can be specified. Usually later specified strategies serve as fallback\n# for earlier ones. (default is no invariant generation at all)\ncpa.predicate.invariants.generationStrategy = []\n\n# How often should generating invariants from sliced prefixes with\n# k-induction be tried?\ncpa.predicate.invariants.kInductionTries = 3\n\n# file for precision that consists of invariants.\ncpa.predicate.invariants.precisionFile = \"invariantPrecs.txt\"\n\n# Timelimit for invariant generation which may be used during refinement.\n# (Use seconds or specify a unit; 0 for infinite)\ncpa.predicate.invariants.timeForInvariantGeneration = 10s\n\n# Should the strategies be used all-together or only as fallback. If all\n# together, the computation is done until the timeout is hit and the results\n# up to this point are taken.\ncpa.predicate.invariants.useAllStrategies = false\n\n# Provide invariants generated with other analyses via the\n# PredicateCPAInvariantsManager.\ncpa.predicate.invariants.useGlobalInvariants = true\n\n# Invariants that are not strong enough to refute the counterexample can be\n# ignored with this option. (Weak invariants will lead to repeated\n# counterexamples, thus taking time which could be used for the rest of the\n# analysis, however, the found invariants may also be better for loops as\n# interpolation.)\ncpa.predicate.invariants.useStrongInvariantsOnly = true\n\n# deprecated name for cpa.predicate.invariants.kInductionTries\ncpa.predicate.kInductionTries = 3\n\n# Max. number of edge of the abstraction tree to prescan for reuse\ncpa.predicate.maxAbstractionReusePrescan = 1\n\n# The maximum length up to which bulk assignments (e.g., initialization) for\n# arrays will be handled. With option useArraysForHeap=false, elements beyond\n# this bound will be ignored completely. Use -1 to disable the limit.\ncpa.predicate.maxArrayLength = -1\n\n# When builtin functions like memcmp/strlen/etc. are called, unroll them up\n# to this bound.If the passed arguments are longer, the return value will be\n# overapproximated.\ncpa.predicate.maxPreciseStrFunctionSize = 100\n\n# Set of functions that non-deterministically provide new memory on the heap,\n# i.e. they can return either a valid pointer or zero.\ncpa.predicate.memoryAllocationFunctions = {\"malloc\", \"__kmalloc\", \"kmalloc\", \"alloca\", \"__builtin_alloca\"}\n\n# Memory allocation functions of which all parameters but the first should be\n# ignored.\ncpa.predicate.memoryAllocationFunctionsWithSuperfluousParameters = {\"__kmalloc\", \"kmalloc\", \"kzalloc\"}\n\n# Set of functions that non-deterministically provide new zeroed memory on\n# the heap, i.e. they can return either a valid pointer or zero.\ncpa.predicate.memoryAllocationFunctionsWithZeroing = {\"kzalloc\", \"calloc\"}\n\n# Setting this to true makes memoryAllocationFunctions always return a valid\n# pointer.\ncpa.predicate.memoryAllocationsAlwaysSucceed = false\n\n# Function that is used to free allocated memory.\ncpa.predicate.memoryFreeFunctionName = \"free\"\n\n# which merge operator to use for predicate cpa (usually ABE should be used)\ncpa.predicate.merge = \"ABE\"\n  allowed values: [SEP, ABE]\n\n# merge two abstraction states if their preceeding abstraction states are the\n# same\ncpa.predicate.merge.mergeAbstractionStatesWithSamePredecessor = false\n\n# Set of functions that should be considered as giving a non-deterministic\n# return value. If you specify this option, the default values are not added\n# automatically to the list, so you need to specify them explicitly if you\n# need them. Mentioning a function in this list has only an effect, if it is\n# an 'external function', i.e., no source is given in the code for this\n# function.\ncpa.predicate.nondetFunctions = {\"sscanf\", \"rand\", \"random\", \"rand_r\", \"srand\", \"time\"}\n\n# Regexp pattern for functions that should be considered as giving a\n# non-deterministic return value (c.f. cpa.predicate.nondedFunctions)\ncpa.predicate.nondetFunctionsRegexp = \"^(__VERIFIER_)?nondet_[a-zA-Z0-9_]*\"\n\n# Do not ignore variables that could lead to an overflow (only makes sense if\n# ignoreIrrelevantVariables is set to true)\ncpa.predicate.overflowVariablesAreRelevant = false\n\n# Which path-formula builder to use.Depending on this setting additional\n# terms are added to the path formulas,e.g. SYMBOLICLOCATIONS will add track\n# the program counter symbolically with a special variable %pc\ncpa.predicate.pathFormulaBuilderVariant = DEFAULT\n  enum:     [DEFAULT, SYMBOLICLOCATIONS]\n\n# Where to apply the found predicates to?\ncpa.predicate.precision.sharing = LOCATION\n  enum:     [GLOBAL, SCOPE, FUNCTION, LOCATION, LOCATION_INSTANCE]\n\n# generate statistics about precisions (may be slow)\ncpa.predicate.precisionStatistics = true\n\n# export final predicate map\ncpa.predicate.predmap.export = true\n\n# file for exporting final predicate map\ncpa.predicate.predmap.file = \"predmap.txt\"\n\n# Format for exporting predicates from precisions.\ncpa.predicate.predmap.predicateFormat = SMTLIB2\n  enum:     [PLAIN, SMTLIB2]\n\n# Specify whether to overapproximate quantified formula, if one or more\n# quantifiers couldn't be eliminated.(Otherwise an exception will be thrown)\ncpa.predicate.pseudoExistQE.overapprox = false\n\n# Which solver tactic to use for Quantifier Elimination(Only used if\n# useRealQuantifierElimination=true)\ncpa.predicate.pseudoExistQE.solverQeTactic = LIGHT\n  enum:     [NONE, LIGHT, FULL]\n\n# Use Destructive Equality Resolution as simplification method\ncpa.predicate.pseudoExistQE.useDER = true\n\n# Use Unconnected Parameter Drop as simplification method\ncpa.predicate.pseudoExistQE.useUPD = true\n\n# If an abstraction is computed during refinement, use only the interpolant\n# as input, not the concrete block.\ncpa.predicate.refinement.abstractInterpolantOnly = false\n\n# use only the atoms from the interpolantsas predicates, and not the whole\n# interpolant\ncpa.predicate.refinement.atomicInterpolants = true\n\n# Direction for doing counterexample analysis: from start of trace, from end\n# of trace, or in more complex patterns. In combination with\n# incrementalCexTraceCheck=true the generated interpolants will refer to the\n# minimal infeasible part of the trace according to this strategy (e.g., with\n# FORWARDS a minimal infeasible prefix is found).\ncpa.predicate.refinement.cexTraceCheckDirection = ZIGZAG\n  enum:     [FORWARDS, BACKWARDS, ZIGZAG, LOOP_FREE_FIRST, RANDOM, LOWEST_AVG_SCORE,\n             HIGHEST_AVG_SCORE, LOOP_FREE_FIRST_BACKWARDS]\n\n# Actually compute an abstraction, otherwise just convert the interpolants to\n# BDDs as they are.\ncpa.predicate.refinement.doAbstractionComputation = false\n\n# dump all interpolation problems\ncpa.predicate.refinement.dumpInterpolationProblems = false\n\n# After each refinement, dump the newly found predicates.\ncpa.predicate.refinement.dumpPredicates = false\n\n# File name for the predicates dumped after refinements.\ncpa.predicate.refinement.dumpPredicatesFile = \"refinement%04d-predicates.prec\"\n\n# apply deletion-filter to the abstract counterexample, to get a minimal set\n# of blocks, before applying interpolation-based refinement\ncpa.predicate.refinement.getUsefulBlocks = false\n\n# Do a complete restart (clearing the reached set) after the refinement\ncpa.predicate.refinement.global.restartAfterRefinement = false\n\n# Instead of updating precision and arg we say that the refinement was not\n# successful after N times of refining. A real error state is not necessary\n# to be found. Use 0 for unlimited refinements (default).\ncpa.predicate.refinement.global.stopAfterNRefinements = 0\n\n# BlockFormulaStrategy for graph-like ARGs (e.g. Slicing Abstractions)\ncpa.predicate.refinement.graphblockformulastrategy = false\n\n# Enable/Disable adding partial state invariants into the PathFormulas\ncpa.predicate.refinement.includePartialInvariants = AbstractionPosition.BOTH\n\n# Use incremental search in counterexample analysis to find a minimal\n# infeasible part of the trace. This will typically lead to interpolants that\n# refer to this part only. The option cexTraceCheckDirection defines in which\n# order the blocks of the trace are looked at.\ncpa.predicate.refinement.incrementalCexTraceCheck = true\n\n# Max. number of prefixes to extract\ncpa.predicate.refinement.maxPrefixCount = 64\n\n# Max. length of feasible prefixes to extract from if at least one prefix was\n# already extracted\ncpa.predicate.refinement.maxPrefixLength = 1024\n\n# skip refinement if input formula is larger than this amount of bytes\n# (ignored if 0)\ncpa.predicate.refinement.maxRefinementSize = 0\n\n# sets the level of the pathformulas to use for abstraction. \n#   EDGE : Based on Pathformulas of every edge in ARGPath\n#   BLOCK: Based on Pathformulas at Abstractionstates\ncpa.predicate.refinement.newtonrefinement.abstractionLevel = EDGE\n  enum:     [BLOCK, EDGE]\n\n# Activate fallback to interpolation. Typically in case of a repeated\n# counterexample.\ncpa.predicate.refinement.newtonrefinement.fallback = false\n\n# use unsatisfiable Core in order to abstract the predicates produced while\n# NewtonRefinement\ncpa.predicate.refinement.newtonrefinement.infeasibleCore = true\n\n# use live variables in order to abstract the predicates produced while\n# NewtonRefinement\ncpa.predicate.refinement.newtonrefinement.liveVariables = true\n\n# use heuristic to extract predicates from the CFA statically on first\n# refinement\ncpa.predicate.refinement.performInitialStaticRefinement = false\n\n# Which predicates should be used as basis for the new precision that will be\n# attached to the refined part of the ARG:\n# ALL: Collect predicates from the complete ARG.\n# SUBGRAPH: Collect predicates from the removed subgraph of the ARG.\n# CUTPOINT: Only predicates from the cut-point's (pivot state) precision are\n# kept.\n# TARGET: Only predicates from the target state's precision are kept.\ncpa.predicate.refinement.predicateBasisStrategy = SUBGRAPH\n  enum:     [ALL, SUBGRAPH, TARGET, CUTPOINT]\n\n# which sliced prefix should be used for interpolation\ncpa.predicate.refinement.prefixPreference = PrefixSelector.NO_SELECTION\n\n# Do a complete restart (clearing the reached set) after N refinements. 0 to\n# disable, 1 for always.\ncpa.predicate.refinement.restartAfterRefinements = 0\n\n# Use a single SMT solver environment for all interpolation queries and keep\n# formulas pushed on solver stack between interpolation queries.\ncpa.predicate.refinement.reuseInterpolationEnvironment = false\n\n# In case we apply sequential interpolation, forward and backward directions\n# return valid interpolants. We can either choose one of the directions,\n# fallback to the other if one does not succeed, or even combine the\n# interpolants.\ncpa.predicate.refinement.sequentialStrategy = FWD\n  enum:     [FWD, FWD_FALLBACK, BWD, BWD_FALLBACK, CONJUNCTION, DISJUNCTION, WEIGHTED,\n             RANDOM]\n\n# During refinement, add all new predicates to the precisions of all abstract\n# states in the reached set.\ncpa.predicate.refinement.sharePredicates = false\n\n# slice block formulas, experimental feature!\ncpa.predicate.refinement.sliceBlockFormulas = false\n\n# split each arithmetic equality into two inequalities when extracting\n# predicates from interpolants\ncpa.predicate.refinement.splitItpAtoms = false\n\n# Stop after refining the n-th spurious counterexample and export that. If 0,\n# stop after finding the first spurious counterexample but before refinement.\n# If -1, never stop. If this option is used with a value different from -1,\n# option counterexample.export.alwaysUseImpreciseCounterexamples=true should\n# be set. Then, an actually infeasible counterexample will be handed to\n# export. So this option will also not work with additional counterexample\n# checks or similar, because these may reject the (infeasible)\n# counterexample.\ncpa.predicate.refinement.stopAfter = -1\n\n# Strategy how to interact with the intepolating prover. The analysis must\n# support the strategy, otherwise the result will be useless!\n# - SEQ_CPACHECKER: Generate an inductive sequence of interpolants by asking\n# the solver individually for each of them. This allows us to fine-tune the\n# queries with the option sequentialStrategy and is supported by all solvers.\n# - SEQ: Generate an inductive sequence of interpolants by asking the solver\n# for the whole sequence at once.\n# - TREE: Use the tree-interpolation feature of the solver to get\n# interpolants.\n# - TREE_WELLSCOPED: Return each interpolant for i={0..n-1} for the\n# partitions A=[lastFunctionEntryIndex..i] and\n# B=[0..lastFunctionEntryIndex-1]+[i+1..n]. Based on a tree-like scheme.\n# - TREE_NESTED: Use callstack and previous interpolants for next\n# interpolants (cf. 'Nested Interpolants').\n# - TREE_CPACHECKER: similar to TREE_NESTED, but the algorithm is taken from\n# 'Tree Interpolation in Vampire'\ncpa.predicate.refinement.strategy = SEQ_CPACHECKER\n  enum:     [SEQ, SEQ_CPACHECKER, TREE, TREE_WELLSCOPED, TREE_NESTED, TREE_CPACHECKER]\n\n# time limit for refinement (use milliseconds or specify a unit; 0 for\n# infinite)\ncpa.predicate.refinement.timelimit = 0ms\n\n# After a failed interpolation query, try to solve the formulas again with\n# different options instead of giving up immediately.\ncpa.predicate.refinement.tryAgainOnInterpolationError = true\n\n# When interpolation query fails, attempt to check feasibility of the current\n# counterexample without interpolation\ncpa.predicate.refinement.tryWithoutInterpolation = true\n\n# Use BDDs to simplify interpolants (removing irrelevant predicates)\ncpa.predicate.refinement.useBddInterpolantSimplification = false\n\n# use Newton-based Algorithm for the CPA-Refinement, experimental feature!\ncpa.predicate.refinement.useNewtonRefinement = false\n\n# Should the path invariants be created and used (potentially additionally to\n# the other invariants)\ncpa.predicate.refinement.usePathInvariants = false\n\n# use UCB predicates for the CPA-Refinement, experimental feature!\ncpa.predicate.refinement.useUCBRefinement = false\n\n# verify if the interpolants fulfill the interpolant properties\ncpa.predicate.refinement.verifyInterpolants = false\n\n# Enable the option to allow detecting the allocation type by type of the LHS\n# of the assignment, e.g. char *arr = malloc(size) is detected as char[size]\ncpa.predicate.revealAllocationTypeFromLhs = true\n\n# maximum blocksize before a satisfiability check is done\n# (non-negative number, 0 means never, if positive should be smaller than\n# blocksize)\ncpa.predicate.satCheck = 0\n\n# Enables sat checks at abstraction location.\n# Infeasible paths are already excluded by transfer relation and not later by\n# precision adjustment. This property is required in proof checking.\ncpa.predicate.satCheckAtAbstraction = false\n\n# Call 'simplify' on generated formulas.\ncpa.predicate.simplifyGeneratedPathFormulas = false\n\n# Whether to perform dynamic block encoding as part of each refinement\n# iteration\ncpa.predicate.slicingabstractions.dynamicBlockEncoding = false\n\n# Only slices the minimal amount of edges to guarantuee progress\ncpa.predicate.slicingabstractions.minimalslicing = false\n\n# Reduces the amount of solver calls by directely slicing some edgesthat are\n# mathematically proven to be infeasible in any case\ncpa.predicate.slicingabstractions.optimizeslicing = true\n\n# Whether to remove parts fo the ARG from which no target state is reachable\ncpa.predicate.slicingabstractions.removeSafeRegions = true\n\n# deprecated name for solver.cacheUnsatCores\ncpa.predicate.solver.cacheUnsatCores = true\n\n# deprecated name for solver.checkUFs\ncpa.predicate.solver.checkUFs = false\n\n# deprecated name for solver.enableLoggingInSolver\ncpa.predicate.solver.enableLoggingInSolver = false\n\n# deprecated name for solver.interpolationSolver\ncpa.predicate.solver.interpolationSolver = no default value\n  enum:     [OPENSMT, MATHSAT5, SMTINTERPOL, Z3, PRINCESS, BOOLECTOR, CVC4, CVC5,\n             YICES2, BITWUZLA]\n\n# deprecated name for solver.solver\ncpa.predicate.solver.solver = MATHSAT5\n  enum:     [OPENSMT, MATHSAT5, SMTINTERPOL, Z3, PRINCESS, BOOLECTOR, CVC4, CVC5,\n             YICES2, BITWUZLA]\n\n# C99 only defines the overflow of unsigned integer type.\ncpa.predicate.solver.ufCheckingProver.isSignedOverflowSafe = true\n\n# How often should we try to get a better evaluation?\ncpa.predicate.solver.ufCheckingProver.maxIterationNum = 5\n\n# which stop operator to use for predicate cpa (usually SEP should be used in\n# analysis). SEPNAA works the same as SEP, except that it Never stops At\n# Abstraction states. SEPNAA is used in bmc-IMC.properties for config\n# bmc-incremental-ABEl to keep exploring covered states.\ncpa.predicate.stop = \"SEP\"\n  allowed values: [SEP, SEPPCC, SEPNAA]\n\n# Use formula reporting states for strengthening.\ncpa.predicate.strengthenWithFormulaReportingStates = false\n\n# try to reuse old abstractions from file during strengthening\ncpa.predicate.strengthenWithReusedAbstractions = false\n\n# file that consists of old abstractions, to be used during strengthening\ncpa.predicate.strengthenWithReusedAbstractionsFile = \"abstractions.txt\"\n\n# The function used to model successful heap object allocation. This is only\n# used, when pointer analysis with UFs is enabled.\ncpa.predicate.successfulAllocFunctionName = \"__VERIFIER_successful_alloc\"\n\n# The function used to model successful heap object allocation with zeroing.\n# This is only used, when pointer analysis with UFs is enabled.\ncpa.predicate.successfulZallocFunctionName = \"__VERIFIER_successful_zalloc\"\n\n# whether to include the symbolic path formula in the coverage checks or do\n# only the fast abstract checks\ncpa.predicate.symbolicCoverageCheck = false\n\n# check satisfiability when a target state has been found\ncpa.predicate.targetStateSatCheck = false\n\n# deprecated name for cpa.predicate.invariants.timeForInvariantGeneration\ncpa.predicate.timeForInvariantGeneration = 10s\n\n# Whether to track values stored in variables of function-pointer type.\ncpa.predicate.trackFunctionPointers = true\n\n# deprecated name for cpa.predicate.invariants.useAllStrategies\ncpa.predicate.useAllStrategies = false\n\n# Use SMT arrays for encoding heap memory instead of uninterpreted function\n# (ignored if useByteArrayForHeap=true). This is more precise but may lead to\n# interpolation failures.\ncpa.predicate.useArraysForHeap = true\n\n# try to add some useful static-learning-like axioms for bitwise operations\n# (which are encoded as UFs): essentially, we simply collect all the numbers\n# used in bitwise operations, and add axioms like (0 & n = 0)\ncpa.predicate.useBitwiseAxioms = false\n\n# Use SMT byte array for encoding heap memory instead of uninterpreted\n# function. This is more close to c heap implementation but may be to\n# expensive.\ncpa.predicate.useByteArrayForHeap = false\n\n# Use an optimisation for constraint generation\ncpa.predicate.useConstraintOptimization = true\n\n# deprecated name for cpa.predicate.invariants.useGlobalInvariants\ncpa.predicate.useGlobalInvariants = true\n\n# For multithreaded programs this is an overapproximation of possible values\n# of shared variables.\ncpa.predicate.useHavocAbstraction = false\n\n# deprecated name for cpa.predicate.invariants.appendToPathFormula\ncpa.predicate.useInvariantsForAbstraction = false\n\n# Use regions for pointer analysis. So called Burstall&Bornat (BnB) memory\n# regions will be used for pointer analysis. BnB regions are based not only\n# on type, but also on structure field names. If the field is not accessed by\n# an address then it is placed into a separate region.\ncpa.predicate.useMemoryRegions = false\n\n# add special information to formulas about non-deterministic functions\ncpa.predicate.useNondetFlags = false\n\n# Insert tmp-variables for parameters at function-entries. The variables are\n# similar to return-variables at function-exit.\ncpa.predicate.useParameterVariables = false\n\n# Insert tmp-parameters for global variables at function-entries. The global\n# variables are also encoded with return-variables at function-exit.\ncpa.predicate.useParameterVariablesForGlobals = false\n\n# Use quantifiers when encoding heap accesses. This requires an SMT solver\n# that is capable of quantifiers (e.g. Z3 or PRINCESS).\ncpa.predicate.useQuantifiersOnArrays = false\n\n# deprecated name for cpa.predicate.invariants.useStrongInvariantsOnly\ncpa.predicate.useStrongInvariantsOnly = true\n\n# Do not follow states which can not syntactically lead to a target location\ncpa.property_reachability.noFollowBackwardsUnreachable = true\n\n# Qualified name for class which checks that the computed abstraction adheres\n# to the desired property.\ncpa.propertychecker.className = org.sosy_lab.cpachecker.pcc.propertychecker.DefaultPropertyChecker.class\n\n# List of parameters for constructor of propertychecker.className. Parameter\n# values are specified in the order the parameters are defined in the\n# respective constructor. Every parameter value is finished with \",\". The\n# empty string represents an empty parameter list.\ncpa.propertychecker.parameters = \"\"\n\n# Whether to consider constraints on program variables (e.g., x > 10) as\n# definitions)\ncpa.reachdef.constraintIsDef = false\n\n# which merge operator to use for ReachingDefCPA\ncpa.reachdef.merge = \"JOIN\"\n  allowed values: [SEP, JOIN, IGNORECALLSTACK]\n\n# which stop operator to use for ReachingDefCPA\ncpa.reachdef.stop = \"SEP\"\n  allowed values: [SEP, JOIN, IGNORECALLSTACK]\n\n# Do not report 'False' result, return UNKNOWN instead.  Useful for\n# incomplete analysis with no counterexample checking.\ncpa.reportFalseAsUnknown = false\n\n# which merge operator to use for SignCPA\ncpa.sign.merge = \"JOIN\"\n  allowed values: [SEP, JOIN]\n\n# which stop operator to use for SignCPA\ncpa.sign.stop = \"SEP\"\n  allowed values: [SEP, JOIN]\n\n# max length of a chain of states, -1 for infinity\ncpa.singleSuccessorCompactor.maxChainLength = -1\n\n# Apply AND- LBE transformation to loop transition relation.\ncpa.slicing.applyLBETransformation = true\n\n# Check target states reachability\ncpa.slicing.checkTargetStates = true\n\n# Filter lemmas by liveness\ncpa.slicing.filterByLiveness = true\n\n# Depth limit for the 'LEAST_REMOVALS' strategy.\ncpa.slicing.leastRemovalsDepthLimit = 2\n\n# Pre-run syntactic weakening\ncpa.slicing.preRunSyntacticWeakening = true\n\n# Whether to use a refinable slicing precision that starts with an empty\n# slice, or a statically computed, fixed slicing precision\ncpa.slicing.refinableSlice = false\n\n# Allow counterexamples that are valid only on the program slice. If you set\n# this to `false`, you may have to set takeEagerSlice=true to avoid failed\n# refinements. If this is set to true, the counterexample check won't work\n# (in general), so you have to turn it off.\ncpa.slicing.refinement.counterexampleCheckOnSlice = false\n\n# Which prefix provider to use? (give class name) If the package name starts\n# with 'org.sosy_lab.cpachecker.', this prefix can be omitted.\ncpa.slicing.refinement.prefixProvider = no default value\n\n# How to refine the slice:\n# - CEX_ASSUME_DEPS: Add the dependencies of all counterexample assume edges\n# to the slice.\n# - INFEASIBLE_PREFIX_ASSUME_DEPS: Find an infeasible prefix and add the\n# dependencies of all assume edges that are part of the infeasible prefix to\n# the slice. Requires a prefix provider\n# ('cpa.slicing.refinement.prefixProvider').\n# - CEX_FIRST_ASSUME_DEPS: Add the dependencies of the first counterexample\n# assume edges, that is not already part of the slice, to the slice.\n# - CEX_LAST_ASSUME_DEPS: Add the dependencies of the last counterexample\n# assume edges, that is not already part of the slice, to the slice.\ncpa.slicing.refinement.refineStrategy = CEX_ASSUME_DEPS\n  enum:     [CEX_ASSUME_DEPS, INFEASIBLE_PREFIX_ASSUME_DEPS, CEX_FIRST_ASSUME_DEPS,\n             CEX_LAST_ASSUME_DEPS]\n\n# What kind of restart to do after a successful refinement\ncpa.slicing.refinement.restartStrategy = PIVOT\n  enum:     [PIVOT, ROOT]\n\n# Use all assumptions of a target path as slicing criteria, not just the edge\n# to the target location.\ncpa.slicing.refinement.takeEagerSlice = false\n\n# Strategy for abstracting children during CEX weakening\ncpa.slicing.removalSelectionStrategy = ALL\n  enum:     [ALL, FIRST, RANDOM, LEAST_REMOVALS]\n\n# Time for loop generation before aborting.\n# (Use seconds or specify a unit; 0 for infinite)\ncpa.slicing.timeForLoopGeneration = 0s\n\n# Inductive weakening strategy\ncpa.slicing.weakeningStrategy = CEX\n  enum:     [SYNTACTIC, DESTRUCTIVE, CEX]\n\n# Enable GCC extension 'Arrays of Length Zero'.\ncpa.smg.GCCZeroLengthArray = false\n\n# Allocate memory on declaration of external variable\ncpa.smg.allocateExternalVariables = true\n\n# Array allocation functions\ncpa.smg.arrayAllocationFunctions = {\"calloc\"}\n\n# with this option enabled, a check for unreachable memory occurs whenever a\n# function returns, and not only at the end of the main function\ncpa.smg.checkForMemLeaksAtEveryFrameDrop = true\n\n# Crash on unknown array dereferences\ncpa.smg.crashOnUnknown = false\n\n# Deallocation functions\ncpa.smg.deallocationFunctions = {\"free\"}\n\n# with this option enabled, heap abstraction will be enabled.\ncpa.smg.enableHeapAbstraction = false\n\n# If this Option is enabled, failure of malloc is simulated\ncpa.smg.enableMallocFail = true\n\n# Filename format for SMG graph dumps\ncpa.smg.exportSMG.file = \"smg/smg-%s.dot\"\n\n# Describes when SMG graphs should be dumped.\ncpa.smg.exportSMGwhen = NEVER\n  enum:     [NEVER, LEAF, INTERESTING, EVERY]\n\n# Functions which indicate on external allocated memory\ncpa.smg.externalAllocationFunction = {\"ext_allocation\"}\n\n# Default size of externally allocated memory\ncpa.smg.externalAllocationSize = Integer.MAX_VALUE\n\n# Allocation size of memory that cannot be calculated.\ncpa.smg.guessSize = 2\n\n# Size of memory that cannot be calculated will be guessed.\ncpa.smg.guessSizeOfUnknownMemorySize = false\n\n# Handle external variables with incomplete type (extern int array[]) as\n# external allocation\ncpa.smg.handleIncompleteExternalVariableAsExternalAllocation = false\n\n# with this option enabled, memory that is not freed before the end of main\n# is reported as memleak even if it is reachable from local variables in main\ncpa.smg.handleNonFreedMemoryInMainAsMemLeak = true\n\n# Handle unknown dereference as safe and check error based on error\n# predicate, depends on trackPredicates\ncpa.smg.handleUnknownDereferenceAsSafe = false\n\n# Sets how unknown functions are handled.\ncpa.smg.handleUnknownFunctions = STRICT\n  enum:     [STRICT, ASSUME_SAFE, ASSUME_EXTERNAL_ALLOCATED]\n\n# Perform merge SMGStates by SMGJoin on ends of code block. Works with\n# 'merge=JOIN'\ncpa.smg.joinOnBlockEnd = true\n\n# Memory allocation functions\ncpa.smg.memoryAllocationFunctions = {\"malloc\", \"__kmalloc\", \"kmalloc\", \"realloc\"}\n\n# Size parameter of memory allocation functions\ncpa.smg.memoryAllocationFunctionsSizeParameter = 0\n\n# Position of element size parameter for array allocation functions\ncpa.smg.memoryArrayAllocationFunctionsElemSizeParameter = 1\n\n# Position of number of element parameter for array allocation functions\ncpa.smg.memoryArrayAllocationFunctionsNumParameter = 0\n\n# Determines if memory errors are target states\ncpa.smg.memoryErrors = true\n\n# which merge operator to use for the SMGCPA\ncpa.smg.merge = \"SEP\"\n  allowed values: [SEP, JOIN]\n\n# export interpolant smgs for every path interpolation to this path template\ncpa.smg.refinement.exportInterpolantSMGs = \"smg/interpolation-%d/%s\"\n\n# when to export the interpolation tree\n# NEVER:   never export the interpolation tree\n# FINAL:   export the interpolation tree once after each refinement\n# ALWAYS:  export the interpolation tree once after each interpolation, i.e.\n# multiple times per refinement\ncpa.smg.refinement.exportInterpolationTree = \"NEVER\"\n  allowed values: [NEVER, FINAL, ALWAYS]\n\n# export interpolant smgs for every path interpolation to this path template\ncpa.smg.refinement.exportRefinementSMGs = \"smg/refinement-%d/smg-%s\"\n\n# export interpolation trees to this file template\ncpa.smg.refinement.interpolationTreeExportFile = \"interpolationTree.%d-%d.dot\"\n\n# Sets the level of runtime checking: NONE, HALF, FULL\ncpa.smg.runtimeCheck = NONE\n  enum:     [FORCED, NONE, HALF, FULL]\n\n# Patterns of unknown functions which are always considered as safe\n# functions, i.e., free of memory-related side-effects.\ncpa.smg.safeUnknownFunctionsPatterns = {\"abort\"}\n\n# which stop operator to use for the SMGCPA\ncpa.smg.stop = \"SEP\"\n  allowed values: [SEP, NEVER, END_BLOCK]\n\n# Enable track predicates for possible memory safety error on SMG state\ncpa.smg.trackErrorPredicates = false\n\n# Enable track predicates on SMG state\ncpa.smg.trackPredicates = false\n\n# Emit messages when we encounter non-target undefined behavior\ncpa.smg.unknownOnUndefined = true\n\n# Allow SMG to check predicates\ncpa.smg.verifyPredicates = false\n\n# Allocation functions which set memory to zero\ncpa.smg.zeroingMemoryAllocation = {\"calloc\", \"kzalloc\"}\n\n# Enable GCC extension 'Arrays of Length Zero'.\ncpa.smg2.GCCZeroLengthArray = false\n\n# aborts the analysis for a non-concrete (this includes symbolic values)\n# memory allocation of any kind.\ncpa.smg2.abortOnNonConcreteMemorySize = true\n\n# Periodically removes concrete values from the memory model and replaces\n# them with symbolic values. Only the newest concrete values above this\n# threshold are removed. For negative numbers this option is ignored. Note: 0\n# also removes the null value, reducing impacting null dereference or free\n# soundness. Currently only supported for given value 0.\ncpa.smg2.abstraction.abstractConcreteValuesAboveThreshold = -1\n\n# If heap values are to be abstracted based on CEGAR.\ncpa.smg2.abstraction.abstractHeapValues = false\n\n# Abstraction of all detected linked lists at loop heads.\ncpa.smg2.abstraction.abstractLinkedLists = true\n\n# Abstraction of program variables via CEGAR.\ncpa.smg2.abstraction.abstractProgramVariables = false\n\n# restrict abstraction computations to branching points\ncpa.smg2.abstraction.alwaysAtBranch = false\n\n# restrict abstraction computations to function calls/returns\ncpa.smg2.abstraction.alwaysAtFunction = false\n\n# restrict abstraction computations to join points\ncpa.smg2.abstraction.alwaysAtJoin = false\n\n# If enabled, abstraction computations at loop-heads are enabled. List\n# abstraction has to be enabled for this.\ncpa.smg2.abstraction.alwaysAtLoop = false\n\n# threshold for level of determinism, in percent, up-to which abstraction\n# computations are performed (and iteration threshold was reached)\ncpa.smg2.abstraction.determinismThreshold = 85\n\n# toggle memory sensitive liveness abstraction. Liveness abstraction is\n# supposed to simply abstract all variables away (invalidating memory) when\n# unused, even if there is valid outside pointers on them. With this option\n# enabled, it is first checked if there is a valid address still pointing to\n# the variable before removing it. Liveness abstraction might be unsound\n# without this option.\ncpa.smg2.abstraction.doEnforcePointerSensitiveLiveness = true\n\n# toggle liveness abstraction. Is independent of CEGAR, but dependent on the\n# CFAs liveness variables being tracked. Might be unsound for stack-based\n# memory structures like arrays.\ncpa.smg2.abstraction.doLivenessAbstraction = true\n\n# skip abstraction computations until the given number of iterations are\n# reached, after that decision is based on then current level of determinism,\n# setting the option to -1 always performs abstraction computations\ncpa.smg2.abstraction.iterationThreshold = -1\n\n# The minimum list segments that are needed for abstraction may be increased\n# during the analysis based on a heuristic in fixed sized loops. This is the\n# maximum increase that is allowed. E.g. all lists with the length given here\n# are abstracted in any case. If you want to prevent dynamic increase of list\n# abstraction min threshold set this to the same value as\n# listAbstractionMinimumLengthThreshold.\ncpa.smg2.abstraction.listAbstractionMaximumIncreaseLengthThreshold = 6\n\n# The minimum list segments directly following each other with the same value\n# needed to abstract them.Minimum is 2.\ncpa.smg2.abstraction.listAbstractionMinimumLengthThreshold = 4\n\n# restrict liveness abstractions to nodes with more than one entering and/or\n# leaving edge\ncpa.smg2.abstraction.onlyAtNonLinearCFA = false\n\n# Periodically removes unused constraints from the state.\ncpa.smg2.abstraction.removeUnusedConstraints = false\n\n# Allocate memory on declaration of external variable\ncpa.smg2.allocateExternalVariables = true\n\n# Array allocation functions\ncpa.smg2.arrayAllocationFunctions = {\"calloc\"}\n\n# Use equality assumptions to assign values (e.g., (x == 0) => x = 0)\ncpa.smg2.assignEqualityAssumptions = true\n\n# Whether to perform caching of constraint satisfiability results\ncpa.smg2.cache = true\n\n# Whether to use subset caching\ncpa.smg2.cacheSubsets = false\n\n# Whether to use superset caching\ncpa.smg2.cacheSupersets = false\n\n# If this Option is enabled, C function atexit() will return a succeeding and\n# failing registration for each registration. Otherwise only succeeding.\ncpa.smg2.canAtexitFail = false\n\n# with this option enabled, memory addresses (pointers) are transformed into\n# a numeric assumption upon casting the pointer to a number. This assumption\n# can be returned to a proper pointer by casting it back. This enables\n# numeric operations beyond pointer arithmetics, but loses precision for\n# comparisons/assumptions, as the numeric assumption is static. May be\n# unsound!\ncpa.smg2.castMemoryAddressesToNumeric = false\n\n# with this option enabled, a check for unreachable memory occurs whenever a\n# function returns, and not only at the end of the main function\ncpa.smg2.checkForMemLeaksAtEveryFrameDrop = true\n\n# Maximum amount of concrete assignments before the assigning is aborted. The\n# last offset is then once treated as option\n# overapproximateSymbolicOffsetsAsFallback specifies.\ncpa.smg2.concreteValueForSymbolicOffsetsAssignmentMaximum = 300\n\n# Crash on unknown value when creating constraints of any form.\ncpa.smg2.crashOnUnknownInConstraint = false\n\n# Deallocation functions\ncpa.smg2.deallocationFunctions = {\"free\"}\n\n# with this option enabled, heap abstraction will be enabled.\ncpa.smg2.enableHeapAbstraction = false\n\n# If this Option is enabled, failure of malloc is simulated\ncpa.smg2.enableMallocFail = true\n\n# Filename format for SMG graph dumps\ncpa.smg2.exportSMG.file = \"smg/smg-%s.dot\"\n\n# Describes when SMG graphs should be dumped.\ncpa.smg2.exportSMGwhen = NEVER\n  enum:     [NEVER, LEAF, INTERESTING, EVERY]\n\n# Functions which indicate on external allocated memory\ncpa.smg2.externalAllocationFunction = {\"ext_allocation\"}\n\n# Default size of externally allocated memory\ncpa.smg2.externalAllocationSize = Integer.MAX_VALUE\n\n# If this Option is enabled, all symbolic offsets used when writing to memory\n# are evaluated into all possible concrete values by an SMT solver. This\n# might be very expensive, as all possible combinations of values for the\n# symbolic offsets are concretely evaluated. May not be used together with\n# option overapproximateForSymbolicWrite.\ncpa.smg2.findConcreteValuesForSymbolicOffsets = false\n\n# Allocation size of memory that cannot be calculated.\ncpa.smg2.guessSize = BigInteger.valueOf(2)\n\n# Size of memory that cannot be calculated will be guessed.\ncpa.smg2.guessSizeOfUnknownMemorySize = false\n\n# Handle external variables with incomplete type (extern int array[]) as\n# external allocation\ncpa.smg2.handleIncompleteExternalVariableAsExternalAllocation = false\n\n# with this option enabled, memory that is not freed before the end of main\n# is reported as memleak even if it is reachable from local variables in main\ncpa.smg2.handleNonFreedMemoryInMainAsMemLeak = true\n\n# Handle unknown dereference as safe and check error based on error\n# predicate, depends on trackPredicates\ncpa.smg2.handleUnknownDereferenceAsSafe = false\n\n# Sets how unknown functions are handled.\ncpa.smg2.handleUnknownFunctions = STRICT\n  enum:     [STRICT, ASSUME_SAFE, ASSUME_EXTERNAL_ALLOCATED]\n\n# If this option is enabled, a memory allocation (e.g. malloc or array\n# declaration) for unknown memory sizes does not abort, but also does not\n# create any memory.\ncpa.smg2.handleUnknownMemoryAllocation = STOP_ANALYSIS\n  enum:     [IGNORE, MEMORY_ERROR, STOP_ANALYSIS]\n\n# if there is an assumption like (x!=0), this option sets unknown\n# (uninitialized) variables to 1L, when the true-branch is handled.\ncpa.smg2.initAssumptionVars = false\n\n# get an initial precision from file\ncpa.smg2.initialPrecisionFile = no default value\n\n# get an initial precision from a predicate precision file\ncpa.smg2.initialPredicatePrecisionFile = no default value\n\n# Perform merge SMGStates by SMGJoin on ends of code block. Works with\n# 'merge=JOIN'\ncpa.smg2.joinOnBlockEnd = false\n\n# If this option is enabled, a call to malloc with value zero results in a\n# return value that is equal to zero. If this option is disabled, a non-zero\n# memory section that may not be accessed but freed is returned.\ncpa.smg2.mallocZeroReturnsZero = false\n\n# Memory allocation functions\ncpa.smg2.memoryAllocationFunctions = {\"malloc\", \"__kmalloc\", \"kmalloc\"}\n\n# Size parameter of memory allocation functions\ncpa.smg2.memoryAllocationFunctionsSizeParameter = 0\n\n# Position of element size parameter for array allocation functions\ncpa.smg2.memoryArrayAllocationFunctionsElemSizeParameter = 1\n\n# Position of number of element parameter for array allocation functions\ncpa.smg2.memoryArrayAllocationFunctionsNumParameter = 0\n\n# Determines if memory errors are target states\ncpa.smg2.memoryErrors = true\n\n# which merge operator to use for the SMGCPA\ncpa.smg2.merge = \"SEP\"\n  allowed values: [SEP]\n\n# Whether to perform SAT checks only for the last added constraint\ncpa.smg2.minimalSatCheck = true\n\n# Assume that variables used only in a boolean context are either zero or\n# one.\ncpa.smg2.optimizeBooleanVariables = true\n\n# If this Option is enabled, all values of a memory region that is written or\n# read with a symbolic offset are overapproximated. I.e. when writing to a\n# memory region, all previous values are deleted and the memory region is\n# overapproximated so that only unknown values are in the memory region after\n# the write. When reading, all possible reads are evaluated. Can not be used\n# at the same time as option findConcreteValuesForSymbolicOffsets.\ncpa.smg2.overapproximateSymbolicOffsets = false\n\n# If this Option is enabled, all values of a memory region that is written to\n# with a symbolic and non-unique offset in symbolically sized memory are\n# deleted and the value itself is overapproximated to unknown in the memory\n# region.\ncpa.smg2.overapproximateValuesForSymbolicSize = false\n\n# with this option enabled, we try to gather information on memory reads from\n# values that are overlapping but not exactly fitting to the read parameters.\n# Example: int value = 1111; char a = (char)((char[])&value)[1];\ncpa.smg2.preciseSMGRead = true\n\n# target file to hold the exported precision\ncpa.smg2.precisionFile = no default value\n\n# whether or not to use heuristic to avoid similar, repeated refinements\ncpa.smg2.refinement.avoidSimilarRepeatedRefinement = false\n\n# Which base precision should be used for a new precision? ALL: During\n# refinement, collect precisions from the complete ARG. SUBGRAPH: During\n# refinement, keep precision from all removed parts (subgraph) of the ARG.\n# CUTPOINT: Only the cut-point's precision is kept. TARGET: Only the target\n# state's precision is kept.\ncpa.smg2.refinement.basisStrategy = SUBGRAPH\n  enum:     [ALL, SUBGRAPH, TARGET, CUTPOINT]\n\n# whether or not to do lazy-abstraction\ncpa.smg2.refinement.doLazyAbstraction = true\n\n# whether to perform (more precise) edge-based interpolation or (more\n# efficient) path-based interpolation\ncpa.smg2.refinement.performEdgeBasedInterpolation = true\n\n# whether or not to do lazy-abstraction\ncpa.smg2.refinement.restart = PIVOT\n  enum:     [ROOT, PIVOT, COMMON]\n\n# Resolve definite assignments\ncpa.smg2.resolveDefinites = true\n\n# Sets the level of runtime checking: NONE, HALF, FULL\ncpa.smg2.runtimeCheck = NONE\n  enum:     [FORCED, NONE, HALF, FULL]\n\n# Which unknown function are always considered as safe functions, i.e., free\n# of memory-related side-effects?\ncpa.smg2.safeUnknownFunctions = {\"abort\"}\n\n# When to check the satisfiability of constraints\ncpa.smg2.satCheckStrategy = AT_ASSUME\n  enum:     [AT_ASSUME, AT_TARGET]\n\n# which stop operator to use for the SMGCPA\ncpa.smg2.stop = \"SEP\"\n  allowed values: [SEP, NEVER, END_BLOCK]\n\n# Enable track predicates for possible memory safety error on SMG state\ncpa.smg2.trackErrorPredicates = false\n\n# Enable track predicates on SMG state\ncpa.smg2.trackPredicates = false\n\n# Treat symbolic values as unknowns and assign new concrete values to them.\ncpa.smg2.treatSymbolicValuesAsUnknown = false\n\n# Emit messages when we encounter non-target undefined behavior\ncpa.smg2.unknownOnUndefined = true\n\n# Allocation functions which set memory to zero\ncpa.smg2.zeroingMemoryAllocation = {\"calloc\", \"kzalloc\"}\n\n# set this to true when you only want to do a code analysis. If StatisticsCPA\n# is combined with other CPAs to do queries use false.\ncpa.statistics.analysis = true\n\n# which merge operator to use for StatisticsCPA? Ignored when analysis is set\n# to true\ncpa.statistics.mergeSep = \"sep\"\n  allowed values: [sep, join]\n\n# count the number of traversed arithmetic operations.\ncpa.statistics.metric.arithmeticOperationCount = true\n\n# count the number of traversed variable definitions with array type.\ncpa.statistics.metric.arrayVariablesCount = true\n\n# count the number of traversed assume statements.\ncpa.statistics.metric.assumeCount = true\n\n# count the number of traversed bitwise operations.\ncpa.statistics.metric.bitwiseOperationCount = true\n\n# count the number of traversed edges with more then one outgoing edge.\ncpa.statistics.metric.branchCount = true\n\n# count the number of traversed dereference operations.\ncpa.statistics.metric.dereferenceCount = true\n\n# count the number of traversed variable definitions with floating type\n# (float or double).\ncpa.statistics.metric.floatVariablesCount = true\n\n# count the number of traversed function calls.\ncpa.statistics.metric.functionCallCount = true\n\n# count the number of traversed function definitions.\ncpa.statistics.metric.functionDefCount = true\n\n# count the number of traversed global variable definitions.\ncpa.statistics.metric.globalVariablesCount = true\n\n# count the number of traversed gotos.\ncpa.statistics.metric.gotoCount = true\n\n# count the number of traversed variable definitions with integer type.\ncpa.statistics.metric.integerVariablesCount = true\n\n# count the number of traversed jumps.\ncpa.statistics.metric.jumpCount = true\n\n# count the number of traversed local variable definitions.\ncpa.statistics.metric.localVariablesCount = true\n\n# count the number of traversed loops.\ncpa.statistics.metric.loopCount = true\n\n# count the number of traversed nodes.\ncpa.statistics.metric.nodeCount = true\n\n# count the number of traversed variable definitions with pointer type.\ncpa.statistics.metric.pointerVariablesCount = true\n\n# count the number of traversed variable definitions with a complex structure\n# type.\ncpa.statistics.metric.structVariablesCount = true\n\n# target file to hold the statistics\ncpa.statistics.statisticsCPAFile = no default value\n\n# Which refinement algorithm to use? (give class name, required for\n# termination algorithm with CEGAR) If the package name starts with\n# 'org.sosy_lab.cpachecker.', this prefix can be omitted.\ncpa.termination.refiner = no default value\n\n# Simple thread analysis from theory paper\ncpa.thread.simpleMode = false\n\n# The case when the same thread is created several times we do not support.We\n# may skip or fail in this case.\ncpa.thread.skipTheSameThread = false\n\n# The case when the same thread is created several times we do not support.We\n# may try to support it with self-parallelizm.\ncpa.thread.supportSelfCreation = false\n\n# allow assignments of a new thread to the same left-hand-side as an existing\n# thread.\ncpa.threading.allowMultipleLHS = false\n\n# the maximal number of parallel threads, -1 for infinite. When combined with\n# 'useClonedFunctions=true', we need at least N cloned functions. The option\n# 'cfa.cfaCloner.numberOfCopies' should be set to N.\ncpa.threading.maxNumberOfThreads = 5\n\n# in case of witness validation we need to check all possible function calls\n# of cloned CFAs.\ncpa.threading.useAllPossibleClones = false\n\n# atomic locks are used to simulate atomic statements, as described in the\n# rules of SV-Comp.\ncpa.threading.useAtomicLocks = true\n\n# do not use the original functions from the CFA, but cloned ones. See\n# cfa.postprocessing.CFACloner for detail.\ncpa.threading.useClonedFunctions = true\n\n# local access locks are used to avoid expensive interleaving, if a thread\n# only reads and writes its own variables.\ncpa.threading.useLocalAccessLocks = true\n\n# The max amount of refinements for the trace abstraction algorithm. Setting\n# it to 0 leads to an analysis of the ARG without executing any refinements.\n# This is used for debugging purposes.\ncpa.traceabstraction.refinementStrategy.maxRefinementIterations = -1\n\n# which merge operator to use for UninitializedVariablesCPA?\ncpa.uninitvars.merge = \"sep\"\n  allowed values: [sep, join]\n\n# print warnings during analysis when uninitialized variables are used\ncpa.uninitvars.printWarnings = \"true\"\n\n# which stop operator to use for UninitializedVariablesCPA?\ncpa.uninitvars.stop = \"sep\"\n  allowed values: [sep, join]\n\n# functions, which stops analysis\ncpa.usage.abortfunctions = {}\n\n# functions, which are used to bind variables (like list elements are binded\n# to list variable)\ncpa.usage.binderFunctions = {}\n\n# export counterexample core as text file\ncpa.usage.export.witnessTemplate = \"witness.%s.graphml\"\n\n# path to write results\ncpa.usage.falseUnsafesOutput = \"FalseUnsafes\"\n\n# if a file do not exist, do not include the corresponding edge\ncpa.usage.filterMissedFiles = true\n\n# filtered unsafes, which can not be removed using precision, may be hidden\ncpa.usage.hideFilteredUnsafes = false\n\n# The functions, which cannot be executed in parallel with themselves\ncpa.usage.notSelfParallelFunctions = new HashSet<>()\n\n# path to write results\ncpa.usage.output = \"unsafe_rawdata\"\n\n# all variables should be printed to the one file or to the different\ncpa.usage.outputType = KLEVER\n  enum:     [ETV, KLEVER, KLEVER_OLD]\n\n# The way how to identify two paths as equal\ncpa.usage.pathEquality = CFANodeId\n  enum:     [ARGStateId, CFANodeId]\n\n# The value of marked unsafes, after which the precision should be cleaned\ncpa.usage.precisionReset = Integer.MAX_VALUE\n\n# print all unsafe cases in report\ncpa.usage.printFalseUnsafes = false\n\n# output only true unsafes\ncpa.usage.printOnlyTrueUnsafes = false\n\n# print found unsafes in case of unknown verdict\ncpa.usage.printUnsafesIfUnknown = true\n\n# The order of refinement blocks\ncpa.usage.refinementChain = no default value\n\n# use single file for output or dump every error trace to its own file\ncpa.usage.singleFileOutput = false\n\n# The functions, which are executed in one thread\ncpa.usage.singleThreadFunctions = new HashSet<>()\n\n# functions, which we don't analize\ncpa.usage.skippedfunctions = {}\n\n# variables, which will be filtered by function location\ncpa.usage.skippedvariables.byFunction = {}\n\n# variables, which will be filtered by function prefix\ncpa.usage.skippedvariables.byFunctionPrefix = {}\n\n# variables, which will be filtered by its name\ncpa.usage.skippedvariables.byName = {}\n\n# variables, which will be filtered by its name prefix\ncpa.usage.skippedvariables.byNamePrefix = {}\n\n# variables, which will be filtered by its type\ncpa.usage.skippedvariables.byType = {}\n\n# clean all ARG or try to reuse some parts of it (memory consuming)\ncpa.usage.totalARGCleaning = true\n\n# ignore unsafes only with empty callstacks\ncpa.usage.unsafedetector.ignoreEmptyLockset = true\n\n# A name of interrupt lock for checking deadlock free\ncpa.usage.unsafedetector.intLock = no default value\n\n# defines what is unsafe\ncpa.usage.unsafedetector.unsafeMode = RACE\n  enum:     [RACE, DEADLOCKCIRCULAR, DEADLOCKDISPATCH]\n\n# functions, which are marked as write access\ncpa.usage.writeAccessFunctions = {}\n\n# which merge operator to use for ValidVarsCPA\ncpa.validVars.merge = \"JOIN\"\n  allowed values: [SEP, JOIN]\n\n# restrict abstraction computations to branching points\ncpa.value.abstraction.alwaysAtBranch = false\n\n# restrict abstraction computations to function calls/returns\ncpa.value.abstraction.alwaysAtFunction = false\n\n# restrict abstraction computations to join points\ncpa.value.abstraction.alwaysAtJoin = false\n\n# restrict abstraction computations to loop heads\ncpa.value.abstraction.alwaysAtLoop = false\n\n# threshold for level of determinism, in percent, up-to which abstraction\n# computations are performed (and iteration threshold was reached)\ncpa.value.abstraction.determinismThreshold = 85\n\n# toggle liveness abstraction\ncpa.value.abstraction.doLivenessAbstraction = false\n\n# skip abstraction computations until the given number of iterations are\n# reached, after that decision is based on then current level of determinism,\n# setting the option to -1 always performs abstraction computations\ncpa.value.abstraction.iterationThreshold = -1\n\n# restrict liveness abstractions to nodes with more than one entering and/or\n# leaving edge\ncpa.value.abstraction.onlyAtNonLinearCFA = false\n\n# Allow the given extern functions and interpret them as pure functions\n# although the value analysis does not support their semantics and this can\n# produce wrong results.\ncpa.value.allowedUnsupportedFunctions = {}\n\n# Use equality assumptions to assign values (e.g., (x == 0) => x = 0)\ncpa.value.assignEqualityAssumptions = true\n\n# configure when to export loop invariants\ncpa.value.exportLoopInvariants = IF_TRUE\n  enum:     [ALWAYS, IF_NOT_FALSE, IF_TRUE, IF_UNKNOWN]\n\n# Fixed set of values for function calls to VERIFIER_nondet_*. Does only\n# work, if ignoreFunctionValueExceptRandom is enabled \ncpa.value.functionValuesForRandom = no default value\n\n# Track or not function pointer values\ncpa.value.ignoreFunctionValue = true\n\n# If 'ignoreFunctionValue' is set to true, this option allows to provide a\n# fixed set of values in the TestComp format. It is used for function-calls\n# to calls of VERIFIER_nondet_*. The file is provided via the option\n# functionValuesForRandom \ncpa.value.ignoreFunctionValueExceptRandom = false\n\n# if there is an assumption like (x!=0), this option sets unknown\n# (uninitialized) variables to 1L, when the true-branch is handled.\ncpa.value.initAssumptionVars = false\n\n# get an initial precision from file\ncpa.value.initialPrecisionFile = no default value\n\n# get an initial precision from a predicate precision file\ncpa.value.initialPredicatePrecisionFile = no default value\n\n# apply optimizations based on equality of input interpolant and candidate\n# interpolant\ncpa.value.interpolation.applyItpEqualityOptimization = true\n\n# apply optimizations based on CFA edges with only variable-renaming\n# semantics\ncpa.value.interpolation.applyRenamingOptimization = true\n\n# apply optimizations based on infeasibility of suffix\ncpa.value.interpolation.applyUnsatSuffixOptimization = true\n\n# whether or not to manage the callstack, which is needed for BAM\ncpa.value.interpolation.manageCallstack = true\n\n# Enable invariants that use  an arithmetic operator(linear invariants are\n# enabled separately)\ncpa.value.invExport.exportArithmetic = true\n\n# Enable to export invariants that include two variables\ncpa.value.invExport.exportBinary = true\n\n# Enable invariants that use a bit operator\ncpa.value.invExport.exportBitops = true\n\n# Enable to export linear equalities or inequalities over variables, e.g., ax\n# + by + c = 0, ax + bx + c <= 0, ax + bx + c >= 0, or ax + by + cy + d = 0\ncpa.value.invExport.exportLinear = true\n\n# Enable invariants that relate (compare) two variables\ncpa.value.invExport.exportRelational = true\n\n# Enable invariants that use a shift operator, note that additionally\n# exportBitops must be enabled\ncpa.value.invExport.exportShiftops = true\n\n# Enable to export invariants that include three variables, currently only\n# effective if exportLinear is enabled, too\ncpa.value.invExport.exportTernary = true\n\n# Enable to export invariants on single variables\ncpa.value.invExport.exportUnary = true\n\n# enable if loop invariant export should consider context\ncpa.value.invExport.invariantsContextSensitive = true\n\n# target file to hold the exported loop invariants\ncpa.value.loopInvariantsFile = no default value\n\n# which merge operator to use for ValueAnalysisCPA\ncpa.value.merge = \"SEP\"\n  allowed values: [SEP, JOIN]\n\n# Assume that variables used only in a boolean context are either zero or\n# one.\ncpa.value.optimizeBooleanVariables = true\n\n# target file to hold the exported precision\ncpa.value.precisionFile = no default value\n\n# whether or not to add assumptions to counterexamples, e.g., for supporting\n# counterexample checks\ncpa.value.refinement.addAssumptionsToCex = true\n\n# whether or not to use heuristic to avoid similar, repeated refinements\ncpa.value.refinement.avoidSimilarRepeatedRefinement = false\n\n# Which base precision should be used for a new precision? ALL: During\n# refinement, collect precisions from the complete ARG. SUBGRAPH: During\n# refinement, keep precision from all removed parts (subgraph) of the ARG.\n# CUTPOINT: Only the cut-point's precision is kept. TARGET: Only the target\n# state's precision is kept.\ncpa.value.refinement.basisStrategy = SUBGRAPH\n  enum:     [ALL, SUBGRAPH, TARGET, CUTPOINT]\n\n# completely disable the tracking of found error paths in the refiner, i.e.,\n# disable the detection of repeated counterexamples\ncpa.value.refinement.disableErrorPathTracking = false\n\n# whether or not to do lazy-abstraction\ncpa.value.refinement.doLazyAbstraction = true\n\n# when to export the interpolation tree\n# NEVER:   never export the interpolation tree\n# FINAL:   export the interpolation tree once after each refinement\n# ALWAYS:  export the interpolation tree once after each interpolation, i.e.\n# multiple times per refinement\ncpa.value.refinement.exportInterpolationTree = \"NEVER\"\n  allowed values: [NEVER, FINAL, ALWAYS]\n\n# export interpolation trees to this file template\ncpa.value.refinement.interpolationTreeExportFile = \"interpolationTree.%d-%d.dot\"\n\n# heuristic to sort targets based on the quality of interpolants derivable\n# from them\ncpa.value.refinement.itpSortedTargets = false\n\n# File to which path constraints should be written.\ncpa.value.refinement.pathConstraintsFile = \"Counterexample.%d.symbolic-trace.txt\"\n\n# whether or not to perform path slicing before interpolation\ncpa.value.refinement.pathSlicing = true\n\n# whether to perform (more precise) edge-based interpolation or (more\n# efficient) path-based interpolation\ncpa.value.refinement.performEdgeBasedInterpolation = true\n\n# which prefix of an actual counterexample trace should be used for\n# interpolation\ncpa.value.refinement.prefixPreference = [PrefixPreference.DOMAIN_MIN, PrefixPreference.LENGTH_MIN]\n\n# whether or not to do lazy-abstraction\ncpa.value.refinement.restart = PIVOT\n  enum:     [ROOT, PIVOT, COMMON]\n\n# instead of reporting a repeated counter-example, search and refine another\n# error-path for the same target-state.\ncpa.value.refinement.searchForFurtherErrorPaths = false\n\n# store all refined paths\ncpa.value.refinement.storeAllRefinedPaths = false\n\n# if this option is set to false, constraints are never kept\ncpa.value.refinement.trackConstraints = true\n\n# whether to use the top-down interpolation strategy or the bottom-up\n# interpolation strategy\ncpa.value.refinement.useTopDownInterpolationStrategy = true\n\n# Whether to write symbolic trace (including path constraints) for found\n# erexamples\ncpa.value.refinement.writePathConstraints = true\n\n# Overall timelimit for computing initial value precision from given\n# predicate precision(use seconds or specify a unit; 0 for infinite)\ncpa.value.reuse.precision.predicate.adaptionLimit = 0ns\n\n# also consider other binary operators then ==, !== when considering control\n# dependencies while adapting predicate precision\ncpa.value.reuse.precision.predicate.includeControlNonEquiv = false\n\n# comma-separated list of files with property specifications that should be\n# considered when determining the relevant edges for predicate precision\n# adaption\ncpa.value.reuse.precision.predicate.relevantProperties = []\n\n# which strategy to use to convert predicate to value precision\ncpa.value.reuse.precision.predicate.strategy = CONVERT_ONLY\n  enum:     [CONVERT_ONLY, CONVERT_AND_ADD_FLOW_BACKWARD,\n             CONVERT_AND_ADD_FLOW_BIDIRECTED]\n\n# also consider control dependencies during adaption of predicate precision\ncpa.value.reuse.precision.predicate.useControl = false\n\n# which stop operator to use for ValueAnalysisCPA\ncpa.value.stop = \"SEP\"\n  allowed values: [SEP, JOIN, NEVER, EQUALS]\n\n# Default size of arrays whose length can't be determined.\ncpa.value.symbolic.defaultArraySize = 20\n\n# If this option is set to true, an own symbolic identifier is assigned to\n# each array slot when handling non-deterministic arrays of fixed length. If\n# the length of the array can't be determined, it won't be handled in either\n# cases.\ncpa.value.symbolic.handleArrays = false\n\n# Whether to handle non-deterministic pointers in symbolic value analysis.\ncpa.value.symbolic.handlePointers = true\n\n# If this option is set to true, an own symbolic identifier is assigned to\n# each struct member when handling non-deterministic structs.\ncpa.value.symbolic.handleStructs = true\n\n# Whether to try to not use any constraints in refinement\ncpa.value.symbolic.refinement.avoidConstraints = true\n\n# The refinement strategy to use\ncpa.value.symbolic.refinement.strategy = CONSTRAINTS_FIRST\n  enum:     [CONSTRAINTS_FIRST, VALUES_FIRST, ALTERNATING, VALUES_ONLY]\n\n# Whether to simplify symbolic expressions, if possible.\ncpa.value.symbolic.simplifySymbolics = false\n\n# Track Java array values in explicit value analysis. This may be costly if\n# the verified program uses big or lots of arrays. Arrays in C programs will\n# always be tracked, even if this value is false.\ncpa.value.trackJavaArrayValues = true\n\n# Tells the value analysis how to handle unknown values.\ncpa.value.unknownValueHandling = DISCARD\n  enum:     [DISCARD, INTRODUCE_SYMBOLIC]\n\n# Specify simple custom instruction by specifying the binary operator op. All\n# simple cis are of the form r = x op y. Leave empty (default) if you specify\n# a more complex custom instruction within code.\ncustominstructions.binaryOperatorForSimpleCustomInstruction = PLUS\n  enum:     [MULTIPLY, DIVIDE, MODULO, PLUS, MINUS, SHIFT_LEFT, SHIFT_RIGHT, LESS_THAN,\n             GREATER_THAN, LESS_EQUAL, GREATER_EQUAL, BINARY_AND, BINARY_XOR, BINARY_OR,\n             EQUALS, NOT_EQUALS]\n\n# Name of function containing the custom instruction definition\ncustominstructions.ciFun = no default value\n\n# Signature for custom instruction, describes names and order of input and\n# output variables of a custom instruction\ncustominstructions.ciSignature = \"ci_spec.txt\"\n\n# File specifying start locations of custom instruction applications\n# File to dump start location of identified custom instruction applications\ncustominstructions.definitionFile = \"ci_def.txt\"\n\n# Where to dump the requirements on custom instruction extracted from\n# analysis\ncustominstructions.dumpCIRequirements = \"ci%d.smt\"\n\n# Try to remove parts of requirements that are not related to custom\n# instruction and are, thus, irrelevant for custom instruction behavior\ncustominstructions.enableRequirementsSlicing = false\n\n# Specifies the mode how custom instruction applications in program are\n# identified.\ncustominstructions.mode = OPERATOR\n  enum:     [MANUAL, OPERATOR, AUTOMATIC]\n\n# Try to remove requirements that are covered by another requirment and are,\n# thus, irrelevant for custom instruction behavior\ncustominstructions.removeCoveredRequirements = false\n\n# Qualified name of class for abstract state which provides custom\n# instruction requirements.\ncustominstructions.requirementsStateClassName = no default value\n\n# Option to change the behaviour of the loop detection for generating the\n# Counterexample-C-Code that will probably be used to generate invariants.\n# Note that last loop means the first loop encountered when backwards\n# traversing the given ARGPath, thus, the last loop may contain other loops,\n# which are in turn also counted to the last loop.\ncwriter.withLoops.loopDetectionStrategy = ALL_LOOPS\n  enum:     [ALL_LOOPS, ONLY_LAST_LOOP]\n\n# toggle checking forward conditions\ndar.checkForwardConditions = true\n\n# toggle falling back if interpolation or forward-condition is disabled\ndar.fallBack = true\n\n# toggle removing unreachable stop states in ARG\ndar.removeUnreachableStopStates = false\n\n# toggle replace global phase with BMC\ndar.replaceGlobalPhaseWithBMC = false\n\n# When checking for the data race property, use this configuration file\n# instead of the current one.\ndatarace.config = no default value\n\n# Whether to consider pointees. Only if this option is set to true, a pointer\n# analysis is run during system dependence graph (SDG) construction and\n# dependencies of pointees are inserted into the SDG. If this option is set\n# to false, pointers are completely ignored and the resulting SDG is an\n# under-approximation that lacks all pointee dependencies.\ndependencegraph.considerPointees = true\n\n# Whether to take an assumption edge 'p' as control dependence if edge 'not\n# p' is a control dependence. This creates a larger slice, but may reduce the\n# size of the state space for deterministic programs. This behavior is also\n# closer to the static program slicing based on control-flow graphs (CFGs),\n# where branching is represented by a single assumption (with true- and\n# false-edges)\ndependencegraph.controldeps.considerInverseAssumption = true\n\n# Whether to consider control dependencies.\ndependencegraph.controldeps.use = true\n\n# File to export dependence graph to. If `null`, dependence graph will not be\n# exported as dot.\ndependencegraph.exportDot = \"DependenceGraph.dot\"\n\n# Whether to consider (data-)flow dependencies.\ndependencegraph.flowdeps.use = true\n\n# Whether to include only functions reachable from the main function in the\n# dependence graph.\ndependencegraph.onlyReachableFunctions = true\n\n# The maximum duration a single pointer analysis method is allowed to run\n# (use seconds or specify a unit; 0 for infinite).\ndependencegraph.pointerAnalysisTime = 0s\n\n# The computation methods used for pointer analysis. If no method is\n# specified, an imprecise over-approximation of the global pointer state is\n# created without running any actual pointer analysis. If at least one\n# computation method is specified, the first one in the list is run with the\n# time limit set by 'dependencegraph.pointerAnalysisTime'. If this method is\n# able to create a valid global pointer state in time, the state is used and\n# no other methods are run. Otherwise, if a second computation method is\n# specified, the second method is run with the same time limit. If the method\n# is able to create a valid global pointer state in time, the state is used\n# and no other methods are run. The same is true for all subsequent\n# computation methods specified in the list. If no computation method is able\n# to create a valid global pointer state in time, an imprecise\n# over-approximation of the global pointer state is created without running\n# any actual pointer analysis. A pointer analysis is only run if\n# 'dependencegraph.considerPointees' is set to true. Available computation\n# methods: PointerStateComputationMethod.FLOW_SENSITIVE,\n# PointerStateComputationMethod.FLOW_INSENSITIVE\ndependencegraph.pointerStateComputationMethods = [PointerStateComputationMethod.FLOW_SENSITIVE]\n\n# comma-separated list of files with property specifications that should be\n# considered when determining the nodes that are in the reachability\n# property.\ndifferential.badstateProperties = []\n\n# ignore declarations when detecting modifications, be careful when variables\n# are renamed (could be unsound)\ndifferential.ignoreDeclarations = false\n\n# perform assumption implication check\ndifferential.implicationCheck = true\n\n# perform preprocessing to detect states from which error locations are\n# reachable\ndifferential.performPreprocessing = false\n\n# Program to check against\ndifferential.program = no default value\n\n# safely stop analysis on pointer accesses and similar\ndifferential.stopOnPointers = false\n\n# Switch on/off to form the union of variable sets at identical location\n# pairs. Set cpa.automaton.deleteDoubleEdges as well!\ndifferential.variableSetMerge = false\n\n# Abstraction nodes are added to each block after they are created. They are\n# needed to strengthen the preconditions of blocks. Missing blocks make the\n# analysis slower but not impossible.\ndistributedSummaries.allowMissingAbstractionNodes = true\n\n# The number of blocks is dependent by the number of functions in the\n# program.A tolerance of 1 means, that we subtract 1 of the total number of\n# functions.\ndistributedSummaries.allowSingleBlockDecompositionWhenMerging = false\n\n# Where to store the block graph in JSON format\ndistributedSummaries.blockCFAFile = \"block_analysis/blocks.json\"\n\n# Whether to enable debug mode of block-summary analysis. This creates visual\n# output for debugging and exports additional metadata.Creating this\n# information consumes resources and should not be used for benchmarks.\ndistributedSummaries.debug = false\n\n# Allows to set the algorithm for decomposing the CFA. LINEAR_DECOMPOSITION\n# creates blocks from each merge/branching point to the next merge/branching\n# point. MERGE_DECOMPOSITION merges blocks obtained by LINEAR_DECOMPOSITION.\n# The final number of blocks should converge to the number of functions in\n# the program. NO_DECOMPOSITION creates one block around the CFA.\ndistributedSummaries.decompositionType = MERGE_DECOMPOSITION\n  enum:     [LINEAR_DECOMPOSITION, MERGE_DECOMPOSITION, BRIDGE_DECOMPOSITION,\n             NO_DECOMPOSITION]\n\n# Whether to stop after exporting the blockgraph\ndistributedSummaries.generateBlockGraphOnly = false\n\n# Import an existing decomposition from a file\ndistributedSummaries.importDecomposition = no default value\n\n# List of input files that contain preconditions and verification conditions\n# that should be assumed as 'known' by block-summary analysis. Each file must\n# contain a single, valid JSON DssMessage. If at least one file is provided,\n# the block-summary analysis assumes these pre- and verification-conditions.\n# If no file is provided, the block-summary analysis assumes the precondition\n# 'true' and the verification condition 'false'.\ndistributedSummaries.knownConditions = []\n\n# List of input files that contain preconditions and verification conditions\n# that should be assumed as 'new' by block-summary analysis. For each message\n# in this list, block-summary analysis will perform a new analysis run in the\n# order of occurrence. Each file must contain a single, valid JSON\n# DssMessage. If at least one file is provided, the block-summary analysis\n# assumes these pre- and verification-conditions. If no file is provided, the\n# block-summary analysis assumes the precondition 'true' and the verification\n# condition 'false'.\ndistributedSummaries.newConditions = []\n\n# Where to write responses\ndistributedSummaries.outputMessages = \"messages/\"\n\n# Change the queue type. VIOLATION_CONDITION prioritizes the processing of\n# ViolationConditionMessages. DEFAULT does not differ between PostCondition\n# and ViolationCondition messages.\ndistributedSummaries.queue = DEFAULT\n  enum:     [VIOLATION_CONDITION, DEFAULT]\n\n# Whether to spawn a worker for only one block id\ndistributedSummaries.spawnWorkerForId = \"\"\n\n# Configuration for forward analysis in computation of distributed summaries\ndistributedSummaries.worker.forwardConfiguration = \"config/distributed-summary-synthesis/dss-block-analysis.properties\"\n\n# Destination directory for the logfiles of all DssWorkers. The logfiles have\n# the same name as the ID of the worker.\ndistributedSummaries.worker.logDirectory = \"block_summary/logfiles\"\n\n# output file for visualizing message exchange\ndss.logging.reportFiles = \"block_analysis/block_analysis\"\n\n# Enable to use lazy refinement in current analysis instead of restarting\n# from root after each refinement.\nenabledanalysis.allowLazyRefinement = false\n\n# Which CPA is used as enabler in the current analysis.\nenabledanalysis.enablerCPA = PREDICATE\n  enum:     [APRON, INTERVAL, OCTAGON, PREDICATE, VALUE]\n\n# Ranking algorithm to use for fault localization\nfaultLocalization.by_coverage.type = TARANTULA\n  enum:     [TARANTULA, DSTAR, OCHIAI]\n\n# Configuration to use for initial program-state exploration\nfaultLocalization.by_distance.analysis = no default value\n\n# The distance metric that ought to be used for the computation of the\n# distance\nfaultLocalization.by_distance.metric = ADM\n  enum:     [ADM, CFDM, PG]\n\n# Maximum number of explorations to run for collecting error paths, before\n# performing fault localization.  Exploration runs stop when the program\n# under analysis is fully explored or the specified number of runs is\n# reached. Fault localization may be more precise if more error paths are\n# available.\nfaultLocalization.by_distance.stopAfter = 40\n\n# whether to include variables beginning with\n# __FAULT_LOCALIZATION_precondition\nfaultLocalization.by_traceformula.includeDeclared = true\n\n# Do not show faults that contain a certain variable. Use, e.g., 'main::x' to\n# ban variable 'x' in the main function. Use, e.g., '::x' to ban all\n# variables named 'x'. This is especially useful to filter specific faults if\n# the first run results in many candidates. Provide a comma separated string\n# to add variables, e.g., main::x,doStuff::y,::z\nfaultLocalization.by_traceformula.maxsat.ban = []\n\n# which post-condition type to use\nfaultLocalization.by_traceformula.postConditionType = LAST_ASSUME_EDGES_ON_SAME_LINE\n  enum:     [LAST_ASSUME_EDGE, LAST_ASSUME_EDGES_ON_SAME_LINE,\n             LAST_ASSUME_EDGE_CLUSTER]\n\n# By default, the precondition only contains the failing variable assignment\n# of all nondet variables. Choose INITIAL_ASSIGNMENT to add assignments like\n# '<datatype> <variable-name> = <value>' to the precondition.\nfaultLocalization.by_traceformula.preconditionType = NONDETERMINISTIC_VARIABLES_ONLY\n  enum:     [NONDETERMINISTIC_VARIABLES_ONLY, INITIAL_ASSIGNMENT, ALWAYS_TRUE]\n\n# Whether the found counterexample needs to be precise\nfaultLocalization.by_traceformula.requirePreciseCounterexample = true\n\n# Whether to stop searching for further faults if first fault was found.\nfaultLocalization.by_traceformula.stopAfterFirstFault = false\n\n# which algorithm to use\nfaultLocalization.by_traceformula.type = UNSAT\n  enum:     [UNSAT, MAXSAT, MAXORG, ERRINV]\n\n# Whether to zip the resulting JSON file.\nfaultLocalization.export.compressed = false\n\n# Where to write machine readable faults.\nfaultLocalization.export.outputFile = \"faultlocalization.json\"\n\n# Whether to run specified analysis\nfaultLocalization.import.algorithmActivated = false\n\n# which explanations to use\nfaultLocalization.import.explanations = []\n\n# path to the input json file with faults\nfaultLocalization.import.importFile = no default value\n\n# which scoring functions to use\nfaultLocalization.import.scorings = []\n\n# Configuration for programs containing more than @Option adressedRatio\n# addressed vars.\nheuristicSelection.addressedConfig = no default value\n\n# Ratio of addressed vars. Values bigger than the passed value lead to\n# @option addressedConfig.\nheuristicSelection.addressedRatio = 0\n\n# Configuration for programs containing arrays.\nheuristicSelection.arrayConfig = no default value\n\n# Configuration for programs with loops and complex datastructures.\nheuristicSelection.complexLoopConfig = no default value\n\n# Configuration for programs containing composite types.\nheuristicSelection.compositeTypeConfig = no default value\n\n# If true, the strategy-selection algorithm does not run the selected config,\n# but only produces the statistics that show what config it would run.\nheuristicSelection.dryRun = false\n\n# Configuration for programs with loops.\nheuristicSelection.loopConfig = no default value\n\n# Configuration for loop-free programs.\nheuristicSelection.loopFreeConfig = no default value\n\n# Configuration for programs containing only relevant bool vars.\nheuristicSelection.onlyBoolConfig = no default value\n\n# Configuration for preliminary algorithm.\nheuristicSelection.preAnalysisAlgorithmConfig = no default value\n\n# Configuration for programs containing recursion.\nheuristicSelection.recursionConfig = no default value\n\n# Configuration for programs with a single loop.\nheuristicSelection.singleLoopConfig = no default value\n\n# toggle asserting targets at every iteration for IMC\nimc.assertTargetsAtEveryIteration = false\n\n# toggle whether to compute fixed-point backward by swapping initial-state\n# (prefix) and assertion (target) formulas\nimc.backwardAnalysis = false\n\n# toggle checking forward conditions\nimc.checkForwardConditions = true\n\n# toggle checking whether the safety property is inductive\nimc.checkPropertyInductiveness = false\n\n# toggle falling back if interpolation or forward-condition is disabled\nimc.fallBack = true\n\n# toggle which strategy is used for computing fixed points in order to verify\n# programs with loops. ITP enables IMC algorithm, and ITPSEQ enables ISMC\n# algorithm. ITPSEQ_AND_ITP runs ISMC first, and if a fixed point is not\n# reached by ISMC, IMC is invoked.\nimc.fixedPointComputeStrategy = ITP\n  enum:     [NONE, ITP, ITPSEQ, ITPSEQ_AND_ITP]\n\n# toggle Impact-like covering for the ISMC fixed-point check\nimc.impactLikeCovering = false\n\n# toggle the strategy to determine the next loop iteration\n# to execute BMC phase of IMC or ISMC\n# CONST: increased by one (to guarantee a shortest counterexample)\n# EAGER: skip all iterations where a bug cannot be found\nimc.loopBoundIncrementStrategyForBMC = CONST\n  enum:     [CONST, EAGER]\n\n# toggle the strategy to determine the next loop iteration\n# to execute interpolation phase of IMC\n# CONST: increased by a constant (specified via\n# loopBoundIncrementValueForIMC)\n# EAGER: skip all iterations where a bug cannot be found\nimc.loopBoundIncrementStrategyForIMC = CONST\n  enum:     [CONST, EAGER]\n\n# toggle the strategy to determine the next loop iteration\n# to execute k-inductive check if \"checkPropertyInductiveness\" is enabled\n# CONST: increased by by a constant (specified via\n# loopBoundIncrementValueForKI)\n# EAGER: skip all iterations where a bug cannot be found\nimc.loopBoundIncrementStrategyForKI = CONST\n  enum:     [CONST, EAGER]\n\n# toggle the value to increment the loop bound by at each step for IMC\nimc.loopBoundIncrementValueForIMC = 1\n\n# toggle the value to increment the loop bound by at each step for KI\nimc.loopBoundIncrementValueForKI = 1\n\n# toggle removing unreachable stop states in ARG\nimc.removeUnreachableStopStates = false\n\n# enable the Forced Covering optimization\nimpact.useForcedCovering = true\n\n# Configuration file for the K-Induction algorithm for checking candidates on\n# invariance.\ninvariantChecker.kInductionConfig = \"config/bmc-invgen.properties\"\n\n# configuration file for invariant generation\ninvariantGeneration.config = no default value\n\n# Check candidate invariants in a separate thread asynchronously.\ninvariantGeneration.kInduction.async = true\n\n# Guess some candidates for the k-induction invariant generator from the CFA.\ninvariantGeneration.kInduction.guessCandidatesFromCFA = ASSUME_EDGES_PLAIN\n  enum:     [NONE, ASSUME_EDGES_PLAIN, ASSUME_EDGE_TEMPLATES, LINEAR_TEMPLATES]\n\n# Provides additional candidate invariants to the k-induction invariant\n# generator.\ninvariantGeneration.kInduction.invariantsAutomatonFile = no default value\n\n# For correctness-witness validation: Shut down if a candidate invariant is\n# found to be incorrect.\ninvariantGeneration.kInduction.terminateOnCounterexample = false\n\n# Specify the class code path to search for java class or interface\n# definitions\njava.classpath = \"\"\n\n# use the following encoding for java files\njava.encoding = StandardCharsets.UTF_8\n\n# export TypeHierarchy as .dot file\njava.exportTypeHierarchy = true\n\n# Specify the source code path to search for java class or interface\n# definitions\njava.sourcepath = \"\"\n\n# export TypeHierarchy as .dot file\njava.typeHierarchyFile = \"typeHierarchy.dot\"\n\n# Specifies the java version of source code accepted\njava.version = JavaCore.VERSION_1_7\n\n# Programming language of the input program. If not given explicitly,\n# auto-detection will occur\n# C, Java, or LLVM IR?\nlanguage = C\n  enum:     [C, JAVA, LLVM]\nlanguage = no default value\n  enum:     [C, JAVA, LLVM]\nlanguage = C\n  enum:     [C, JAVA, LLVM]\n\n# Limit for cpu time used by CPAchecker (use seconds or specify a unit; -1\n# for infinite)\nlimits.time.cpu = -1ns\n\n# Limit for thread cpu time used by CPAchecker. This option will in general\n# not work when multi-threading is used in more than one place, use only with\n# great caution! (use seconds or specify a unit; -1 for infinite)\nlimits.time.cpu.thread = -1ns\n\n# Enforce that the given CPU time limit is set as the value of\n# limits.time.cpu.\nlimits.time.cpu::required = -1ns\n\n# Limit for wall time used by CPAchecker (use seconds or specify a unit; -1\n# for infinite)\nlimits.time.wall = -1ns\n\n# By changing this option one can adjust the way how live variables are\n# created. Function-wise means that each function is handled separately,\n# global means that the whole cfa is used for the computation.\nliveVar.evaluationStrategy = FUNCTION_WISE\n  enum:     [FUNCTION_WISE, GLOBAL]\n\n# Overall timelimit for collecting the liveness information.(use seconds or\n# specify a unit; 0 for infinite)\nliveVar.overallLivenessCheckTime = 0ns\n\n# Timelimit for collecting the liveness information with one approach, (p.e.\n# if global analysis is selected and fails in the specified timelimit the\n# function wise approach will have the same time-limit afterwards to compute\n# the live variables).(use seconds or specify a unit; 0 for infinite)\nliveVar.partwiseLivenessCheckTime = 20s\n\n# Write the tokenized version of the input program to this file.\nlocmapper.dumpTokenizedProgramToFile = no default value\n\n# all used options are printed\nlog.usedOptions.export = false\n\n# When checking for memory cleanup properties, use this configuration file\n# instead of the current one.\nmemorycleanup.config = no default value\n\n# When checking for memory safety properties, use this configuration file\n# instead of the current one.\nmemorysafety.config = no default value\n\n# which merge operator to use for LiveVariablesCPA\nmerge = \"JOIN\"\n  allowed values: [SEP, JOIN]\n\n# List of property-files to be run by the subprocesses.\nmpiAlgorithm.configFiles = no default value\n\n# The MCA parameter ('Modular Component Architecture') is available only on\n# Open MPI frameworks. It might thus need to be disabled if unavailable on\n# the working machine.\nmpiAlgorithm.disableMCAOptions = no default value\n\n# File containing the ip addresses to be used by MPI.\nmpiAlgorithm.hostfile = no default value\n\n# Max. amount of processes to be used by MPI.\nmpiAlgorithm.numberProcesses = no default value\n\n# Find all violations of each checked property.\nmpv.findAllViolations = false\n\n# Ignore exceptions, which may be caused by checking of some properties, to\n# successfully check the others.\nmpv.ignoreInnerExceptions = false\n\n# Adjust resource limitations during the analysis.\n# - NONE: do not adjust resource limitations (default).\n# - DISTRIBUTE_REMAINING: distribute resources, which were allocated for some\n# already checked property, but were not fully spent, between other\n# properties, which are still checking.\n# - DISTRIBUTE_BY_PROPERTY: scale resources for each property in accordance\n# with the given ratio in the property distribution file.\nmpv.limits.adjustmentStrategy = NONE\n  enum:     [NONE, DISTRIBUTE_REMAINING, DISTRIBUTE_BY_PROPERTY]\n\n# Set CPU time limit per each property in multi-property verification (use\n# seconds or specify a unit; -1 to disable)\nmpv.limits.cpuTimePerProperty = -1ns\n\n# Change resource limitations for the first partition by the given ratio.\n# This option will be ignored if NONE limits adjustment strategy is used.\nmpv.limits.firstPartitionRatio = 1.0\n\n# The ratio of CPU time limit in the first phase of Joint partitioning\n# operator to CPU time limit per each property.\nmpv.limits.joint.firstPhaseRatio = 1.3\n\n# Get a resource limitation distribution per property from file. This option\n# should be used only together with DISTRIBUTE_BY_PROPERTY limits adjustment\n# strategy. The following format should be used in the file:\n# '<property name>':<ratio>\nmpv.limits.propertyDistributionFile = no default value\n\n# The ratio of CPU time limit in the first phase of Relevance partitioning\n# operator to CPU time limit per each property.\nmpv.limits.relevance.firstPhaseRatio = 0.2\n\n# The ratio of CPU time limit in the second phase of Relevance partitioning\n# operator to CPU time limit per each property.\nmpv.limits.relevance.secondPhaseRatio = 1.3\n\n# Partitioning operator for multi-property verification.\nmpv.partitionOperator = no default value\n\n# Specifies how to separate a single property.\n# - FILE: each .spc file represent a single property (i.e., property is\n# represented by several automata).\n# - AUTOMATON: each automaton represent a single property.\nmpv.propertySeparator = FILE\n  enum:     [FILE, AUTOMATON]\n\n# Check for unsigned integer overflows\noverflow.checkUnsigned = false\n\n# When checking for the overflow property, use this configuration file\n# instead of the current one.\noverflow.config = no default value\n\n# Simplify overflow assumptions.\noverflow.simplifyExpressions = true\n\n# Track overflows in additive(+/-) operations.\noverflow.trackAdditiveOperations = true\n\n# Track overflows in division(/ or %) operations.\noverflow.trackDivisions = true\n\n# Track overflows in left-shift operations.\noverflow.trackLeftShifts = true\n\n# Track overflows in multiplication operations.\noverflow.trackMultiplications = true\n\n# Track overflows in binary expressions involving pointers.\noverflow.trackPointers = false\n\n# Only check live variables for overflow, as compiler can remove dead\n# variables.\noverflow.useLiveness = true\n\n# List of files with configurations to use. Files can be suffixed with\n# ::refinable to enable iterative refinement of the analysis precision (one\n# of the CPAs has to be instanceof ReachedSetAdjustingCPA), ::supply-reached\n# to enabled sharing of the (parial or finished) reached set for use in other\n# analyses (e.g. for invariants computation), or ::supply-reached-refinable\n# for both.\nparallelAlgorithm.configFiles = no default value\n\n# toggle to write all the files also for the unsuccessful analyses\nparallelAlgorithm.writeUnsuccessfulAnalysisFiles = false\n\n# The command line for calling the clang preprocessor. May contain binary\n# name and arguments, but won't be expanded by a shell. The source file name\n# will be appended to this string. Clang needs to print the output to stdout.\nparser.clang = \"clang-\" + LlvmUtils.extractVersionNumberFromLlvmJ() + \" -S -emit-llvm -o /dev/stdout\"\n\n# Whether to dump the results of the preprocessor to disk.\nparser.clang.dumpResults = true\n\n# Whether to collect ACSL annotations if present\nparser.collectACSLAnnotations = false\n\n# C dialect for parser\nparser.dialect = GNUC\n  enum:     [C99, GNUC]\n\n# The command line for calling the preprocessor. May contain binary name and\n# arguments, but won't be expanded by a shell. The source file name will be\n# appended to this string. The preprocessor needs to print the output to\n# stdout.\nparser.preprocessor = \"cpp\"\n\n# Directory where to dump the results of the preprocessor.\nparser.preprocessor.dumpDirectory = \"preprocessed\"\n\n# Whether to dump the results of the preprocessor to disk for debugging.\nparser.preprocessor.dumpResults = false\n\n# For C files, read #line preprocessor directives and use their information\n# for outputting line numbers. (Always enabled when pre-processing is used.)\nparser.readLineDirectives = false\n\n# Preprocess the given C files before parsing: Put every single token onto a\n# new line. Then the line number corresponds to the token number.\nparser.transformTokensToLines = false\n\n# For C files, convert to LLVM IR with clang first and then use the LLVM\n# parser.\nparser.useClang = false\n\n# For C files, run the preprocessor on them before parsing. Note that all\n# line numbers printed by CPAchecker will refer to the pre-processed file,\n# not the original input file.\nparser.usePreprocessor = false\n\n# Specifies the mode how HW requirements are detected in the proof.\npcc.HWrequirements.extraction.mode = OPERATOR\n  enum:     [MANUAL, OPERATOR, AUTOMATIC]\n\n# Enable if used property checker implements satisfiesProperty(AbstractState)\n# and checked property is violated for a set iff an element in this set\n# exists for which violates the property\npcc.arg.checkPropertyPerElement = false\n\n# Enable to store ARG states instead of abstract states wrapped by ARG state\npcc.backwardtargets.certificateStatesAsARGStates = false\n\n# List of files with configurations to use. \npcc.cmc.configFiles = no default value\n\n# write collected assumptions to file\npcc.cmc.file = \"AssumptionAutomaton.txt\"\n\n# collects information about value analysis states in proof\npcc.collectValueAnalysisStateInfo = false\n\n# The number of cores used exclusively for proof reading. Must be less than\n# pcc.useCores and may not be negative. Value 0 means that the cores used for\n# reading and checking are shared\npcc.interleaved.useReadCores = 0\n\n# enables parallel checking of partial certificate\npcc.parallel.io.enableParallelCheck = false\n\n# Selects the strategy used for partial certificate construction\npcc.partial.certificateType = HEURISTIC\n  enum:     [ALL, HEURISTIC, ARG, MONOTONESTOPARG]\n\n# If enabled, distributes checking of partial elements depending on actual\n# checking costs, else uses the number of elements\npcc.partial.enableLoadDistribution = false\n\n# Enables proper PCC but may not work correctly for heuristics. Stops adding\n# newly computed elements to reached set if size saved in proof is reached.\n# If another element must be added, stops certificate checking and returns\n# false.\npcc.partial.stopAddingAtReachedSetSize = false\n\n# [Best-first] Balance criterion for pairwise optimization of partitions\npcc.partitioning.bestfirst.balancePrecision = 1.0d\n\n# Evaluation function to determine exploration order of best-first-search\npcc.partitioning.bestfirst.chosenFunction = BEST_IMPROVEMENT_FIRST\n  enum:     [BREADTH_FIRST, DEPTH_FIRST, BEST_IMPROVEMENT_FIRST]\n\n# Balance criterion for pairwise optimization of partitions\npcc.partitioning.fm.balanceCriterion = 1.5d\n\n# Heuristic for computing an initial partitioning of proof\npcc.partitioning.fm.initialPartitioningStrategy = RANDOM\n  enum:     [RANDOM]\n\n# [FM-k-way] Balance criterion for pairwise optimization of partitions\npcc.partitioning.kwayfm.balancePrecision = 1.3d\n\n# [FM-k-way] Partitioning method to compute initial partitioning.\npcc.partitioning.kwayfm.globalHeuristic = BEST_IMPROVEMENT_FIRST\n  enum:     [RANDOM, DFS, BFS, BEST_IMPROVEMENT_FIRST]\n\n# [FM-k-way] Local optimization criterion to be minimized druing\n# Fiduccia/Mattheyses refinment\npcc.partitioning.kwayfm.optimizationCriterion = NODECUT\n  enum:     [EDGECUT, NODECUT]\n\n# Specifies the maximum size of the partition. This size is used to compute\n# the number of partitions if a proof (reached set) should be written.\n# Default value 0 means always a single partition.\npcc.partitioning.maxNumElemsPerPartition = 0\n\n# Partitioning method applied in multilevel heuristic to compute initial\n# partitioning.\npcc.partitioning.multilevel.globalHeuristic = BEST_IMPROVEMENT_FIRST\n  enum:     [RANDOM, DFS, BFS, BEST_IMPROVEMENT_FIRST]\n\n# Matching method applied to coarsen graph down in multilevel heuristic.\npcc.partitioning.multilevel.matchingGenerator = HEAVY_EDGE\n  enum:     [RANDOM, HEAVY_EDGE]\n\n# Refinement method applied in multilevel heuristic's uncoarsening phase.\npcc.partitioning.multilevel.refinementHeuristic = FM_NODECUT\n  enum:     [FM_NODECUT, FM_EDGECUT]\n\n# Heuristic for computing partitioning of proof (partial reached set).\npcc.partitioning.partitioningStrategy = RANDOM\n  enum:     [RANDOM, DFS, BFS, OPTIMAL, BEST_FIRST, FM, FM_K_WAY, MULTILEVEL]\n\n# If enabled uses the number of nodes saved in certificate to compute\n# partition number otherwise the number of states explored during analysis\npcc.partitioning.useGraphSizeToComputePartitionNumber = false\n\n# file in which proof representation needed for proof checking is stored\npcc.proof = \"arg.obj\"\n\n# file in which proof representation will be stored\npcc.proofFile = \"arg.obj\"\n\n# Generate and dump a proof\npcc.proofgen.doPCC = false\n\n# Configuration for proof checking if differs from analysis configuration\npcc.resultcheck.checkerConfig = no default value\n\n# Enable to write proof and read it again for validation instead of using the\n# in memory solution\npcc.resultcheck.writeProof = false\n\n# Make proof more abstract, remove some of the information not needed to\n# prove the property.\npcc.sliceProof = false\n\n# writes the validation configuration required for checking to proof\npcc.storeConfig = false\n\n# Qualified name for class which implements certification strategy, hence\n# proof writing, to be used.\npcc.strategy = no default value\n\n# number of cpus/cores which should be used in parallel for proof checking\npcc.useCores = 1\n\n# Which strategy to use to perform abstraction of successful proof results or\n# when lifting with the lifting strategy ABSTRACTION_BASED_LIFTING.\npdr.abstractionStrategy = NO_ABSTRACTION\n  enum:     [NO_ABSTRACTION, ALLSAT_BASED_PREDICATE_ABSTRACTION]\n\n# Whether to adjust conditions (i.e. increment k) after frontier extension.\npdr.conditionAdjustmentCriterion = NEVER\n  enum:     [NEVER, ALWAYS]\n\n# Which strategy to use to perform invariant refinement on successful proof\n# results.\npdr.invariantRefinementStrategy = NO_STRENGTHENING\n  enum:     [NO_STRENGTHENING, UNSAT_CORE_BASED_STRENGTHENING]\n\n# Maximum number of ignored lifting abstraction failures within a\n# proof-obligation trace.\npdr.liftingAbstractionFailureThreshold = 0\n\n# Which strategy to use to abstract counterexamples to inductivity.\npdr.liftingStrategy = NO_LIFTING\n  enum:     [NO_LIFTING, UNSAT_CORE_BASED_LIFTING, ABSTRACTION_BASED_LIFTING]\n\n# Maximum number of accepted spurious transitions within a proof-obligation\n# trace before a consecution abstraction failure triggers a refinement.\npdr.spuriousTransitionCountThreshold = 0\n\n# Format to use for image output\npixelgraphic.export.format = \"svg\"\n\n# Height of the bitmap in pixels. If set to -1, height is  computed in\n# relation to the width. If both are set to -1, the optimal bitmap size to\n# represent the graph is used. The final height is height*scaling\npixelgraphic.export.height = -1\n\n# Scaling of the bitmap. If set to 1, 1 pixel represents one graph node. If\n# set to 2, 2 * 2 pixels represent one graph node, and so on.\npixelgraphic.export.scaling = 2\n\n# Highlight not only corresponding graph nodes, but background of\n# corresponding line, too. This may give an better overview, but also\n# introduces more clutter\npixelgraphic.export.strongHighlight = false\n\n# Width of the bitmap in pixels. If set to -1, width is computed in relation\n# to the height. If both are set to -1, the optimal bitmap size to represent\n# the graph is used. The final width is width*scaling\npixelgraphic.export.width = -1\n\n# Padding of the bitmap on the left and right (each) in pixels\npixelgraphic.export.xPadding = 2\n\n# Padding of the bitmap on the top and bottom (each) in pixels\npixelgraphic.export.yPadding = 2\n\n# A path to a precision output\n# A path to precision\nprecision.path = \"localsave\"\n\n# whether to track relevant variables only at the exact program location\n# (sharing=location), or within their respective (function-/global-) scope\n# (sharing=scoped).\nprecision.sharing = SCOPE\n  enum:     [SCOPE, LOCATION]\n\n# Allowed coefficients in a template.\nprecision.template.allowedCoefficients = {Rational.NEG_ONE, Rational.ONE}\n\n# Generate difference constraints.This option is redundant for\n# `maxExpressionSize` >= 2.\nprecision.template.generateDifferences = false\n\n# Generate templates from assert statements\nprecision.template.generateFromAsserts = true\n\n# Generate templates from all program statements\nprecision.template.generateFromStatements = false\n\n# Force the inclusion of function parameters into the generated templates.\n# Required for summaries computation.\nprecision.template.includeFunctionParameters = false\n\n# Maximum size for the generated template\nprecision.template.maxExpressionSize = 1\n\n# Perform refinement using enumerative template synthesis.\nprecision.template.performEnumerativeRefinement = true\n\n# Do not generate templates with threshold larger than specified. Set to '-1'\n# for no limit.\nprecision.template.templateConstantThreshold = 100\n\n# Strategy for filtering variables out of templates using liveness\nprecision.template.varFiltering = ALL_LIVE\n  enum:     [INTERPOLATION_BASED, ALL_LIVE, ONE_LIVE, ALL]\n\n# If this option is used, variables that are addressed may get tracked\n# depending on the rest of the precision. When this option is disabled, a\n# variable that is addressed is definitely not tracked.\nprecision.trackAddressedVariables = true\n\n# If this option is used, booleans from the cfa are tracked.\nprecision.trackBooleanVariables = true\n\n# If this option is used, variables that have type double or float are\n# tracked.\nprecision.trackFloatVariables = true\n\n# If this option is used, variables, that are only used in simple\n# calculations (add, sub, lt, gt, eq) are tracked.\nprecision.trackIntAddVariables = true\n\n# If this option is used, variables that are only compared for equality are\n# tracked.\nprecision.trackIntEqualVariables = true\n\n# If this option is used, variables that are irrelevantare also tracked.\nprecision.trackIrrelevantVariables = true\n\n# If this option is used, all variables that are of a different\n# classification than IntAdd, IntEq and Boolean get tracked by the precision.\nprecision.trackVariablesBesidesEqAddBool = true\n\n# blacklist regex for variables that won't be tracked by the CPA using this\n# precision\nprecision.variableBlacklist = \"\"\n\n# whitelist regex for variables that will always be tracked by the CPA using\n# this precision\nprecision.variableWhitelist = \"\"\n\n# where to export conditions\nprogram.splitter.conditionFile = \"Condition.%d.txt\"\n\n# export program splitting as conditions (assumption automata)\nprogram.splitter.exportAsCondition = true\n\n# Which program split heuristic to use\nprogram.splitter.heuristic = no default value\n\n# maximal number\nprogram.splitter.max = 2\n\n# Quantifier elimination strategy\nrcnf.boundVarsHandling = QE_LIGHT_THEN_DROP\n  enum:     [QE_LIGHT_THEN_DROP, QE, DROP]\n\n# Expand equality atoms. E.g. 'x=a' gets expanded into 'x >= a AND x <= a'.\n# Can lead to stronger weakenings.\nrcnf.expandEquality = false\n\n# Limit on the size of the resulting number of lemmas from the explicit\n# expansion\nrcnf.expansionResultSizeLimit = 100\n\n# print reached set to graph file\nreachedSet.dot = \"reached.dot\"\n\n# print reached set to text file\nreachedSet.export = false\nreachedSet.file = \"reached.txt\"\n\n# Add visualization of correctness witnesses to the report (can be costly)\nreport.addWitness = false\n\n# Generate HTML report with analysis result.\nreport.export = true\n\n# File name for analysis report in case no counterexample was found.\nreport.file = \"Report.html\"\n\n# set path to file which contains the condition\nresidualprogram.assumptionFile = no default value\n\n# set specification file to automaton which guides analysis along assumption\n# produced by incomplete analysis,e.g.,\n# config/specification/AssumptionGuidingAutomaton.spc, to enable residual\n# program from combination of program and assumption condition\nresidualprogram.assumptionGuider = no default value\n\n# Export CFA of residual program as pixel graphic to the given file name. The\n# suffix is added corresponding to the value of option\n# pixelgraphic.export.formatIf set to 'null', no pixel graphic is exported.\nresidualprogram.cfa.pixelGraphicFile = \"residProgPixel\"\n\n# Export residual program as pixel graphic\nresidualprogram.export.pixel = false\n\n# write residual program to file\nresidualprogram.file = \"residualProgram.c\"\n\n# Define kind of folder to use when combining condition with folding approach\n# in residual program generation\nresidualprogram.folderType = CFA\n  enum:     [CFA, FOLD_EXCEPT_LOOPS, LOOP_ALWAYS, LOOP_BOUND, LOOP_BOUND_SAME_CONTEXT,\n             LOOP_SAME_CONTEXT]\n\n# Collect statistical data about size of residual program\nresidualprogram.statistics.size = false\n\n# which strategy to use to generate the residual program\nresidualprogram.strategy = CONDITION\n  enum:     [REACHABILITY, SLICING, CONDITION, CONDITION_PLUS_FOLD, COMBINATION]\n\n# How often may a loop be unrolled before it must be folded\nresidualprogram.unrollBound = 2\n\n# wether to start next algorithm independently from the previous result\nrestartAlgorithm.alwaysRestart = false\n\n# combine (partial) ARGs obtained by restarts of the analysis after an\n# unknown result with a different configuration\nrestartAlgorithm.combineARGsAfterRestart = false\n\n# List of files with configurations to use. A filename can be suffixed with\n# :if-interrupted, :if-failed, and :if-terminated which means that this\n# configuration will only be used if the previous configuration ended with a\n# matching condition. What also can be added is :use-reached then the reached\n# set of the preceding analysis is taken and provided to the next analysis.\nrestartAlgorithm.configFiles = no default value\n\n# print the statistics of each component of the restart algorithm directly\n# after the components computation is finished\nrestartAlgorithm.printIntermediateStatistics = true\n\n# let each component of the restart algorithm write output files and not only\n# the last one that is excuted\nrestartAlgorithm.writeIntermediateOutputFiles = false\n\n# path to condition file\nslicing.conditionFile = \"output/AssumptionAutomaton.txt\"\n\n# path to condition files plus additional assumption guiding automaton when\n# condition itself is in propriertary format and not in witness format\nslicing.conditionFiles = {\n          Path.of(\"output/AssumptionAutomaton.txt\"),\n          Classes.getCodeLocation(ReducerExtractor.class)\n              .resolveSibling(\"config/specification/AssumptionGuidingAutomaton.spc\")}\n\n# Export the used slicing criteria to file\nslicing.exportCriteria.enable = false\n\n# File template for export of used slicing criteria\nslicing.exportCriteria.file = \"programSlice.%d.criteria.txt\"\n\n# Whether to export slices as C program files\nslicing.exportToC.enable = false\n\n# File template for exported C program slices\nslicing.exportToC.file = \"programSlice.%d.c\"\n\n# Whether to export program slices as DOT files.\nslicing.exportToDot.enable = true\n\n# File template for exported program slice DOT files.\nslicing.exportToDot.file = \"programSlice.%d.dot\"\n\n# which type of extractor for slicing criteria to use\nslicing.extractor = ALL\n  enum:     [ALL, REDUCER, SYNTAX]\n\n# Whether to allow edges in the resulting slice that are only partially\n# relevant (e.g. function calls where not every parameter is relevant).\n# Setting this parameter to true can decrease the size of the resulting\n# slice.\nslicing.partiallyRelevantEdges = true\n\n# what kind of slicing to use\nslicing.type = STATIC\n  enum:     [STATIC, IDENTITY]\n\n# Extract and cache unsat cores for satisfiability checking\nsolver.cacheUnsatCores = true\n\n# improve sat-checks with additional constraints for UFs\nsolver.checkUFs = false\n\n# whether CPAchecker's logger should be used as logger for the solver,\n# otherwise nothing is logged from the solver.\nsolver.enableLoggingInSolver = false\n\n# Which solver to use specifically for interpolation (default is to use the\n# main one).\nsolver.interpolationSolver = no default value\n  enum:     [OPENSMT, MATHSAT5, SMTINTERPOL, Z3, PRINCESS, BOOLECTOR, CVC4, CVC5,\n             YICES2, BITWUZLA]\n\n# Which SMT solver to use.\nsolver.solver = MATHSAT5\n  enum:     [OPENSMT, MATHSAT5, SMTINTERPOL, Z3, PRINCESS, BOOLECTOR, CVC4, CVC5,\n             YICES2, BITWUZLA]\n\n# Comma-separated list of files with specifications that should be checked\n# (cf. config/specification/ for examples). Property files as used in SV-COMP\n# can also be used here, but when these are specified inside a configuration\n# file instead of on the command line, CPAchecker will ignore the entry\n# function in the property file.\nspecification = []\n\n# export abstract states as formula, e.g. for re-using them as\n# PredicatePrecision.\nstatesToFormulas.exportFile = no default value\n\n# export formulas for all program locations or just the important\n# locations,which include loop-heads, funtion-calls and function-exits.\nstatesToFormulas.exportOnlyImporantLocations = false\n\n# instead of writing the exact state-representation as a single formula,\n# write its atoms as a list of formulas. Therefore we ignore operators for\n# conjunction and disjunction.\nstatesToFormulas.splitFormulas = LOCATION\n  enum:     [LOCATION, STATE, ATOM]\n\n# Add all assumptions from the control flow automaton to the precision.\nstaticRefiner.addAllControlFlowAssumes = false\n\n# Add all assumptions along a error trace to the precision.\nstaticRefiner.addAllErrorTraceAssumes = false\n\n# Add all assumptions along the error trace to the precision.\nstaticRefiner.addAssumesByBoundedBackscan = true\n\n# Apply mined predicates on the corresponding scope. false = add them to the\n# global precision.\nstaticRefiner.applyScoped = true\n\n# Dump CFA assume edges as SMTLIB2 formulas to a file.\nstaticRefiner.assumePredicatesFile = no default value\n\n# split generated heuristic predicates into atoms\nstaticRefiner.atomicPredicates = true\n\n# collect at most this number of assumes along a path, backwards from each\n# target (= error) location\nstaticRefiner.maxBackscanPathAssumes = 1\n\n# write some statistics to disk\nstatistics.export = true\nstatistics.file = \"Statistics.txt\"\n\n# track memory usage of JVM during runtime\nstatistics.memory = true\n\n# print statistics to console\nstatistics.print = false\n\n# which stop operator to use for LiveVariablesCPA\nstop = \"SEP\"\n  allowed values: [SEP, JOIN, NEVER]\n\n# compress the produced violation-witness automata using GZIP compression.\ntermination.compressWitness = true\n\n# When checking for the termination property, use this configuration file\n# instead of the current one.\ntermination.config = no default value\n\n# enable to also analyze whether recursive calls terminate\ntermination.considerRecursion = false\n\n# Number of generalized eigenvectors in the geometric nontermination\n# argument.\ntermination.lassoAnalysis.eigenvectors = 3\n\n# Shell command used to call the external SMT solver.\ntermination.lassoAnalysis.externalSolverCommand = NativeLibraries.getNativeLibraryPath().resolve(\"z3\") + \" -smt2 -in SMTLIB2_COMPLIANT=true \"\n\n# Analysis type used for synthesis of linear termination arguments.\ntermination.lassoAnalysis.linear.analysisType = LINEAR_WITH_GUESSES\n  enum:     [DISABLED, LINEAR, LINEAR_WITH_GUESSES, NONLINEAR]\n\n# If true, an external tool is used as SMT solver instead of SMTInterpol.\n# This affects only synthesis of linear termination arguments.\ntermination.lassoAnalysis.linear.externalSolver = false\n\n# Maximal number of functions used in a ranking function template.\ntermination.lassoAnalysis.maxTemplateFunctions = 3\n\n# Number of non-strict supporting invariants for each Motzkin transformation\n# during synthesis of termination arguments.\ntermination.lassoAnalysis.nonStrictInvariants = 3\n\n# Analysis type used for synthesis of non-linear termination arguments.\ntermination.lassoAnalysis.nonlinear.analysisType = LINEAR_WITH_GUESSES\n  enum:     [DISABLED, LINEAR, LINEAR_WITH_GUESSES, NONLINEAR]\n\n# If true, an external tool is used as SMT solver instead of SMTInterpol.\n# This affects only synthesis of non-linear termination arguments and\n# non-termination arguments.\ntermination.lassoAnalysis.nonlinear.externalSolver = false\n\n# Number of strict supporting invariants for each Motzkin transformation\n# during synthesis of termination arguments.\ntermination.lassoAnalysis.strictInvariants = 2\n\n# Simplifies loop and stem formulas.\ntermination.lassoBuilder.simplify = false\n\n# maximal number of repeated ranking functions per loop before stopping\n# analysis\ntermination.maxRepeatedRankingFunctionsPerLoop = 10\n\n# Strategy used to prepare reched set and ARG for next iteration after\n# successful refinement of the termination argument.\ntermination.resetReachedSetStrategy = REMOVE_LOOP\n  enum:     [REMOVE_TARGET_STATE, REMOVE_LOOP, RESET]\n\n# A human readable representation of the synthesized (non-)termination\n# arguments is exported to this file.\ntermination.resultFile = \"terminationAnalysisResult.txt\"\n\n# consider counterexamples for loops for which only pointer variables are\n# relevant or which check that pointer is unequal to null pointer to be\n# imprecise\ntermination.useCexImpreciseHeuristic = false\n\n# Export termination counterexample to file as GraphML automaton \ntermination.violation.witness = \"nontermination_witness.graphml\"\n\n# Export termination counterexample to file as dot/graphviz automaton \ntermination.violation.witness.dot = \"nontermination_witness.dot\"\n\n# compress the produced violation-witness automata using GZIP compression.\nterminationtoreach.compressWitness = false\n\n# do not produce witness for validation\nterminationtoreach.validation = false\n\n# Export termination counterexample to file as GraphML automaton \nterminationtoreach.violation.witness = \"witness.graphml\"\n\n# Export termination counterexample to file as dot/graphviz automaton \nterminationtoreach.violation.witness.dot = \"witness.dot\"\n\n# Only genenerate for __VERIFIER_nondet calls\ntestHarnessExport.onlyVerifierNondet = false\n\n# Provide dummy values for external variable declarations. This is useful\n# when definitions are not implemented yet or missing. But it may introduce\n# conflicts with values from standard libraries.\ntestHarnessExport.provideDummyValues = false\n\n# Use the counterexample model to provide test-vector values\ntestHarnessExport.useModel = true\n\n# zip all exported test cases into a single file\ntestcase.compress = false\n\n# Do not output values for variables that are not initialized when declared\ntestcase.excludeInitialization = false\n\n# export test harness to file as code\ntestcase.file = no default value\n\n# set to true if run multiple test case generation instances in parallel\ntestcase.generate.parallel = false\n\n# display all test targets and non-covered test targets in statistics\ntestcase.inStats = false\n\n# how many mutated test cases should be additionally generated (disabled if\n# <= 0)\ntestcase.mutants = 0\n\n# Random seed for mutation of test cases\ntestcase.mutationSeed = 0\n\n# Number of random test cases that should be generated\ntestcase.numRandomTests = 1\n\n# Only convert literal value and do not add suffix, e.g., for unsigned, etc.\ntestcase.plainLiteralValue = false\n\n# defines how progress is computed\ntestcase.progress = RELATIVE_TOTAL\n  enum:     [ABSOLUTE, RELATIVE_TOTAL]\n\n# Maximum value randomly generated\ntestcase.random.max = 20\n\n# Number of random test cases that should be generated\ntestcase.random.maxLength = 20\n\n# Minimum value randomly generated\ntestcase.random.min = 0\n\n# Random seed for random test-case generation\ntestcase.randomInputSeed = 0\n\n# when generating tests covering error call stop as soon as generated one\n# test case and report false (only possible in combination with error call\n# property specification\ntestcase.reportCoveredErrorCallAsError = false\n\n# CFA edge if only a specific edge should be considered, e.g., in\n# counterexample check\ntestcase.targets.edge = no default value\n\n# Name of target function if target type is FUN_CALL\ntestcase.targets.funName = no default value\n\n# Set to enable optimizations to be applied to result of previous\n# optimizations\ntestcase.targets.optimization.nested = false\n\n# Which strategy or which strategies (comma separated list of strategies) to\n# use to optimize set of test target edges. If more than one strategy is\n# provided, all strategies are applied and if targets.optimization.nested is\n# disabled the smallest result is taken otherwise see description of option\n# targets.optimization.nested.If no strategy is provided, no optimization is\n# performed. \ntestcase.targets.optimization.strategy = []\n\n# enable to track coverage of test targets removed in optimization\ntestcase.targets.optimization.trackAll = false\n\n# Which CFA edges to use as test targets\ntestcase.targets.type = ASSUME\n  enum:     [ASSUME, TEST_COMP_ASSUME, ERROR_CALL, FUN_CALL, STATEMENT]\n\n# export test values to file (line separated)\ntestcase.values = no default value\n\n# export test cases to xm file (Test-Comp format)\ntestcase.xml = no default value\n\n# Zip file into which all test case files are bundled\ntestcase.zip.file = no default value\n\n# Usually every statement that is not part of the precondition gets a\n# selector. If a certain variable is known to not cause the error, add it to\n# this option, e.g., main::x,doStuff::y\ntraceformula.disable = []\n\n# The alternative precondition consists of all initial variable assignments\n# and a failing variable assignment for all nondet variables. By default only\n#  variables in the main function are part of the precondition. Overwrite the\n# default by adding functions to this option, e.g., \"main,doStuff\"\ntraceformula.filter = [\"main\"]\n\n# The alternative precondition consists of all initial variable assignments.\n# If a variable assignment seems suspicious, it might be useful to exclude it\n# from the precondition. To do this, add these variables to this option,\n# e.g., main::x,doStuff::y. Make sure to add the function in which the\n# variable is used as prefix, separated by two ':'\ntraceformula.ignore = []\n\n# if enabled, nondet declarations get a selector, otherwise they don't\ntraceformula.inlinePrecondition = true\n\n# Make trace formula flow-sensitive, i.e., assume edges imply the edges that\n# are only reachable through the assume edge. Flow-sensitive traces remove\n# assume edges from the trace. Hence, no assume edge will be part of a fault.\ntraceformula.makeFlowSensitive = false\n\n# By default, every executed statement gets its own selector. If a loop is\n# part of the program to analyze, the number of selectors can increase which\n# also increases the run time of max-sat drastically. To use the same\n# selector for equal statements (on the same line), set this option to true.\n# Note that enabling this option  also decreases the quality of results.\ntraceformula.reduceSelectors = false\n\n# Ignore functions that are defined by C11\nundefinedFunctionsCollector.allowC11Functions = true\n\n# Ignore functions that are defined by GNU C and not by C11/POSIX\nundefinedFunctionsCollector.allowGnuCFunctions = true\n\n# Ignore functions that are defined by POSIX\nundefinedFunctionsCollector.allowPosixFunctions = true\n\n# Set of functions that should be ignored\nundefinedFunctionsCollector.allowedFunctions = ImmutableSet.of(\n\n# Regexp matching function names that are allowed to be undefined\nundefinedFunctionsCollector.allowedFunctionsRegexp = \"^(__VERIFIER|pthread)_[a-zA-Z0-9_]*\"\n\n# Regexp matching function names that need not be declared\nundefinedFunctionsCollector.allowedUndeclaredFunctionsRegexp = \"^__builtin_[a-zA-Z0-9_]*\"\n\n# Memory-allocation function that will be used in stubs\nundefinedFunctionsCollector.externAllocFunction = \"external_alloc\"\n\n# export undefined functions as C file\nundefinedFunctionsCollector.stubsFile = \"stubs.c\"\n\n# select an analysis from a set of analyses after unknown result\nuseCompositionAnalysis = false\n\n# Whether or not one wants to refine MemorySafety errors.\nutil.refinement.refineMemorySafety = false\n\n# Instead of comments, output the assertions into the original program as\n# violations to unreach_call.prp\nwacsl.makeDirectAssertions = false\n\n# The directory where generated, ACSL annotated programs are stored.\nwacsl.outDir = \"annotated\"\n\n# Makes the annotated file's name identical to the original source file's\n# name.\nwacsl.useSameFileName = false\n\n# The witness from which ACSL annotations should be generated.\nwacsl.witness = no default value\n\n# File for exporting the witness automaton in DOT format.\nwitness.automatonDumpFile = no default value\n\n# remove assumptions from transitions in the ISA where they are not strictly\n# neccessary.This option is intended to be used with an ISA (c.f. option\n# witness.invariantsSpecificationAutomaton)\nwitness.checkInvariantViolations = true\n\n# Check that the value of the programhash field of the witness matches the\n# SHA-256 hash value computed for the source code.\nwitness.checkProgramHash = true\n\n# Consider assumptions that are provided with the path automaton?\nwitness.considerAssumptions = true\n\n# Fail-fast if invariants in the witness exist that would not be accounted\n# for. There are cases where unaccounted invariants are perfectly fine, e.g.\n# if those states in the witness automaton are actually unreachable in the\n# program. This is however rarely the intention of the original producer of\n# the witness, so this options can be used to debug those cases.\nwitness.debug.checkForMissedInvariants = false\n\n# Fail if invariants in the witness do not match a unique location in the\n# CFA. This is useful to detect errors in the witness file.\nwitness.failOnUnmatchedInvariants = false\n\n# Validate correctness witness by specifying an invariants specification\n# automaton\nwitness.invariantsSpecificationAutomaton = NO_ISA\n  enum:     [NO_ISA, WITNESSBASED_ISA, TWOSTATES_ISA, CFABASED_ISA]\n\n# Match the branching information at a branching location.\nwitness.matchAssumeCase = true\n\n# Match the character offset within the file.\nwitness.matchOffset = true\n\n# Match the line numbers within the origin (mapping done by preprocessor line\n# markers).\nwitness.matchOriginLine = true\n\n# This option can be used to ensure that no correctness witnesses are\n# checked.\nwitness.noCorrectnessValidation = false\n\n# This option can be used to ensure that no violation witnesses are checked.\nwitness.noViolationValidation = false\n\n# remove assumptions from transitions in the ISA where they are not strictly\n# neccessary.This option is intended to be used with an ISA (c.f. option\n# witness.invariantsSpecificationAutomaton)\nwitness.optimizeInvariantsSpecificationAutomaton = true\n\n# Represent sink states by bottom state instead of break state\nwitness.stopNotBreakAtSinkStates = true\n\n# Enforce strict validity checks regarding the witness format, such as\n# checking for the presence of required fields.\nwitness.strictChecking = true\n\n# remove assumptions from transitions in the ISA where they are not strictly\n# neccessary.This option is intended to be used with an ISA (c.f. option\n# witness.invariantsSpecificationAutomaton)\nwitness.useInvariantsAsAssumptions = true\n\n# extend name of each witness automaton with a unique id\nwitness.useUniqueName = false\n\n# Validate program using invariants from ACSL annotations.\nwitness.validation.correctness.acsl = false\n\n# When validating a correctness witness, use this configuration file instead\n# of the current one.\nwitness.validation.correctness.config = no default value\n\n# Use correctness witness as invariants specification automaton (ISA).\nwitness.validation.correctness.isa = false\n\n# The witness to validate.\nwitness.validation.file = no default value\n\n# Use this configuration when checking that when reach recurrent set,\n# execution can be extended to an infinite one\nwitness.validation.termination.inspectCycle.config = no default value\n\n# Use this configuration when checking that recurrent set (at cycle head) is\n# reachable. Configuration must be precise, i.e., may only report real\n# counterexamples\nwitness.validation.termination.reachCycle.config = no default value\n\n# Report a successful validation of the witness, i.e., a confirmation of the\n# nontermination, as termination violation.\nwitness.validation.termination.successAsViolation = true\n\n# Path to automaton specification describing which statements let the program\n# terminate.\nwitness.validation.termination.terminatingStatements = \"config/specification/TerminatingStatements.spc\"\n\n# When validating a violation witness, use this configuration file instead of\n# the current one.\nwitness.validation.violation.config = no default value\n\n# when enabled we also provide an analysis in form of logging output of the\n# likely quality of the produced witnesses\nwitness.yamlexporter.analyseWitnessQuality = false\n\n# Export all information contained in the counterexample as a witness.\nwitness.yamlexporter.exportCompleteCounterexample = false\n\n# The version for which to export the witness.\nwitness.yamlexporter.witnessVersions = [YAMLWitnessVersion.V2]\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/doc/ConfigurationOptions.txt b/doc/ConfigurationOptions.txt
--- a/doc/ConfigurationOptions.txt	(revision 994693c6616e755015ebf8f13b83d23d2f5cd593)
+++ b/doc/ConfigurationOptions.txt	(date 1744898341147)
@@ -1918,14 +1918,6 @@
 # in order to find calls to such pointers
 cpa.functionpointer.trackInvalidFunctionPointers = false
 
-# which merge operator to use for GlobalVarAnalysisCPA
-cpa.globalvar.merge = "SEP"
-  allowed values: [SEP, JOIN]
-
-# which stop operator to use for GlobalVarAnalysisCPA
-cpa.globalvar.stop = "SEP"
-  allowed values: [SEP, JOIN, NEVER]
-
 # which type of merge operator to use for IntervalAnalysisCPA
 cpa.interval.merge = "SEP"
   allowed values: [SEP, JOIN]
@@ -3648,6 +3640,14 @@
 cpa.uninitvars.stop = "sep"
   allowed values: [sep, join]
 
+# which merge operator to use for UnseqBehaviorAnalysisCPA 
+cpa.unseqbehavior.merge = "SEP"
+  allowed values: [SEP, JOIN]
+
+# which stop operator to use for UnseqBehaviorAnalysisCPA
+cpa.unseqbehavior.stop = "SEP"
+  allowed values: [SEP, JOIN, NEVER]
+
 # functions, which stops analysis
 cpa.usage.abortfunctions = {}
 
Index: src/org/sosy_lab/cpachecker/cpa/unsequenced/UnseqBehaviorAnalysisCPA.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/org/sosy_lab/cpachecker/cpa/unsequenced/UnseqBehaviorAnalysisCPA.java b/src/org/sosy_lab/cpachecker/cpa/unsequenced/UnseqBehaviorAnalysisCPA.java
new file mode 100644
--- /dev/null	(date 1744785367478)
+++ b/src/org/sosy_lab/cpachecker/cpa/unsequenced/UnseqBehaviorAnalysisCPA.java	(date 1744785367478)
@@ -0,0 +1,91 @@
+// This file is part of CPAchecker,
+// a tool for configurable software verification:
+// https://cpachecker.sosy-lab.org
+//
+// SPDX-FileCopyrightText: 2025 Dirk Beyer <https://www.sosy-lab.org>
+//
+// SPDX-License-Identifier: Apache-2.0
+
+package org.sosy_lab.cpachecker.cpa.unsequenced;
+
+import java.util.Collection;
+import org.sosy_lab.common.ShutdownNotifier;
+import org.sosy_lab.common.configuration.Configuration;
+import org.sosy_lab.common.configuration.InvalidConfigurationException;
+import org.sosy_lab.common.configuration.Option;
+import org.sosy_lab.common.configuration.Options;
+import org.sosy_lab.common.log.LogManager;
+import org.sosy_lab.cpachecker.cfa.CFA;
+import org.sosy_lab.cpachecker.cfa.model.CFANode;
+import org.sosy_lab.cpachecker.core.defaults.AbstractCPA;
+import org.sosy_lab.cpachecker.core.defaults.AutomaticCPAFactory;
+import org.sosy_lab.cpachecker.core.defaults.DelegateAbstractDomain;
+import org.sosy_lab.cpachecker.core.interfaces.AbstractState;
+import org.sosy_lab.cpachecker.core.interfaces.CPAFactory;
+import org.sosy_lab.cpachecker.core.interfaces.MergeOperator;
+import org.sosy_lab.cpachecker.core.interfaces.StateSpacePartition;
+import org.sosy_lab.cpachecker.core.interfaces.Statistics;
+import org.sosy_lab.cpachecker.core.interfaces.StatisticsProvider;
+import org.sosy_lab.cpachecker.core.interfaces.StopOperator;
+import org.sosy_lab.cpachecker.core.interfaces.TransferRelation;
+import org.sosy_lab.cpachecker.cpa.interval.IntervalAnalysisState;
+import org.sosy_lab.cpachecker.util.StateToFormulaWriter;
+
+@Options(prefix = "cpa.unseqbehavior")
+public class UnseqBehaviorAnalysisCPA extends AbstractCPA implements StatisticsProvider {
+  @Option(
+      secure = true,
+      name = "merge",
+      toUppercase = true,
+      values = {"SEP", "JOIN"},
+      description = "which merge operator to use for UnseqBehaviorAnalysisCPA ")
+  private String mergeType = "SEP";
+
+  @Option(
+      secure = true,
+      name = "stop",
+      toUppercase = true,
+      values = {"SEP", "JOIN", "NEVER"},
+      description = "which stop operator to use for UnseqBehaviorAnalysisCPA")
+  private String stopType = "SEP";
+
+  private final StateToFormulaWriter writer;
+  private final LogManager logger;
+
+  private UnseqBehaviorAnalysisCPA (
+      Configuration config, LogManager pLogger, ShutdownNotifier shutdownNotifier, CFA cfa)
+      throws InvalidConfigurationException {
+    super("sep", "sep", DelegateAbstractDomain.<IntervalAnalysisState>getInstance(), null);
+    config.inject(this);
+    writer = new StateToFormulaWriter(config, pLogger, shutdownNotifier, cfa);
+    logger = pLogger;
+  }
+
+  public static CPAFactory factory() {
+    return AutomaticCPAFactory.forType(UnseqBehaviorAnalysisCPA.class);
+  }
+
+  @Override
+  public MergeOperator getMergeOperator() {
+    return buildMergeOperator(mergeType);
+  }
+
+  @Override
+  public StopOperator getStopOperator() {
+    return buildStopOperator(stopType);
+  }
+
+  @Override
+  public TransferRelation getTransferRelation() {
+    return new UnseqBehaviorAnalysisTransferRelation(logger);
+  }
+  @Override
+  public AbstractState getInitialState(CFANode node, StateSpacePartition partition)
+      throws InterruptedException {
+    return new UnseqBehaviorAnalysisState();
+  }
+  @Override
+  public void collectStatistics(Collection<Statistics> pStatsCollection) {
+    writer.collectStatistics(pStatsCollection);
+  }
+}
Index: src/org/sosy_lab/cpachecker/cfa/model/c/CCfaEdge.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>// This file is part of CPAchecker,\n// a tool for configurable software verification:\n// https://cpachecker.sosy-lab.org\n//\n// SPDX-FileCopyrightText: 2007-2021 Dirk Beyer <https://www.sosy-lab.org>\n//\n// SPDX-License-Identifier: Apache-2.0\n\npackage org.sosy_lab.cpachecker.cfa.model.c;\n\nimport org.sosy_lab.cpachecker.cfa.model.CFAEdge;\n\npublic interface CCfaEdge extends CFAEdge {\n\n  <R, X extends Exception> R accept(CCfaEdgeVisitor<R, X> pVisitor) throws X;\n}\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/org/sosy_lab/cpachecker/cfa/model/c/CCfaEdge.java b/src/org/sosy_lab/cpachecker/cfa/model/c/CCfaEdge.java
--- a/src/org/sosy_lab/cpachecker/cfa/model/c/CCfaEdge.java	(revision 994693c6616e755015ebf8f13b83d23d2f5cd593)
+++ b/src/org/sosy_lab/cpachecker/cfa/model/c/CCfaEdge.java	(date 1744318991729)
@@ -8,9 +8,16 @@
 
 package org.sosy_lab.cpachecker.cfa.model.c;
 
+import java.util.Optional;
+import org.sosy_lab.cpachecker.cfa.ast.AAstNode;
 import org.sosy_lab.cpachecker.cfa.model.CFAEdge;
 
 public interface CCfaEdge extends CFAEdge {
 
   <R, X extends Exception> R accept(CCfaEdgeVisitor<R, X> pVisitor) throws X;
+
+  @Override
+  default Optional<AAstNode> getRawAST() {
+    return Optional.empty();
+  }
 }
Index: src/org/sosy_lab/cpachecker/cpa/unsequenced/BinaryExpressionGatherVisitor.java
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/org/sosy_lab/cpachecker/cpa/unsequenced/BinaryExpressionGatherVisitor.java b/src/org/sosy_lab/cpachecker/cpa/unsequenced/BinaryExpressionGatherVisitor.java
new file mode 100644
--- /dev/null	(date 1744838331733)
+++ b/src/org/sosy_lab/cpachecker/cpa/unsequenced/BinaryExpressionGatherVisitor.java	(date 1744838331733)
@@ -0,0 +1,67 @@
+// This file is part of CPAchecker,
+// a tool for configurable software verification:
+// https://cpachecker.sosy-lab.org
+//
+// SPDX-FileCopyrightText: 2025 Dirk Beyer <https://www.sosy-lab.org>
+//
+// SPDX-License-Identifier: Apache-2.0
+
+package org.sosy_lab.cpachecker.cpa.unsequenced;
+
+import java.util.Collections;
+import java.util.HashSet;
+import java.util.Set;
+import java.util.logging.Level;
+import org.sosy_lab.common.log.LogManager;
+import org.sosy_lab.cpachecker.cfa.ast.c.CBinaryExpression;
+import org.sosy_lab.cpachecker.cfa.ast.c.CExpression;
+import org.sosy_lab.cpachecker.cfa.ast.c.DefaultCExpressionVisitor;
+import org.sosy_lab.cpachecker.exceptions.UnrecognizedCodeException;
+
+public class BinaryExpressionGatherVisitor extends DefaultCExpressionVisitor<Set<CBinaryExpression>, UnrecognizedCodeException> {
+
+  private final LogManager logger;
+
+  public BinaryExpressionGatherVisitor(LogManager pLogger) {
+    logger = pLogger;
+  }
+
+  @Override
+  protected Set<CBinaryExpression> visitDefault(CExpression exp) throws UnrecognizedCodeException {
+    return Collections.emptySet();
+  }
+
+  @Override
+  public Set<CBinaryExpression> visit(CBinaryExpression expr) throws UnrecognizedCodeException {
+    Set<CBinaryExpression> binaryExprs = new HashSet<>();
+
+    binaryExprs.addAll(expr.getOperand1().accept(this));
+    binaryExprs.addAll(expr.getOperand2().accept(this));
+
+    if (isUnsequencedBinaryOperator(expr.getOperator())) {
+      binaryExprs.add(expr);
+    }
+
+    logger.log(
+        Level.INFO,
+        String.format("Detected unsequenced binary expression '%s' at %s",
+            expr.toASTString(),
+            expr.getFileLocation())
+    );
+
+    return binaryExprs;
+  }
+
+  private boolean isUnsequencedBinaryOperator(CBinaryExpression.BinaryOperator op) {
+    return switch (op) {
+      case BINARY_AND, BINARY_OR -> false;
+      case MULTIPLY, DIVIDE, MODULO,
+           PLUS, MINUS,
+           SHIFT_LEFT, SHIFT_RIGHT, BINARY_XOR,
+           LESS_EQUAL, LESS_THAN, GREATER_EQUAL, GREATER_THAN,
+           EQUALS, NOT_EQUALS -> true;
+      default -> throw new AssertionError("Unhandled operator in isUnsequencedBinaryOperator: " + op);
+    };
+  }
+
+}
Index: src/org/sosy_lab/cpachecker/cpa/unsequenced/testcases/undetected_subexpression_global.c
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/src/org/sosy_lab/cpachecker/cpa/unsequenced/testcases/undetected_subexpression_global.c b/src/org/sosy_lab/cpachecker/cpa/unsequenced/testcases/undetected_subexpression_global.c
new file mode 100644
--- /dev/null	(date 1744780286036)
+++ b/src/org/sosy_lab/cpachecker/cpa/unsequenced/testcases/undetected_subexpression_global.c	(date 1744780286036)
@@ -0,0 +1,19 @@
+#include <stdio.h>
+
+int x = 0;
+int y = 0;
+
+int f() {
+  x = 1;
+  return 0;
+}
+
+int g() {
+  int a = y;
+  return a;
+}
+
+int main() {
+  int result = f() + g(); // f() writes x, g() reads y, no conflict
+  return 0;
+}
\ No newline at end of file
